{
  "extraction_info": {
    "date": "2025-10-01T15:21:07.936425",
    "total_toolsets": 1,
    "total_tools": 69,
    "toolbox": "spatial-statistics"
  },
  "tools": [
    {
      "toolset": "spatial-statistics",
      "tool_name": "Geoprocessing considerations for shapefile output",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/appendices/geoprocessing-considerations-for-shapefile-output.htm",
      "parameters": [],
      "summary": "",
      "extraction_date": "2025-10-01T15:17:37.014360"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Incremental Spatial Autocorrelation",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/incremental-spatial-autocorrelation.htm",
      "parameters": [
        {
          "name": "Input_Features",
          "explanation": "The feature class for which spatial autocorrelation will be measured over a series of distances.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Input_Field",
          "explanation": "The numeric field that will be used in assessing spatial autocorrelation.",
          "datatype": "Field"
        },
        {
          "name": "Number_of_Distance_Bands",
          "explanation": "The number of times the neighborhood size will be incremented and the dataset will be analyzed for spatial autocorrelation. The starting point and size of the increment are specified by the Beginning_Distance and Distance_Increment parameters, respectively.",
          "datatype": "Long"
        },
        {
          "name": "Beginning_Distance(Optional)",
          "explanation": "The distance at which the analysis of spatial autocorrelation and the distance from which to increment will start. The value provided for this parameter should be in the units of the Output Coordinate System environment setting.",
          "datatype": "Double"
        },
        {
          "name": "Distance_Increment(Optional)",
          "explanation": "The distance that will be increased after each iteration. The distance used in the analysis starts at the Beginning_Distance parameter value and increases by the amount specified in the Distance_Increment parameter value. The value provided for this parameter should be in the units of the Output Coordinate System environment setting.",
          "datatype": "Double"
        },
        {
          "name": "Distance_Method(Optional)",
          "explanation": "Specifies how distances will be calculated from each feature to neighboring features.            EUCLIDEAN—The distances will be calculated using the straight-line distance between two points (as the crow flies). This is the default.MANHATTAN—The distances will be calculated using the distance between two points measured along axes at right angles (city block), which is calculated by summing the (absolute) difference between the x- and y-coordinates.",
          "datatype": "String"
        },
        {
          "name": "Row_Standardization(Optional)",
          "explanation": "Specifies whether spatial weights will be standardized. Row standardization is recommended whenever feature distribution is potentially biased due to sampling design or an imposed aggregation scheme.ROW_STANDARDIZATION—Spatial weights will be standardized. Each weight will divided by its row sum (the sum of the weights of all neighboring features). This is the default.NO_STANDARDIZATION—Spatial weights will not be standardized.",
          "datatype": "Boolean"
        },
        {
          "name": "Output_Table(Optional)",
          "explanation": "The table that will be created with each distance band and associated z-score result.",
          "datatype": "Table"
        },
        {
          "name": "Output_Report_File(Optional)",
          "explanation": "The .pdf file that will be created containing a line graph summarizing results.",
          "datatype": "File"
        }
      ],
      "summary": "Measures spatial autocorrelation for a series of distances and optionally creates a line graph of those distances and their corresponding z-scores.  Z-scores reflect the intensity of spatial clustering, and statistically significant peak z-scores indicate distances where spatial processes promoting clustering are most pronounced.  These peak distances are often appropriate values to use for tools with a Distance Band or Distance Radius parameter.",
      "extraction_date": "2025-10-01T15:17:40.739186"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Hot Spot Analysis",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/hot-spot-analysis.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class for which hot spot analysis will be performed.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Input_Field",
          "explanation": "The numeric field (for example, number of victims, crime rate, test scores, and so on) to be evaluated.",
          "datatype": "Field"
        },
        {
          "name": "Output_Feature_Class",
          "explanation": "The output feature class that will receive the z-score and p-value results.",
          "datatype": "Feature Class"
        },
        {
          "name": "Conceptualization_of_Spatial_Relationships",
          "explanation": "Specifies how spatial relationships among features will be defined.INVERSE_DISTANCE—Nearby neighboring features will have a larger influence  on the  computations for a target feature than features that are far away.INVERSE_DISTANCE_SQUARED—This is the same as INVERSE_DISTANCE except that the slope is sharper, so influence will drop off more quickly, and only a target feature's closest neighbors will exert substantial influence on  computations for that feature.FIXED_DISTANCE_BAND—Each feature will be analyzed within the context of neighboring features.  Neighboring features inside the specified critical distance (Distance_Band_or_Threshold) will receive a weight of 1  and exert influence on computations for the target feature.  Neighboring features outside the critical distance will receive a weight of 0 and have no  influence on a target feature's computations.ZONE_OF_INDIFFERENCE—Features within the specified critical distance (Distance_Band_or_Threshold) of a target feature will receive a weight of 1 and influence computations for that feature. Once the critical distance is exceeded, weights (and the influence a neighboring feature has on target feature computations) will diminish with distance.K_NEAREST_NEIGHBORS—The closest k features will be included in the analysis; k is a specified numeric parameter.CONTIGUITY_EDGES_ONLY—Only neighboring polygon features that share a boundary or overlap will influence computations for the target polygon feature.CONTIGUITY_EDGES_CORNERS—Polygon features that share a boundary, share a node, or overlap will influence computations for the target polygon feature.GET_SPATIAL_WEIGHTS_FROM_FILE—Spatial relationships will be defined by a specified spatial weights file. The path to the spatial weights file is specified by the Weights_Matrix_File parameter.",
          "datatype": "String"
        },
        {
          "name": "Distance_Method",
          "explanation": "Specifies how distances will be calculated from each feature to neighboring features.EUCLIDEAN_DISTANCE—The straight-line distance between two points (as the crow flies) will be used.MANHATTAN_DISTANCE—The distance between two points measured along axes at right angles (city block) calculated by summing the (absolute) difference between the x- and y-coordinates will be used.",
          "datatype": "String"
        },
        {
          "name": "Standardization",
          "explanation": "Row standardization has no impact on this tool: Results from this tool would be identical with or without row standardization.  This parameter is disabled; it remains only to support backward compatibility.NONE—No standardization of spatial weights is applied. ROW—No standardization of spatial weights is applied.",
          "datatype": "String"
        },
        {
          "name": "Distance_Band_or_Threshold_Distance(Optional)",
          "explanation": "The cutoff distance for the inverse distance and fixed distance options. Features outside the specified cutoff for a target feature will be ignored in analyses for that feature. However, for ZONE_OF_INDIFFERENCE, the influence of features outside the given distance will be reduced with distance, while those inside the distance threshold will be equally considered. The distance value provided should match that of the output coordinate system.For the inverse distance conceptualizations of spatial relationships, a value of 0 indicates that no threshold distance will be applied; when this parameter is left blank, a default threshold value will be computed and applied.    The default value is the Euclidean distance, which ensures that every feature has at least one neighbor.This parameter has no effect when polygon contiguity  (CONTIGUITY_EDGES_ONLY or CONTIGUITY_EDGES_CORNERS) or the GET_SPATIAL_WEIGHTS_FROM_FILE spatial conceptualization option is specified.",
          "datatype": "Double"
        },
        {
          "name": "Self_Potential_Field(Optional)",
          "explanation": "The field representing self potential, which is the distance or weight between a feature and itself.",
          "datatype": "Field"
        },
        {
          "name": "Weights_Matrix_File(Optional)",
          "explanation": "The path to a file containing weights that define spatial, and potentially temporal, relationships among features.",
          "datatype": "File"
        },
        {
          "name": "Apply_False_Discovery_Rate__FDR__Correction(Optional)",
          "explanation": "Specifies whether statistical significance will be assessed based on the FDR correction.APPLY_FDR—Statistical significance will be based on the FDR correction.NO_FDR—Statistical significance will not be based on the FDR correction; it will be based on the p-value and z-score fields. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "An integer specifying the number of neighbors that will be included in the analysis.",
          "datatype": "Long"
        }
      ],
      "summary": "Given a set of weighted features, identifies statistically significant hot spots and cold spots using the Getis-Ord Gi* statistic. Learn more about how Hot Spot Analysis (Getis-Ord Gi*) works",
      "extraction_date": "2025-10-01T15:17:43.718787"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "p-value",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/what-is-a-z-score-what-is-a-p-value.htm",
      "parameters": [],
      "summary": "",
      "extraction_date": "2025-10-01T15:17:46.182569"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Average Nearest Neighbor",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/average-nearest-neighbor.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class, typically a point feature class, for which the average nearest neighbor distance will be calculated.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Distance_Method",
          "explanation": "Specifies how distances are calculated from each feature to neighboring features.EUCLIDEAN_DISTANCE—The straight-line distance between two points (as the crow flies) MANHATTAN_DISTANCE—The distance between two points measured along axes at right angles (city block); calculated by summing the (absolute) difference between the x- and y-coordinates",
          "datatype": "String"
        },
        {
          "name": "Generate_Report(Optional)",
          "explanation": "Specifies whether the tool will create a graphical summary of results.            \r\n            NO_REPORT—No graphical summary will be created. This is the default.GENERATE_REPORT—A graphical summary will be created as an HTML file.",
          "datatype": "Boolean"
        },
        {
          "name": "Area(Optional)",
          "explanation": "A numeric value representing the study area size. The default value is the area of the minimum enclosing rectangle that would encompass all features (or all selected features). Units should match those for the Output Coordinate System.",
          "datatype": "Double"
        }
      ],
      "summary": "Calculates a nearest neighbor index based on the average distance from each feature to its nearest neighboring feature. Learn more about how Average Nearest Neighbor Distance works",
      "extraction_date": "2025-10-01T15:17:48.639826"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "High/Low Clustering",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/high-low-clustering.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class for which the General G statistic will be calculated.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Input_Field",
          "explanation": "The numeric field to be evaluated.",
          "datatype": "Field"
        },
        {
          "name": "Generate_Report(Optional)",
          "explanation": "Specifies whether a graphical summary of result will be created as an .html file.\r\nNO_REPORT—No graphical summary will be created. This is the default.GENERATE_REPORT—A graphical summary will be created.",
          "datatype": "Boolean"
        },
        {
          "name": "Conceptualization_of_Spatial_Relationships",
          "explanation": "Specifies how spatial relationships among features are defined.INVERSE_DISTANCE—Nearby neighboring features have a larger influence  on the  computations for a target feature than features that are far away.INVERSE_DISTANCE_SQUARED—Same as INVERSE_DISTANCE except that the slope is sharper, so influence drops off more quickly, and only a target feature's closest neighbors will exert substantial influence on  computations for that feature. FIXED_DISTANCE_BAND—Each feature is analyzed within the context of neighboring features.  Neighboring features inside the specified critical distance (Distance_Band_or_Threshold) receive a weight of one  and exert influence on computations for the target feature.  Neighboring features outside the critical distance receive a weight of zero and have no  influence on a target feature's computations. ZONE_OF_INDIFFERENCE—Features within the specified critical distance (Distance_Band_or_Threshold) of a target feature receive a weight of one and influence computations for that feature. Once the critical distance is exceeded, weights (and the influence a neighboring feature has on target feature computations) diminish with distance. K_NEAREST_NEIGHBORS—The closest k features are included in the analysis; k is a specified numeric parameter.CONTIGUITY_EDGES_ONLY—Only neighboring polygon features that share a boundary or overlap will influence computations for the target polygon feature.  CONTIGUITY_EDGES_CORNERS—Polygon features that share a boundary, share a node, or overlap will influence computations for the target polygon feature. GET_SPATIAL_WEIGHTS_FROM_FILE—Spatial relationships are defined by a specified spatial weights file. The path to the spatial weights file is specified by the Weights_Matrix_File parameter.",
          "datatype": "String"
        },
        {
          "name": "Distance_Method",
          "explanation": "Specifies how distances are calculated from each feature to neighboring features.EUCLIDEAN_DISTANCE—The straight-line distance between two points (as the crow flies) MANHATTAN_DISTANCE—The distance between two points measured along axes at right angles (city block); calculated by summing the (absolute) difference between the x- and y-coordinates",
          "datatype": "String"
        },
        {
          "name": "Standardization",
          "explanation": "Specifies whether standardization of spatial weights will be applied. Row standardization is recommended whenever the distribution of your features is potentially biased due to sampling design or an imposed aggregation scheme.NONE—No standardization of spatial weights is applied. ROW—Spatial weights are standardized; each weight is divided by its row sum (the sum of the weights of all neighboring features). This is the default.",
          "datatype": "String"
        },
        {
          "name": "Distance_Band_or_Threshold_Distance(Optional)",
          "explanation": "Specifies a cutoff distance for the inverse distance and fixed distance options. Features outside the specified cutoff for a target feature are ignored in analyses for that feature. However, for ZONE_OF_INDIFFERENCE, the influence of features outside the given distance is reduced with distance, while those inside the distance threshold are equally considered. The distance value entered should match that of the output coordinate system.For the inverse distance conceptualizations of spatial relationships, a value of 0 indicates that no threshold distance is applied; when this parameter is left blank, a default threshold value is computed and applied.    This default value is the Euclidean distance that ensures that every feature has at least one neighbor.This parameter has no effect when polygon contiguity  (CONTIGUITY_EDGES_ONLY or CONTIGUITY_EDGES_CORNERS) or GET_SPATIAL_WEIGHTS_FROM_FILE spatial conceptualizations are selected.",
          "datatype": "Double"
        },
        {
          "name": "Weights_Matrix_File(Optional)",
          "explanation": "The path to a file containing weights that define spatial, and potentially temporal, relationships among features.",
          "datatype": "File"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "An integer specifying the number of neighbors that will be included in the analysis.",
          "datatype": "Long"
        }
      ],
      "summary": "Measures the degree of clustering for either high or low values using the Getis-Ord General G statistic. Learn more about how High/Low Clustering: Getis-Ord General G works",
      "extraction_date": "2025-10-01T15:17:53.057616"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Multi-Distance Spatial Cluster Analysis (Ripley's k-function)",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/multi-distance-spatial-cluster-analysis.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class upon which the analysis will be performed.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Table",
          "explanation": "The table to which the results of the analysis will be written.",
          "datatype": "Table"
        },
        {
          "name": "Number_of_Distance_Bands",
          "explanation": "The number of times to increment the neighborhood size and analyze the dataset for clustering. The starting point and size of the increment are specified in the Beginning_Distance and Distance_Increment parameters, respectively.",
          "datatype": "Long"
        },
        {
          "name": "Compute_Confidence_Envelope(Optional)",
          "explanation": "The confidence envelope is calculated by randomly placing feature points (or feature values) in the study area. The number of points/values randomly placed is equal to the number of points in the feature class. Each set of random placements is called a permutation and the confidence envelope is created from these permutations. This parameter allows you to select how many permutations you want to use to create the confidence envelope.0_PERMUTATIONS_-_NO_CONFIDENCE_ENVELOPE—Confidence envelopes are not created. 9_PERMUTATIONS—Nine sets of points/values are randomly placed. 99_PERMUTATIONS—99 sets of points/values are randomly placed. 999_PERMUTATIONS—999 sets of points/values are randomly placed.",
          "datatype": "String"
        },
        {
          "name": "Display_Results_Graphically(Optional)",
          "explanation": "This parameter has no effect; it remains to support backward compatibility.NO_DISPLAY—No graphical summary will be created (default).DISPLAY_IT—A graphical summary will be created as a graph layer.",
          "datatype": "Boolean"
        },
        {
          "name": "Weight_Field(Optional)",
          "explanation": "A numeric field with weights representing the number of features/events at each location.",
          "datatype": "Field"
        },
        {
          "name": "Beginning_Distance(Optional)",
          "explanation": "The distance at which to start the cluster analysis and the distance from which to increment. The value entered for this parameter should be in the units of the Output Coordinate System.",
          "datatype": "Double"
        },
        {
          "name": "Distance_Increment(Optional)",
          "explanation": "The distance to increment during each iteration. The distance used in the analysis starts at the Beginning_Distance and increments by the amount specified in the Distance_Increment. The value entered for this parameter should be in the units of the Output Coordinate System environment setting.",
          "datatype": "Double"
        },
        {
          "name": "Boundary_Correction_Method(Optional)",
          "explanation": "Method to use to correct for underestimates in the number of neighbors for features near the edges of the study area.NONE—No edge correction is applied. However, if the input feature class already has points that fall outside the study area boundaries, these will be used in neighborhood counts for features near boundaries. SIMULATE_OUTER_BOUNDARY_VALUES—This method simulates points outside the study area so that the number of neighbors near edges is not underestimated. The simulated points are the \"mirrors\" of points near edges within the study area boundary. REDUCE_ANALYSIS_AREA—This method shrinks the study area such that some points are found outside of the study area boundary. Points found outside the study area are used to calculate neighbor counts but are not used in the cluster analysis itself. RIPLEY_EDGE_CORRECTION_FORMULA—For all the points (j) in the neighborhood of point i, this method checks to see if the edge of the study area is closer to i, or if j is closer to i. If j is closer, extra weight is given to the point j. This edge correction method is only appropriate for square or rectangular shaped study areas.",
          "datatype": "String"
        },
        {
          "name": "Study_Area_Method(Optional)",
          "explanation": "Specifies the region to use for the study area. The K Function is sensitive to changes in study area size so careful selection of this value is important.MINIMUM_ENCLOSING_RECTANGLE—Indicates that the smallest possible rectangle enclosing all of the points will be used. USER_PROVIDED_STUDY_AREA_FEATURE_CLASS—Indicates that a feature class defining the study area will be provided in the Study Area Feature Class parameter.",
          "datatype": "String"
        },
        {
          "name": "Study_Area_Feature_Class(Optional)",
          "explanation": "Feature class that delineates the area over which the input feature class should be analyzed. Only specified if Study_Area_Method = \"USER_PROVIDED_STUDY_AREA_FEATURE_CLASS\".",
          "datatype": "Feature Layer"
        }
      ],
      "summary": "Determines whether features, or the values associated with features, exhibit statistically significant clustering or dispersion over a range of distances. Learn more about how Multi-Distance Spatial Cluster Analysis works",
      "extraction_date": "2025-10-01T15:17:55.631896"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Spatial Autocorrelation",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/spatial-autocorrelation.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class for which spatial autocorrelation will be calculated.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Input_Field",
          "explanation": "The numeric field that will be used in assessing spatial autocorrelation.",
          "datatype": "Field"
        },
        {
          "name": "Generate_Report(Optional)",
          "explanation": "Specifies whether a graphical summary of result will be created as an .html file.\r\nNO_REPORT—No graphical summary will be created. This is the default.GENERATE_REPORT—A graphical summary will be created.",
          "datatype": "Boolean"
        },
        {
          "name": "Conceptualization_of_Spatial_Relationships",
          "explanation": "Specifies how spatial relationships among features will be defined.INVERSE_DISTANCE—Nearby neighboring features have a larger influence  on the  computations for a target feature than features that are far away.INVERSE_DISTANCE_SQUARED—This is the same as the INVERSE_DISTANCE option except that the slope is sharper, so influence drops off more quickly, and only a target feature's closest neighbors will exert substantial influence on  computations for that feature. FIXED_DISTANCE_BAND—Each feature is analyzed within the context of neighboring features.  Neighboring features within the specified critical distance (Distance_Band_or_Threshold value) receive a weight of one  and exert influence on computations for the target feature.  Neighboring features outside the critical distance receive a weight of zero and have no  influence on a target feature's computations. ZONE_OF_INDIFFERENCE—Features within the specified critical distance (Distance_Band_or_Threshold value) of a target feature receive a weight of one and influence computations for that feature. Once the critical distance is exceeded, weights (and the influence a neighboring feature has on target feature computations) diminish with distance. K_NEAREST_NEIGHBORS—The closest k features are included in the analysis.  The number of neighbors (k) to include in the analysis is specified by the number_of_neighbors parameter.CONTIGUITY_EDGES_ONLY—Only neighboring polygon features that share a boundary or overlap will influence computations for the target polygon feature.  CONTIGUITY_EDGES_CORNERS—Polygon features that share a boundary, share a node, or overlap will influence computations for the target polygon feature. GET_SPATIAL_WEIGHTS_FROM_FILE—Spatial relationships are defined by a specified spatial weights file. The path to the spatial weights file is specified by the Weights_Matrix_File parameter.",
          "datatype": "String"
        },
        {
          "name": "Distance_Method",
          "explanation": "Specifies how distances will be calculated from each feature to neighboring features.EUCLIDEAN_DISTANCE—The straight-line distance between two points (as the crow flies) will be used. This is the default.MANHATTAN_DISTANCE—The distance between two points measured along axes at right angles (city block) will be used. This is calculated by summing the (absolute) difference between the x- and y-coordinates",
          "datatype": "String"
        },
        {
          "name": "Standardization",
          "explanation": "Specifies whether standardization of spatial weights will be applied. Row standardization is recommended whenever the distribution of features is potentially biased due to sampling design or an imposed aggregation scheme.NONE—No standardization of spatial weights will be applied. ROW—Spatial weights will be standardized; each weight will be divided by its row sum (the sum of the weights of all neighboring features). This is the default.",
          "datatype": "String"
        },
        {
          "name": "Distance_Band_or_Threshold_Distance(Optional)",
          "explanation": "The cutoff distance for the various inverse distance and fixed distance options. Features outside the specified cutoff for a target feature are ignored in analyses for that feature. However, for ZONE_OF_INDIFFERENCE, the influence of features outside the given distance is reduced with distance, while those within the distance threshold are equally considered. The distance value provided should match that of the output coordinate system.For the inverse distance conceptualizations of spatial relationships, a value of 0 indicates that no threshold distance is applied; when this parameter is left blank, a default threshold value is computed and applied.    The default value is the Euclidean distance, which ensures that every feature has at least one neighbor.This parameter has no effect when polygon contiguity  (CONTIGUITY_EDGES_ONLY or CONTIGUITY_EDGES_CORNERS) or GET_SPATIAL_WEIGHTS_FROM_FILE spatial conceptualization is specified.",
          "datatype": "Double"
        },
        {
          "name": "Weights_Matrix_File(Optional)",
          "explanation": "The path to a file containing weights that define spatial, and potentially temporal, relationships among features.",
          "datatype": "File"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "An integer specifying the number of neighbors that will be included in the analysis.",
          "datatype": "Long"
        }
      ],
      "summary": "Measures spatial autocorrelation based on feature locations and attribute values using the Global Moran's I statistic. Learn more about how Spatial Autocorrelation (Global Moran's I) works",
      "extraction_date": "2025-10-01T15:17:58.621973"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Hot Spot Analysis (Getis-Ord Gi*)",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/hot-spot-analysis.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class for which hot spot analysis will be performed.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Input_Field",
          "explanation": "The numeric field (for example, number of victims, crime rate, test scores, and so on) to be evaluated.",
          "datatype": "Field"
        },
        {
          "name": "Output_Feature_Class",
          "explanation": "The output feature class that will receive the z-score and p-value results.",
          "datatype": "Feature Class"
        },
        {
          "name": "Conceptualization_of_Spatial_Relationships",
          "explanation": "Specifies how spatial relationships among features will be defined.INVERSE_DISTANCE—Nearby neighboring features will have a larger influence  on the  computations for a target feature than features that are far away.INVERSE_DISTANCE_SQUARED—This is the same as INVERSE_DISTANCE except that the slope is sharper, so influence will drop off more quickly, and only a target feature's closest neighbors will exert substantial influence on  computations for that feature.FIXED_DISTANCE_BAND—Each feature will be analyzed within the context of neighboring features.  Neighboring features inside the specified critical distance (Distance_Band_or_Threshold) will receive a weight of 1  and exert influence on computations for the target feature.  Neighboring features outside the critical distance will receive a weight of 0 and have no  influence on a target feature's computations.ZONE_OF_INDIFFERENCE—Features within the specified critical distance (Distance_Band_or_Threshold) of a target feature will receive a weight of 1 and influence computations for that feature. Once the critical distance is exceeded, weights (and the influence a neighboring feature has on target feature computations) will diminish with distance.K_NEAREST_NEIGHBORS—The closest k features will be included in the analysis; k is a specified numeric parameter.CONTIGUITY_EDGES_ONLY—Only neighboring polygon features that share a boundary or overlap will influence computations for the target polygon feature.CONTIGUITY_EDGES_CORNERS—Polygon features that share a boundary, share a node, or overlap will influence computations for the target polygon feature.GET_SPATIAL_WEIGHTS_FROM_FILE—Spatial relationships will be defined by a specified spatial weights file. The path to the spatial weights file is specified by the Weights_Matrix_File parameter.",
          "datatype": "String"
        },
        {
          "name": "Distance_Method",
          "explanation": "Specifies how distances will be calculated from each feature to neighboring features.EUCLIDEAN_DISTANCE—The straight-line distance between two points (as the crow flies) will be used.MANHATTAN_DISTANCE—The distance between two points measured along axes at right angles (city block) calculated by summing the (absolute) difference between the x- and y-coordinates will be used.",
          "datatype": "String"
        },
        {
          "name": "Standardization",
          "explanation": "Row standardization has no impact on this tool: Results from this tool would be identical with or without row standardization.  This parameter is disabled; it remains only to support backward compatibility.NONE—No standardization of spatial weights is applied. ROW—No standardization of spatial weights is applied.",
          "datatype": "String"
        },
        {
          "name": "Distance_Band_or_Threshold_Distance(Optional)",
          "explanation": "The cutoff distance for the inverse distance and fixed distance options. Features outside the specified cutoff for a target feature will be ignored in analyses for that feature. However, for ZONE_OF_INDIFFERENCE, the influence of features outside the given distance will be reduced with distance, while those inside the distance threshold will be equally considered. The distance value provided should match that of the output coordinate system.For the inverse distance conceptualizations of spatial relationships, a value of 0 indicates that no threshold distance will be applied; when this parameter is left blank, a default threshold value will be computed and applied.    The default value is the Euclidean distance, which ensures that every feature has at least one neighbor.This parameter has no effect when polygon contiguity  (CONTIGUITY_EDGES_ONLY or CONTIGUITY_EDGES_CORNERS) or the GET_SPATIAL_WEIGHTS_FROM_FILE spatial conceptualization option is specified.",
          "datatype": "Double"
        },
        {
          "name": "Self_Potential_Field(Optional)",
          "explanation": "The field representing self potential, which is the distance or weight between a feature and itself.",
          "datatype": "Field"
        },
        {
          "name": "Weights_Matrix_File(Optional)",
          "explanation": "The path to a file containing weights that define spatial, and potentially temporal, relationships among features.",
          "datatype": "File"
        },
        {
          "name": "Apply_False_Discovery_Rate__FDR__Correction(Optional)",
          "explanation": "Specifies whether statistical significance will be assessed based on the FDR correction.APPLY_FDR—Statistical significance will be based on the FDR correction.NO_FDR—Statistical significance will not be based on the FDR correction; it will be based on the p-value and z-score fields. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "An integer specifying the number of neighbors that will be included in the analysis.",
          "datatype": "Long"
        }
      ],
      "summary": "Given a set of weighted features, identifies statistically significant hot spots and cold spots using the Getis-Ord Gi* statistic. Learn more about how Hot Spot Analysis (Getis-Ord Gi*) works",
      "extraction_date": "2025-10-01T15:18:03.159879"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Optimized Hot Spot Analysis",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/optimized-hot-spot-analysis.htm",
      "parameters": [
        {
          "name": "Input_Features",
          "explanation": "The point or polygon feature class for which hot spot analysis will be performed.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Features",
          "explanation": "The output feature class to receive the z-score, p-value, and Gi_Bin results.",
          "datatype": "Feature Class"
        },
        {
          "name": "Analysis_Field(Optional)",
          "explanation": "The numeric field (number of incidents, crime rates, test scores, and so on) to be evaluated.",
          "datatype": "Field"
        },
        {
          "name": "Incident_Data_Aggregation_Method(Optional)",
          "explanation": "The aggregation method to use to create weighted features for analysis from incident point data.\r\nCOUNT_INCIDENTS_WITHIN_FISHNET_POLYGONS—A fishnet polygon mesh will overlay the incident point data  and the number of incidents within each polygon cell will be counted.  If no bounding polygon is provided in the Bounding_Polygons_Defining_Where_Incidents_Are_Possible parameter, only cells with at least one incident will be used in the analysis; otherwise, all cells within the bounding polygons will be analyzed.COUNT_INCIDENTS_WITHIN_HEXAGON_POLYGONS—A hexagon polygon mesh will overlay the incident point data  and the number of incidents within each polygon cell will be counted.  If no bounding polygon is provided in the Bounding_Polygons_Defining_Where_Incidents_Are_Possible parameter, only cells with at least one incident will be used in the analysis; otherwise, all cells within the bounding polygons will be analyzed.COUNT_INCIDENTS_WITHIN_AGGREGATION_POLYGONS—You provide aggregation polygons to overlay the incident point data in the Polygons_For_Aggregating_Incidents_Into_Counts parameter.  The incidents within each polygon are counted.SNAP_NEARBY_INCIDENTS_TO_CREATE_WEIGHTED_POINTS—Nearby incidents will be aggregated together to create a single weighted point.  The weight for each point is the number of aggregated incidents at that location.",
          "datatype": "String"
        },
        {
          "name": "Bounding_Polygons_Defining_Where_Incidents_Are_Possible(Optional)",
          "explanation": "A polygon feature class defining where the incident Input_Features could possibly occur.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Polygons_For_Aggregating_Incidents_Into_Counts(Optional)",
          "explanation": "The polygons to use to aggregate the incident Input_Features in order to get an incident count for each polygon feature.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Density_Surface(Optional)",
          "explanation": "The Density_Surface parameter is disabled; it\r\nremains as a tool parameter only to support backwards\r\ncompatibility.\r\nThe Kernel Density tool can be used if you would like a density surface visualization of your weighted points.",
          "datatype": "Raster Dataset"
        },
        {
          "name": "Cell_Size(Optional)",
          "explanation": "The size of the grid cells used to aggregate the Input_Features.  When aggregating into a hexagon grid, this distance is used as the height to construct the hexagon polygons.",
          "datatype": "Linear Unit"
        },
        {
          "name": "Distance_Band(Optional)",
          "explanation": "The spatial extent of the analysis neighborhood.  This value determines which features are analyzed together in order to assess local clustering.",
          "datatype": "Linear Unit"
        }
      ],
      "summary": "Creates a map of statistically significant hot and cold spots using the Getis-Ord Gi* statistic, given incident points or weighted features (points or polygons). The tool evaluates the characteristics of the input feature class to produce optimal results. Learn more about how Optimized Hot Spot Analysis works",
      "extraction_date": "2025-10-01T15:18:07.769265"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Cluster and Outlier Analysis (Anselin Local Moran's I)",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/cluster-and-outlier-analysis-anselin-local-moran-s.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class for which cluster and outlier analysis will be performed.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Input_Field",
          "explanation": "The numeric field to be evaluated.",
          "datatype": "Field"
        },
        {
          "name": "Output_Feature_Class",
          "explanation": "The output feature class to receive the results fields.",
          "datatype": "Feature Class"
        },
        {
          "name": "Conceptualization_of_Spatial_Relationships",
          "explanation": "Specifies how spatial relationships among features are defined.INVERSE_DISTANCE—Nearby neighboring features have a larger influence  on the  computations for a target feature than features that are far away.INVERSE_DISTANCE_SQUARED—Same as INVERSE_DISTANCE except that the slope is sharper, so influence drops off more quickly, and only a target feature's closest neighbors will exert substantial influence on  computations for that feature. FIXED_DISTANCE_BAND—Each feature is analyzed within the context of neighboring features.  Neighboring features inside the specified critical distance (Distance_Band_or_Threshold_Distance) receive a weight of one  and exert influence on computations for the target feature.  Neighboring features outside the critical distance receive a weight of zero and have no  influence on a target feature's computations. ZONE_OF_INDIFFERENCE—Features within the specified critical distance (Distance_Band_or_Threshold_Distance) of a target feature receive a weight of one and influence computations for that feature. Once the critical distance is exceeded, weights (and the influence a neighboring feature has on target feature computations) diminish with distance. K_NEAREST_NEIGHBORS—The closest k features are included in the analysis.  The number of neighbors (k) is specified by the number_of_neighbors parameter.CONTIGUITY_EDGES_ONLY—Only neighboring polygon features that share a boundary or overlap will influence computations for the target polygon feature.  CONTIGUITY_EDGES_CORNERS—Polygon features that share a boundary, share a node, or overlap will influence computations for the target polygon feature. GET_SPATIAL_WEIGHTS_FROM_FILE—Spatial relationships are defined by a specified spatial weights file. The path to the spatial weights file is specified by the Weights_Matrix_File parameter.",
          "datatype": "String"
        },
        {
          "name": "Distance_Method",
          "explanation": "Specifies how distances are calculated from each feature to neighboring features.EUCLIDEAN_DISTANCE—The straight-line distance between two points (as the crow flies) MANHATTAN_DISTANCE—The distance between two points measured along axes at right angles (city block); calculated by summing the (absolute) difference between the x- and y-coordinates",
          "datatype": "String"
        },
        {
          "name": "Standardization",
          "explanation": "Row standardization is recommended whenever the distribution of your features is potentially biased due to sampling design or an imposed aggregation scheme.NONE—No standardization of spatial weights is applied. ROW—Spatial weights are standardized; each weight is divided by its row sum (the sum of the weights of all neighboring features).",
          "datatype": "String"
        },
        {
          "name": "Distance_Band_or_Threshold_Distance(Optional)",
          "explanation": "Specifies a cutoff distance for Inverse Distance and Fixed Distance options. Features outside the specified cutoff for a target feature are ignored in analyses for that feature. However, for Zone of Indifference, the influence of features outside the given distance is reduced with distance, while those inside the distance threshold are equally considered. The distance value entered should match that of the output coordinate system.            For the Inverse Distance conceptualizations of spatial relationships, a value of 0 indicates that no threshold distance is applied; when this parameter is left blank, a default threshold value is computed and applied.    This default value is the Euclidean distance that ensures every feature has at least one neighbor.            This parameter has no effect when Polygon Contiguity or Get Spatial Weights From File spatial conceptualizations are selected.",
          "datatype": "Double"
        },
        {
          "name": "Weights_Matrix_File(Optional)",
          "explanation": "The path to a file containing weights that define spatial, and potentially temporal, relationships among features.",
          "datatype": "File"
        },
        {
          "name": "Apply_False_Discovery_Rate__FDR__Correction(Optional)",
          "explanation": "APPLY_FDR—Statistical significance will be based on the False Discovery Rate correction for a 95 percent confidence level.NO_FDR—Features with p-values less than 0.05 will appear in the COType field reflecting statistically significant clusters or outliers at a 95 percent confidence level (default).",
          "datatype": "Boolean"
        },
        {
          "name": "Number_of_Permutations(Optional)",
          "explanation": "The number of random permutations for the calculation of pseudo p-values. The default number of permutations is 499. \r\nIf you choose 0 permutations, the standard p-value is calculated.0—Permutations are not used and a standard p-value is calculated. 99—With 99 permutations, the smallest possible pseudo p-value is 0.01 and all other pseudo p-values will be multiples of this value.199—With 199 permutations, the smallest possible pseudo p-value is 0.005 and all other possible pseudo p-values will be multiples of this value.499—With 499 permutations, the smallest possible pseudo p-value is 0.002 and all other pseudo p-values will be multiples of this value.999—With 999 permutations, the smallest possible pseudo p-value is 0.001 and all other pseudo p-values will be multiples of this value.9999—With 9999 permutations, the smallest possible pseudo p-value is 0.0001 and all other pseudo p-values will be multiples of this value.",
          "datatype": "Long"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "The number of neighbors to include in the analysis.",
          "datatype": "Long"
        }
      ],
      "summary": "Identifies statistically significant hot spots, cold spots, and spatial outliers using the Anselin Local Moran's I statistic, given a set of weighted features. Learn more about how Cluster and Outlier Analysis (Anselin Local Moran's I) works",
      "extraction_date": "2025-10-01T15:18:10.596879"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Optimized Outlier Analysis",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/optimizedoutlieranalysis.htm",
      "parameters": [
        {
          "name": "Input_Features",
          "explanation": "The point or polygon feature class for which the cluster and outlier analysis will be performed.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Features",
          "explanation": "The output feature class to receive the result fields.",
          "datatype": "Feature Class"
        },
        {
          "name": "Analysis_Field(Optional)",
          "explanation": "The numeric field (number of incidents, crime rates, test scores, and so on) to be evaluated.",
          "datatype": "Field"
        },
        {
          "name": "Incident_Data_Aggregation_Method(Optional)",
          "explanation": "The aggregation method to use to create weighted features for analysis from incident point data.\r\nCOUNT_INCIDENTS_WITHIN_FISHNET_POLYGONS—A fishnet polygon mesh will overlay the incident point data  and the number of incidents within each polygon cell will be counted.  If no bounding polygon is provided in the Bounding_Polygons_Defining_Where_Incidents_Are_Possible parameter, only cells with at least one incident will be used in the analysis; otherwise, all cells within the bounding polygons will be analyzed. This is the default.COUNT_INCIDENTS_WITHIN_HEXAGON_POLYGONS—A hexagon polygon mesh will overlay the incident point data  and the number of incidents within each polygon cell will be counted.  If no bounding polygon is provided in the Bounding_Polygons_Defining_Where_Incidents_Are_Possible parameter, only cells with at least one incident will be used in the analysis; otherwise, all cells within the bounding polygons will be analyzed.COUNT_INCIDENTS_WITHIN_AGGREGATION_POLYGONS—You provide aggregation polygons to overlay the incident point data in the Polygons_For_Aggregating_Incidents_Into_Counts parameter.  The incidents within each polygon are counted.SNAP_NEARBY_INCIDENTS_TO_CREATE_WEIGHTED_POINTS—Nearby incidents will be aggregated together to create a single weighted point.  The weight for each point is the number of aggregated incidents at that location.",
          "datatype": "String"
        },
        {
          "name": "Bounding_Polygons_Defining_Where_Incidents_Are_Possible(Optional)",
          "explanation": "A polygon feature class defining where the incident Input_Features could possibly occur.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Polygons_For_Aggregating_Incidents_Into_Counts(Optional)",
          "explanation": "The polygons to use to aggregate the incident Input_Features in order to get an incident count for each polygon feature.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Performance_Adjustment(Optional)",
          "explanation": "This analysis utilizes permutations to create a reference distribution.  Choosing the number of permutations is a balance between precision and increased processing time. \r\nChoose your preference for speed versus precision.  More robust and precise results take longer to calculate.QUICK_199—With 199 permutations, the smallest possible pseudo p-value is 0.005 and all other pseudo p-values will be even multiples of this value.BALANCED_499—With 499 permutations, the smallest possible pseudo p-value is 0.002 and all other pseudo p-values will be even multiples of this value. This is the default.ROBUST_999—With 999 permutations, the smallest possible pseudo p-value is 0.001 and all other pseudo p-values will be even multiples of this value.",
          "datatype": "String"
        },
        {
          "name": "Cell_Size(Optional)",
          "explanation": "The size of the grid cells used to aggregate the Input_Features.  When aggregating into a hexagon grid, this distance is used as the height to construct the hexagon polygons.",
          "datatype": "Linear Unit"
        },
        {
          "name": "Distance_Band(Optional)",
          "explanation": "The spatial extent of the analysis neighborhood.  This value determines which features are analyzed together in order to assess local clustering.",
          "datatype": "Linear Unit"
        }
      ],
      "summary": "Given incident points or weighted features (points or polygons), creates a map of statistically significant hot spots, cold spots, and spatial outliers using the Anselin Local Moran's I statistic. It evaluates the characteristics of the input feature class to produce optimal results. Learn more about how Optimized Outlier Analysis works",
      "extraction_date": "2025-10-01T15:18:14.260556"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Generalized Linear Regression",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/generalized-linear-regression.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The feature class containing the dependent and independent variables.",
          "datatype": "Feature Layer"
        },
        {
          "name": "dependent_variable",
          "explanation": "The numeric field containing the observed values to be modeled.",
          "datatype": "Field"
        },
        {
          "name": "model_type",
          "explanation": "Specifies the  type of data that will be modeled.CONTINUOUS— The dependent_variable value is continuous.  The model used is Gaussian, and the tool performs  ordinary least squares regression.BINARY— The dependent_variable value represents presence or absence. This can be either conventional 1s and 0s, or continuous data that has been recoded based on a threshold value. The model used is Logistic Regression.COUNT—The dependent_variable value is discrete and represents events—for example, crime counts,   disease incidents, or traffic accidents. The model used is Poisson regression.",
          "datatype": "String"
        },
        {
          "name": "output_features",
          "explanation": "The new feature class that will contain the dependent variable estimates and residuals.",
          "datatype": "Feature Class"
        },
        {
          "name": "explanatory_variables[explanatory_variables,...]",
          "explanation": "A list of fields representing independent explanatory variables in the regression model.",
          "datatype": "Field"
        },
        {
          "name": "distance_features[distance_features,...](Optional)",
          "explanation": "Automatically creates explanatory variables by calculating a distance from the provided features to the in_features values. Distances will be calculated from each of the input distance_features values to the nearest in_features value. If the input distance_features values are polygons or lines, the distance attributes will be calculated as the distance between the closest segments of the pair of features.",
          "datatype": "Feature Layer"
        },
        {
          "name": "prediction_locations(Optional)",
          "explanation": "A feature class containing features representing locations where estimates will be computed. Each feature in this dataset should contain values for all  the explanatory variables specified. The dependent variable for these features will be estimated using the model calibrated for the input feature class data.",
          "datatype": "Feature Layer"
        },
        {
          "name": "explanatory_variables_to_match[[Field from Prediction Locations, Field from Input Features],...](Optional)",
          "explanation": "Matches the explanatory variables in the prediction_locations parameter to corresponding explanatory variables from the in_features parameter.",
          "datatype": "Value Table"
        },
        {
          "name": "explanatory_distance_matching[[Prediction Distance Features, Input Explanatory Distance Features],...](Optional)",
          "explanation": "Matches the distance features specified for the features_to_predict parameter on the left to the corresponding distance features for the in_features parameter on the right.",
          "datatype": "Value Table"
        },
        {
          "name": "output_predicted_features(Optional)",
          "explanation": "The output feature class that will receive dependent variable estimates for each prediction_location value.\r\n The output feature class that will receive dependent variable estimates for each Prediction Location value.",
          "datatype": "Feature Class"
        },
        {
          "name": "output_trained_model(Optional)",
          "explanation": "An output model file that will save the trained model, which can be used later for prediction.",
          "datatype": "File"
        }
      ],
      "summary": "Performs generalized linear regression (GLR) to generate predictions or to model a dependent variable in terms of its relationship to a set of explanatory variables.  This tool can be used to fit continuous (OLS), binary (logistic), and count (Poisson) models. Learn more about how Generalized Linear Regression works",
      "extraction_date": "2025-10-01T15:18:17.669572"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Spatial Autocorrelation (Global Moran's I)",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/spatial-autocorrelation.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class for which spatial autocorrelation will be calculated.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Input_Field",
          "explanation": "The numeric field that will be used in assessing spatial autocorrelation.",
          "datatype": "Field"
        },
        {
          "name": "Generate_Report(Optional)",
          "explanation": "Specifies whether a graphical summary of result will be created as an .html file.\r\nNO_REPORT—No graphical summary will be created. This is the default.GENERATE_REPORT—A graphical summary will be created.",
          "datatype": "Boolean"
        },
        {
          "name": "Conceptualization_of_Spatial_Relationships",
          "explanation": "Specifies how spatial relationships among features will be defined.INVERSE_DISTANCE—Nearby neighboring features have a larger influence  on the  computations for a target feature than features that are far away.INVERSE_DISTANCE_SQUARED—This is the same as the INVERSE_DISTANCE option except that the slope is sharper, so influence drops off more quickly, and only a target feature's closest neighbors will exert substantial influence on  computations for that feature. FIXED_DISTANCE_BAND—Each feature is analyzed within the context of neighboring features.  Neighboring features within the specified critical distance (Distance_Band_or_Threshold value) receive a weight of one  and exert influence on computations for the target feature.  Neighboring features outside the critical distance receive a weight of zero and have no  influence on a target feature's computations. ZONE_OF_INDIFFERENCE—Features within the specified critical distance (Distance_Band_or_Threshold value) of a target feature receive a weight of one and influence computations for that feature. Once the critical distance is exceeded, weights (and the influence a neighboring feature has on target feature computations) diminish with distance. K_NEAREST_NEIGHBORS—The closest k features are included in the analysis.  The number of neighbors (k) to include in the analysis is specified by the number_of_neighbors parameter.CONTIGUITY_EDGES_ONLY—Only neighboring polygon features that share a boundary or overlap will influence computations for the target polygon feature.  CONTIGUITY_EDGES_CORNERS—Polygon features that share a boundary, share a node, or overlap will influence computations for the target polygon feature. GET_SPATIAL_WEIGHTS_FROM_FILE—Spatial relationships are defined by a specified spatial weights file. The path to the spatial weights file is specified by the Weights_Matrix_File parameter.",
          "datatype": "String"
        },
        {
          "name": "Distance_Method",
          "explanation": "Specifies how distances will be calculated from each feature to neighboring features.EUCLIDEAN_DISTANCE—The straight-line distance between two points (as the crow flies) will be used. This is the default.MANHATTAN_DISTANCE—The distance between two points measured along axes at right angles (city block) will be used. This is calculated by summing the (absolute) difference between the x- and y-coordinates",
          "datatype": "String"
        },
        {
          "name": "Standardization",
          "explanation": "Specifies whether standardization of spatial weights will be applied. Row standardization is recommended whenever the distribution of features is potentially biased due to sampling design or an imposed aggregation scheme.NONE—No standardization of spatial weights will be applied. ROW—Spatial weights will be standardized; each weight will be divided by its row sum (the sum of the weights of all neighboring features). This is the default.",
          "datatype": "String"
        },
        {
          "name": "Distance_Band_or_Threshold_Distance(Optional)",
          "explanation": "The cutoff distance for the various inverse distance and fixed distance options. Features outside the specified cutoff for a target feature are ignored in analyses for that feature. However, for ZONE_OF_INDIFFERENCE, the influence of features outside the given distance is reduced with distance, while those within the distance threshold are equally considered. The distance value provided should match that of the output coordinate system.For the inverse distance conceptualizations of spatial relationships, a value of 0 indicates that no threshold distance is applied; when this parameter is left blank, a default threshold value is computed and applied.    The default value is the Euclidean distance, which ensures that every feature has at least one neighbor.This parameter has no effect when polygon contiguity  (CONTIGUITY_EDGES_ONLY or CONTIGUITY_EDGES_CORNERS) or GET_SPATIAL_WEIGHTS_FROM_FILE spatial conceptualization is specified.",
          "datatype": "Double"
        },
        {
          "name": "Weights_Matrix_File(Optional)",
          "explanation": "The path to a file containing weights that define spatial, and potentially temporal, relationships among features.",
          "datatype": "File"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "An integer specifying the number of neighbors that will be included in the analysis.",
          "datatype": "Long"
        }
      ],
      "summary": "Measures spatial autocorrelation based on feature locations and attribute values using the Global Moran's I statistic. Learn more about how Spatial Autocorrelation (Global Moran's I) works",
      "extraction_date": "2025-10-01T15:18:22.221359"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Calculate Composite Index",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/calculate-composite-index.htm",
      "parameters": [
        {
          "name": "in_table",
          "explanation": "The table or features containing the variables that will be combined into the index.",
          "datatype": "Table View"
        },
        {
          "name": "in_variables[[var1, reverse1],[var2, reverse2],...]",
          "explanation": "A list of numeric fields representing the variables that will be combined as an index. The Reverse Direction column reverses the values of the variables. This means that the feature or record that originally had the highest value will have the lowest value, and vice versa. Values will be reversed after scaling.",
          "datatype": "Value Table"
        },
        {
          "name": "append_to_input(Optional)",
          "explanation": "Specifies whether the results will be appended to the input data or provided as an output feature class or table.APPEND_TO_INPUT— The results will be appended to the input data. This option modifies the input data.NEW_FEATURES— An output feature class or table will be created containing the results. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "out_table(Optional)",
          "explanation": "The output features or table that will include the results.",
          "datatype": "Table; Feature Class"
        },
        {
          "name": "index_preset(Optional)",
          "explanation": "Specifies the workflow that will be used when creating the index. The options represent common index creation workflows; each option sets default values for the preprocessing and index_method parameters.MEAN_SCALED—An index will be created by scaling the input variables between 0 and 1 and averaging the scaled values. This method is useful for creating an index that is easy to interpret. The shape of the distribution and outliers in the input variables will impact the index. This is the default.MEAN_PCTL—An index will be created by scaling the ranks of the input variables between 0 and 1 and averaging the scaled ranks. This option is useful when the rankings of the variable values are more important than the differences between values. The shape of the distribution and outliers in the input variables will not impact the index.GEOMEAN_SCALED—An index will be created by scaling the input variables between 0 and 1 and calculating the geometric average of the scaled values. High values will not cancel low values, so this option is useful for creating an index in which higher index values will occur only when there are high values in multiple variables.SUM_FLAGSPCTL—An index will be created that counts the number of input variables with values greater than or equal to the 90th percentile. This method is useful for identifying locations that may be considered the most extreme or the most in need.CUSTOM—An index will be created using customized variable scaling and combination options.",
          "datatype": "String"
        },
        {
          "name": "preprocessing(Optional)",
          "explanation": "Specifies the method that will be used to convert \r\nthe input variables to a common scale.MINMAX— Variables will be scaled between 0 and 1 using the minimum and maximum values of each variable. This is the default.CUST_MINMAX— Variables will be scaled between 0 and 1 using the possible minimum and possible maximum values for each variable, specified by the pre_min_max parameter. This method has many uses, including specifying the minimum and maximum based on a benchmark, on a reference statistic, or on theoretical values. For example, if ozone recordings for a single day range between 5 and 27 parts per million (ppm), you can use the theoretical minimum and maximum based on prior observation and domain expertise to ensure that the index can be compared across multiple daysPERCENTILE—Variables will be converted to percentiles between 0 and 1 by calculating the percent of data values less than the data value. This option is useful when you want to ignore absolute differences between the data values, such as with outliers or skewed distributions.RANK—Variables will be ranked.  The smallest value is assigned rank value 1, the next value is assigned rank value 2, and so on.  Ties are assigned the average of their ranks.ZSCORE—Each variable will be standardized by subtracting the mean value and dividing by the standard deviation (called a z-score). The z-score is the number of standard deviations above or below the mean value. This option is useful when the means of the variables are important comparison points. Values above the mean will receive positive z-scores, and values below the mean will receive negative z-scores.CUST_ZSCORE—Each variable will be standardized by subtracting a custom mean value and dividing by a custom standard deviation. Provide the custom values in the pre_custom_zscore parameter. This option is useful when the means and standard deviations of the variables are known from previous research.BINARY—Variables will be identified when they are above or below a defined threshold. The resulting field contains binary (0 or 1) values indicating whether the threshold was exceeded. You can also use the pre_threshold_scaling parameter to scale the input variable values before defining the threshold, and use the pre_thresholds parameter to specify the threshold values. This method is useful when the values of the variables are less important than whether they exceed a particular threshold, such as a safety limit of a pollutant.RAW—The original values of the variables will be used. Use this method only when all variables are measured on a comparable scale, such as percentages or rates, or when the variables have been standardized before using this tool.",
          "datatype": "String"
        },
        {
          "name": "pre_threshold_scaling(Optional)",
          "explanation": "Specifies the method that will be used to convert the input variables to a common scale prior to setting thresholds.\r\nTHRESHOLD_MINMAX—Variables between 0 and 1 will be scaled using the minimum and maximum values of each variable.THRESHOLD_CUST_MINMAX—Variables between 0 and 1 will be scaled using the possible minimum and possible maximum values for each variable.THRESHOLD_PERCENTILE—Variables will be converted to percentiles between 0 and 1. THRESHOLD_ZSCORE—Each variable will be standardized by subtracting the mean value and dividing by the standard deviation.THRESHOLD_CUST_ZSCORE—Each variable will be standardized by subtracting a custom mean value and dividing by a custom standard deviation.THRESHOLD_RAW— The values of the variables will be used without change. This is the default.",
          "datatype": "String"
        },
        {
          "name": "pre_custom_zscore[[field1, mean1, stdev1], [field2, mean2, stdev2],...](Optional)",
          "explanation": "The custom mean value and custom standard deviation that will be used when standardizing each input variable. For each variable, provide the custom mean in the Mean column and the custom standard deviation in the Standard Deviation column.",
          "datatype": "Value Table"
        },
        {
          "name": "pre_min_max[[field1, min1, max1], [field2, min2, max2],...](Optional)",
          "explanation": "The possible minimum and maximum values that will be used in the units of the variables. Each variable will be scaled between 0 and 1 based on the possible minimum and maximum values.",
          "datatype": "Value Table"
        },
        {
          "name": "pre_thresholds[[field1, method1, threshold1], [field2, method2, threshold2],...](Optional)",
          "explanation": "The threshold that determines whether a feature will be flagged. Specify the value in the units of the scaled variables and specify whether values above or below the threshold value will be flagged.",
          "datatype": "Value Table"
        },
        {
          "name": "index_method(Optional)",
          "explanation": "Specifies the method that will be used to combine the scaled variables into a single value.\r\nSUM—The values will be added.MEAN—The arithmetic (additive) mean of the values will be calculated. This is the default.PRODUCT—The values will be multiplied. All scaled values must be greater than or equal to zero.GEOMETRIC_MEAN—The geometric (multiplicative) mean of the values will be calculated. All scaled values must be greater than or equal to zero.You cannot multiply or calculate a geometric mean when any variables are scaled using z-scores, because z-scores always contain negative values.",
          "datatype": "String"
        },
        {
          "name": "index_weights[[field1, weight1], [field2, weight2],...](Optional)",
          "explanation": "The weights that will set the relative influence of each input variable on the index.\r\n Each weight has a default value of 1, meaning that each variable has equal contribution. Increase or decrease the weights to reflect the relative importance of the variables. For example, if a variable is twice as important as another, use a weight value of 2. Using weight values larger than 1 while multiplying to combine scaled values can result in indices with very large values.",
          "datatype": "Value Table"
        },
        {
          "name": "out_index_name(Optional)",
          "explanation": "The name of the index. The value is used in the visualization of the outputs, such as field aliases and chart labels. The value is not used when the output (or appended input) is a shapefile.",
          "datatype": "String"
        },
        {
          "name": "out_index_reverse(Optional)",
          "explanation": "Specifies whether the output index values will be reversed in direction (for example, to treat high index values as low values).REVERSE— The index values will be reversed in direction.NO_REVERSE— The index values will not be reversed in direction. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "post_min_max[min, max](Optional)",
          "explanation": "The minimum and maximum of the output index values. This scaling is applied after combining the scaled variables. If no values are provided, the output index is not scaled.",
          "datatype": "Value Table"
        },
        {
          "name": "post_reclass[post_reclass,...](Optional)",
          "explanation": "Specifies the method that will be used to classify the output index. An additional output field will be provided for each selected option.EQINTERVAL—Classes will be created by dividing the range of values into equally sized intervalsQUANTILE—Classes will be created in which each class includes an equal number of records.STDDEV—Classes will be created corresponding to the number of standard deviations above and below the average of the index. The resulting values will be between -3 and 3.CUST—Class breaks and class values will be specified using the post_custom_classes parameter.",
          "datatype": "String"
        },
        {
          "name": "post_num_classes(Optional)",
          "explanation": "The number of classes that will be used for the equal interval and quantile classification methods.",
          "datatype": "Long"
        },
        {
          "name": "post_custom_classes[[min1, max1], [min2, max2],...](Optional)",
          "explanation": "The upper bounds and class values\r\nfor the custom classification method. For example, you can use this variable to classify an index containing values between 0 and 100 into classes representing low, medium, and high values based on custom break values.",
          "datatype": "Value Table"
        }
      ],
      "summary": "Combines multiple numeric variables to create a single index. Composite indices are used across social and environmental domains to represent complex information from multiple indicators as a single metric that can measure progress toward a goal and facilitate decisions. The tool supports the three main steps of the index creation process: standardize input variables to a common scale (preprocessing), combine variables to a single index variable (combination), and scale and classify the resulting index to meaningful values (postprocessing). Learn more about how Calculate Composite Index works",
      "extraction_date": "2025-10-01T15:18:25.494415"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Assess Sensitivity to Attribute Uncertainty",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/assess-sensitivity-to-attribute-uncertainty.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "A feature class containing the output analysis result from a spatial statistics tool. Only certain tools are supported. This is the analysis result that will be evaluated for stability.",
          "datatype": "Feature Layer"
        },
        {
          "name": "out_features",
          "explanation": "The output features that will contain a copy of the original analysis results and fields summarizing the stability of the analysis for each feature.",
          "datatype": "Feature Class"
        },
        {
          "name": "out_simulation_table",
          "explanation": "The output table that will contain fields summarizing the stability of the analysis.",
          "datatype": "Table"
        },
        {
          "name": "analysis_input_features(Optional)",
          "explanation": "The input features that were used in the analysis that produced the analysis result features.",
          "datatype": "Feature Layer"
        },
        {
          "name": "uncertainty_measure(Optional)",
          "explanation": "Specifies how attribute uncertainty will be measured.MOE—The input feature class of the original analysis contains a field with the symmetrical margin of error for each feature and that will be used.CONFIDENCE_BOUNDS—The input feature class of the original analysis contains a field with the lower bounds and upper bounds for each feature and that will be used. The bounds may be asymmetric with respect to a feature's analysis variable value.PERCENTAGE—The analysis variable will be adjusted by the percentage specified by the randomize_pct parameter.",
          "datatype": "String"
        },
        {
          "name": "moe_field[moe_field,...](Optional)",
          "explanation": "The field containing the margin of error (MOE) of the analysis variable. The MOE is used to construct a symmetric distribution from which the simulated values will be generated.",
          "datatype": "Value Table"
        },
        {
          "name": "confidence_bound_field[confidence_bound_field,...](Optional)",
          "explanation": "The fields containing the lower and upper bounds for the analysis variable. Values will be generated between the lower and upper confidence bounds.",
          "datatype": "Value Table"
        },
        {
          "name": "randomize_pct[randomize_pct,...](Optional)",
          "explanation": "The percentage of the original attribute value that will be subtracted and added to the original value of the analysis variable to create a range of values for the simulations.",
          "datatype": "Value Table"
        },
        {
          "name": "num_simulations(Optional)",
          "explanation": "The number of simulations that will be performed.",
          "datatype": "Long"
        },
        {
          "name": "simulation_method(Optional)",
          "explanation": "Specifies the probability distribution that will be used to simulate data.\r\nNORMAL—A normal distribution will be used. This is the default.UNIFORM—A uniform distribution will be used.TRIANGULAR—A triangular distribution will be used.",
          "datatype": "String"
        },
        {
          "name": "output_workspace(Optional)",
          "explanation": "An existing workspace where the analysis results from each simulation will be stored. The workspace can be a folder or a geodatabase.",
          "datatype": "Workspace"
        },
        {
          "name": "sim_data_limits[sim_data_limits,...](Optional)",
          "explanation": "The lower and upper limits for the simulated values. All simulated values will be within these limits. For example, for counts or percentages, use a lower limit of zero to ensure that there are no negative counts or percentages.",
          "datatype": "Value Table"
        },
        {
          "name": "moe_conf_level(Optional)",
          "explanation": "The confidence level of the margins of error. For example, if the margins of error were created from 95 percent confidence intervals, provide a value of 95.",
          "datatype": "Long"
        }
      ],
      "summary": "Measures the stability of an analysis result by comparing the original analysis output to the results from multiple tool runs using simulated data. The simulated data accounts for uncertainty in one or more analysis variables. Three types of attribute uncertainty are supported: margin of error, confidence bounds, and a percentage of the original attribute value. Learn more about how Assess Sensitivity to Attribute Uncertainty Works",
      "extraction_date": "2025-10-01T15:18:28.378453"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Build Balanced Zones",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/buildbalancedzones.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The feature class or feature layer that will be aggregated into zones.",
          "datatype": "Feature Layer"
        },
        {
          "name": "output_features",
          "explanation": "The output feature class indicating which features are aggregated into each zone. The feature class will be symbolized by the ZONE_ID field and will contain fields displaying the values of each criteria that you specify.",
          "datatype": "Feature Class"
        },
        {
          "name": "zone_creation_method",
          "explanation": "Specifies the method that will be used to create each zone. Zones grow until all specified criteria are satisfied.ATTRIBUTE_TARGET—Zones will be created based on target values of one or multiple variables. The sum of each attribute must be specified in the Zone Building Criteria With Target parameter, and each zone will grow until the sum of the attributes exceeds these values.  For example, you can use this option to create zones that each have at least 100,000 residents and 20,000 family homes.NUMBER_ZONES_AND_ATTRIBUTE—A  specified number of zones will be created while keeping the sum of an attribute approximately equal within each zone.   The number of zones must be specified in the Target Number of Zones parameter. The attribute sum within each zone is equal to the sum of the total attribute divided by the number of zones.NUMBER_OF_ZONES—A specified number of zones will be created that are each composed of approximately the same number of input features. The number of zones must be specified in the Target Number of Zones parameter.",
          "datatype": "String"
        },
        {
          "name": "number_of_zones(Optional)",
          "explanation": "The number of zones that will be created.",
          "datatype": "Long"
        },
        {
          "name": "zone_building_criteria_target[[variable, sum, weight],...](Optional)",
          "explanation": "Specifies the variables that will be considered, as well as their target values and optional weights. The default weight is 1, and each variable contributes equally unless they are changed.",
          "datatype": "Value Table"
        },
        {
          "name": "zone_building_criteria[[variable, weight],...](Optional)",
          "explanation": "Specifies the variables that will be considered and, optionally, their weights. The default weight is 1, and each variable contributes equally unless changed.",
          "datatype": "Value Table"
        },
        {
          "name": "spatial_constraints(Optional)",
          "explanation": "Specifies how neighbors will be defined while the zones grow. Zones can only grow into new features that are neighbors of at least one of the features already in the zone. If the input features are polygons, the default spatial constraint is Contiguity edges corners.  If the input features are points, the default spatial constraint is Trimmed Delaunay triangulation.CONTIGUITY_EDGES_ONLY—For zones containing contiguous polygon features, only polygons that share an edge will be part of the same zone. CONTIGUITY_EDGES_CORNERS— For zones containing contiguous polygon features, only polygons that share an edge or a vertex will be part of the same zone.TRIMMED_DELAUNAY_TRIANGULATION— Features in the same zone will have at least one natural neighbor in common with another feature in the zone. Natural neighbor relationships are based on a trimmed Delaunay Triangulation. Conceptually, Delaunay Triangulation creates a nonoverlapping mesh of triangles from feature centroids. Each feature is a triangle node, and nodes that share edges are considered neighbors. These triangles are then clipped to a convex hull to ensure that features cannot be neighbors with any features outside of the convex hull. This is the default.GET_SPATIAL_WEIGHTS_FROM_FILE— Spatial, and, optionally, temporal relationships will be defined by a specified spatial weights file\r\n(.swm). Create the spatial weights matrix using the Generate\r\nSpatial Weights Matrix tool or the Generate Network Spatial Weights tool. The path to the spatial weights file is specified by\r\nthe Spatial Weights Matrix File parameter.",
          "datatype": "String"
        },
        {
          "name": "weights_matrix_file(Optional)",
          "explanation": "The path to a file containing spatial weights that define spatial and, optionally, temporal relationships among features.",
          "datatype": "File"
        },
        {
          "name": "zone_characteristics[zone_characteristics,...](Optional)",
          "explanation": "Specifies the characteristics of the zones that will be created.EQUAL_AREA— Zones with total area as similar as possible will be created.COMPACTNESS—Zones with more closely-packed (compact) features will be created.EQUAL_NUMBER_OF_FEATURES—Zones with an equal number of features will be created.",
          "datatype": "String"
        },
        {
          "name": "attribute_to_consider[[variable, function],...](Optional)",
          "explanation": "Specifies attributes and statistics to consider in the selection of final zones. You can homogenize attributes based on their sum, average, median, or variance. For example, if you are creating zones based on home values and want to balance the average total income within each zone, the solution with the most equal average income across zones will be preferred.",
          "datatype": "Value Table"
        },
        {
          "name": "distance_to_consider[distance_to_consider,...](Optional)",
          "explanation": "The feature class that will be used to homogenize the total distance per zone. The distance is calculated from each of the input features to the closest feature provided in this parameter. This distance is then used as an additional attribute constraint when selecting the final zone solution. For example, you can create police patrol districts that are each approximately the same distance from the closest police station.",
          "datatype": "Feature Layer"
        },
        {
          "name": "categorial_variable(Optional)",
          "explanation": "The categorical variable to be considered for zone proportions.",
          "datatype": "Field"
        },
        {
          "name": "proportion_method(Optional)",
          "explanation": "Specifies the type of proportion that will be maintained based on the chosen categorical variable.MAINTAIN_WITHIN_PROPORTION—Each zone will maintain the same proportions as the overall study area for the given categorical variable. For example, given a categorical variable that is 60% Type A and 40% Type B, this method will prefer zones that are composed of approximately 60% Type A features and 40% Type B features.MAINTAIN_OVERALL_PROPORTION—Zones will be created so that the overall proportions of category predominance by zone matches the proportions of the given categorical variable for the entire dataset. For example, given a categorical variable that is 60% Type A and 40% Type B, this method will prefer solutions where 60% of the zones are predominantly Type A features and 40% of the zones are predominantly Type B features.",
          "datatype": "String"
        },
        {
          "name": "population_size(Optional)",
          "explanation": "The number of randomly generated initial seeds. For larger datasets, increasing this number will increase the search space and the probability of finding a better solution. The default is 100.",
          "datatype": "Long"
        },
        {
          "name": "number_generations(Optional)",
          "explanation": "The number of times the zone search process will be repeated. For larger datasets, increasing the number is recommended to find an optimal solution. The default is 50 generations.",
          "datatype": "Long"
        },
        {
          "name": "mutation_factor(Optional)",
          "explanation": "The probability that an individual's seed values will be mutated to a new set of seeds. Mutation increases the search space by introducing variability of the possible solutions in every generation and allows for faster convergence to an optimal solution. The default is 0.1.",
          "datatype": "Double"
        },
        {
          "name": "output_convergence_table(Optional)",
          "explanation": "The table containing the total fitness score for the best solution found in every generation as well as the fitness score for the individual zone constraints.",
          "datatype": "Table"
        }
      ],
      "summary": "Creates spatially contiguous zones in a study area using a genetic growth algorithm based on specified criteria. You can create zones that contain an equal number of features, zones that are similar based on a set of attribute values, or both. You can also select zones with approximately equal areas, that are as compact as possible, and that maintain consistent summary statistics of other variables. Learn more about how Build Balanced Zones works",
      "extraction_date": "2025-10-01T15:18:33.059043"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Calculate Composite Index",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/calculate-composite-index.htm",
      "parameters": [
        {
          "name": "in_table",
          "explanation": "The table or features containing the variables that will be combined into the index.",
          "datatype": "Table View"
        },
        {
          "name": "in_variables[[var1, reverse1],[var2, reverse2],...]",
          "explanation": "A list of numeric fields representing the variables that will be combined as an index. The Reverse Direction column reverses the values of the variables. This means that the feature or record that originally had the highest value will have the lowest value, and vice versa. Values will be reversed after scaling.",
          "datatype": "Value Table"
        },
        {
          "name": "append_to_input(Optional)",
          "explanation": "Specifies whether the results will be appended to the input data or provided as an output feature class or table.APPEND_TO_INPUT— The results will be appended to the input data. This option modifies the input data.NEW_FEATURES— An output feature class or table will be created containing the results. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "out_table(Optional)",
          "explanation": "The output features or table that will include the results.",
          "datatype": "Table; Feature Class"
        },
        {
          "name": "index_preset(Optional)",
          "explanation": "Specifies the workflow that will be used when creating the index. The options represent common index creation workflows; each option sets default values for the preprocessing and index_method parameters.MEAN_SCALED—An index will be created by scaling the input variables between 0 and 1 and averaging the scaled values. This method is useful for creating an index that is easy to interpret. The shape of the distribution and outliers in the input variables will impact the index. This is the default.MEAN_PCTL—An index will be created by scaling the ranks of the input variables between 0 and 1 and averaging the scaled ranks. This option is useful when the rankings of the variable values are more important than the differences between values. The shape of the distribution and outliers in the input variables will not impact the index.GEOMEAN_SCALED—An index will be created by scaling the input variables between 0 and 1 and calculating the geometric average of the scaled values. High values will not cancel low values, so this option is useful for creating an index in which higher index values will occur only when there are high values in multiple variables.SUM_FLAGSPCTL—An index will be created that counts the number of input variables with values greater than or equal to the 90th percentile. This method is useful for identifying locations that may be considered the most extreme or the most in need.CUSTOM—An index will be created using customized variable scaling and combination options.",
          "datatype": "String"
        },
        {
          "name": "preprocessing(Optional)",
          "explanation": "Specifies the method that will be used to convert \r\nthe input variables to a common scale.MINMAX— Variables will be scaled between 0 and 1 using the minimum and maximum values of each variable. This is the default.CUST_MINMAX— Variables will be scaled between 0 and 1 using the possible minimum and possible maximum values for each variable, specified by the pre_min_max parameter. This method has many uses, including specifying the minimum and maximum based on a benchmark, on a reference statistic, or on theoretical values. For example, if ozone recordings for a single day range between 5 and 27 parts per million (ppm), you can use the theoretical minimum and maximum based on prior observation and domain expertise to ensure that the index can be compared across multiple daysPERCENTILE—Variables will be converted to percentiles between 0 and 1 by calculating the percent of data values less than the data value. This option is useful when you want to ignore absolute differences between the data values, such as with outliers or skewed distributions.RANK—Variables will be ranked.  The smallest value is assigned rank value 1, the next value is assigned rank value 2, and so on.  Ties are assigned the average of their ranks.ZSCORE—Each variable will be standardized by subtracting the mean value and dividing by the standard deviation (called a z-score). The z-score is the number of standard deviations above or below the mean value. This option is useful when the means of the variables are important comparison points. Values above the mean will receive positive z-scores, and values below the mean will receive negative z-scores.CUST_ZSCORE—Each variable will be standardized by subtracting a custom mean value and dividing by a custom standard deviation. Provide the custom values in the pre_custom_zscore parameter. This option is useful when the means and standard deviations of the variables are known from previous research.BINARY—Variables will be identified when they are above or below a defined threshold. The resulting field contains binary (0 or 1) values indicating whether the threshold was exceeded. You can also use the pre_threshold_scaling parameter to scale the input variable values before defining the threshold, and use the pre_thresholds parameter to specify the threshold values. This method is useful when the values of the variables are less important than whether they exceed a particular threshold, such as a safety limit of a pollutant.RAW—The original values of the variables will be used. Use this method only when all variables are measured on a comparable scale, such as percentages or rates, or when the variables have been standardized before using this tool.",
          "datatype": "String"
        },
        {
          "name": "pre_threshold_scaling(Optional)",
          "explanation": "Specifies the method that will be used to convert the input variables to a common scale prior to setting thresholds.\r\nTHRESHOLD_MINMAX—Variables between 0 and 1 will be scaled using the minimum and maximum values of each variable.THRESHOLD_CUST_MINMAX—Variables between 0 and 1 will be scaled using the possible minimum and possible maximum values for each variable.THRESHOLD_PERCENTILE—Variables will be converted to percentiles between 0 and 1. THRESHOLD_ZSCORE—Each variable will be standardized by subtracting the mean value and dividing by the standard deviation.THRESHOLD_CUST_ZSCORE—Each variable will be standardized by subtracting a custom mean value and dividing by a custom standard deviation.THRESHOLD_RAW— The values of the variables will be used without change. This is the default.",
          "datatype": "String"
        },
        {
          "name": "pre_custom_zscore[[field1, mean1, stdev1], [field2, mean2, stdev2],...](Optional)",
          "explanation": "The custom mean value and custom standard deviation that will be used when standardizing each input variable. For each variable, provide the custom mean in the Mean column and the custom standard deviation in the Standard Deviation column.",
          "datatype": "Value Table"
        },
        {
          "name": "pre_min_max[[field1, min1, max1], [field2, min2, max2],...](Optional)",
          "explanation": "The possible minimum and maximum values that will be used in the units of the variables. Each variable will be scaled between 0 and 1 based on the possible minimum and maximum values.",
          "datatype": "Value Table"
        },
        {
          "name": "pre_thresholds[[field1, method1, threshold1], [field2, method2, threshold2],...](Optional)",
          "explanation": "The threshold that determines whether a feature will be flagged. Specify the value in the units of the scaled variables and specify whether values above or below the threshold value will be flagged.",
          "datatype": "Value Table"
        },
        {
          "name": "index_method(Optional)",
          "explanation": "Specifies the method that will be used to combine the scaled variables into a single value.\r\nSUM—The values will be added.MEAN—The arithmetic (additive) mean of the values will be calculated. This is the default.PRODUCT—The values will be multiplied. All scaled values must be greater than or equal to zero.GEOMETRIC_MEAN—The geometric (multiplicative) mean of the values will be calculated. All scaled values must be greater than or equal to zero.You cannot multiply or calculate a geometric mean when any variables are scaled using z-scores, because z-scores always contain negative values.",
          "datatype": "String"
        },
        {
          "name": "index_weights[[field1, weight1], [field2, weight2],...](Optional)",
          "explanation": "The weights that will set the relative influence of each input variable on the index.\r\n Each weight has a default value of 1, meaning that each variable has equal contribution. Increase or decrease the weights to reflect the relative importance of the variables. For example, if a variable is twice as important as another, use a weight value of 2. Using weight values larger than 1 while multiplying to combine scaled values can result in indices with very large values.",
          "datatype": "Value Table"
        },
        {
          "name": "out_index_name(Optional)",
          "explanation": "The name of the index. The value is used in the visualization of the outputs, such as field aliases and chart labels. The value is not used when the output (or appended input) is a shapefile.",
          "datatype": "String"
        },
        {
          "name": "out_index_reverse(Optional)",
          "explanation": "Specifies whether the output index values will be reversed in direction (for example, to treat high index values as low values).REVERSE— The index values will be reversed in direction.NO_REVERSE— The index values will not be reversed in direction. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "post_min_max[min, max](Optional)",
          "explanation": "The minimum and maximum of the output index values. This scaling is applied after combining the scaled variables. If no values are provided, the output index is not scaled.",
          "datatype": "Value Table"
        },
        {
          "name": "post_reclass[post_reclass,...](Optional)",
          "explanation": "Specifies the method that will be used to classify the output index. An additional output field will be provided for each selected option.EQINTERVAL—Classes will be created by dividing the range of values into equally sized intervalsQUANTILE—Classes will be created in which each class includes an equal number of records.STDDEV—Classes will be created corresponding to the number of standard deviations above and below the average of the index. The resulting values will be between -3 and 3.CUST—Class breaks and class values will be specified using the post_custom_classes parameter.",
          "datatype": "String"
        },
        {
          "name": "post_num_classes(Optional)",
          "explanation": "The number of classes that will be used for the equal interval and quantile classification methods.",
          "datatype": "Long"
        },
        {
          "name": "post_custom_classes[[min1, max1], [min2, max2],...](Optional)",
          "explanation": "The upper bounds and class values\r\nfor the custom classification method. For example, you can use this variable to classify an index containing values between 0 and 100 into classes representing low, medium, and high values based on custom break values.",
          "datatype": "Value Table"
        }
      ],
      "summary": "Combines multiple numeric variables to create a single index. Composite indices are used across social and environmental domains to represent complex information from multiple indicators as a single metric that can measure progress toward a goal and facilitate decisions. The tool supports the three main steps of the index creation process: standardize input variables to a common scale (preprocessing), combine variables to a single index variable (combination), and scale and classify the resulting index to meaningful values (postprocessing). Learn more about how Calculate Composite Index works",
      "extraction_date": "2025-10-01T15:18:37.041511"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Cluster and Outlier Analysis (Anselin Local Moran's I)",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/cluster-and-outlier-analysis-anselin-local-moran-s.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class for which cluster and outlier analysis will be performed.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Input_Field",
          "explanation": "The numeric field to be evaluated.",
          "datatype": "Field"
        },
        {
          "name": "Output_Feature_Class",
          "explanation": "The output feature class to receive the results fields.",
          "datatype": "Feature Class"
        },
        {
          "name": "Conceptualization_of_Spatial_Relationships",
          "explanation": "Specifies how spatial relationships among features are defined.INVERSE_DISTANCE—Nearby neighboring features have a larger influence  on the  computations for a target feature than features that are far away.INVERSE_DISTANCE_SQUARED—Same as INVERSE_DISTANCE except that the slope is sharper, so influence drops off more quickly, and only a target feature's closest neighbors will exert substantial influence on  computations for that feature. FIXED_DISTANCE_BAND—Each feature is analyzed within the context of neighboring features.  Neighboring features inside the specified critical distance (Distance_Band_or_Threshold_Distance) receive a weight of one  and exert influence on computations for the target feature.  Neighboring features outside the critical distance receive a weight of zero and have no  influence on a target feature's computations. ZONE_OF_INDIFFERENCE—Features within the specified critical distance (Distance_Band_or_Threshold_Distance) of a target feature receive a weight of one and influence computations for that feature. Once the critical distance is exceeded, weights (and the influence a neighboring feature has on target feature computations) diminish with distance. K_NEAREST_NEIGHBORS—The closest k features are included in the analysis.  The number of neighbors (k) is specified by the number_of_neighbors parameter.CONTIGUITY_EDGES_ONLY—Only neighboring polygon features that share a boundary or overlap will influence computations for the target polygon feature.  CONTIGUITY_EDGES_CORNERS—Polygon features that share a boundary, share a node, or overlap will influence computations for the target polygon feature. GET_SPATIAL_WEIGHTS_FROM_FILE—Spatial relationships are defined by a specified spatial weights file. The path to the spatial weights file is specified by the Weights_Matrix_File parameter.",
          "datatype": "String"
        },
        {
          "name": "Distance_Method",
          "explanation": "Specifies how distances are calculated from each feature to neighboring features.EUCLIDEAN_DISTANCE—The straight-line distance between two points (as the crow flies) MANHATTAN_DISTANCE—The distance between two points measured along axes at right angles (city block); calculated by summing the (absolute) difference between the x- and y-coordinates",
          "datatype": "String"
        },
        {
          "name": "Standardization",
          "explanation": "Row standardization is recommended whenever the distribution of your features is potentially biased due to sampling design or an imposed aggregation scheme.NONE—No standardization of spatial weights is applied. ROW—Spatial weights are standardized; each weight is divided by its row sum (the sum of the weights of all neighboring features).",
          "datatype": "String"
        },
        {
          "name": "Distance_Band_or_Threshold_Distance(Optional)",
          "explanation": "Specifies a cutoff distance for Inverse Distance and Fixed Distance options. Features outside the specified cutoff for a target feature are ignored in analyses for that feature. However, for Zone of Indifference, the influence of features outside the given distance is reduced with distance, while those inside the distance threshold are equally considered. The distance value entered should match that of the output coordinate system.            For the Inverse Distance conceptualizations of spatial relationships, a value of 0 indicates that no threshold distance is applied; when this parameter is left blank, a default threshold value is computed and applied.    This default value is the Euclidean distance that ensures every feature has at least one neighbor.            This parameter has no effect when Polygon Contiguity or Get Spatial Weights From File spatial conceptualizations are selected.",
          "datatype": "Double"
        },
        {
          "name": "Weights_Matrix_File(Optional)",
          "explanation": "The path to a file containing weights that define spatial, and potentially temporal, relationships among features.",
          "datatype": "File"
        },
        {
          "name": "Apply_False_Discovery_Rate__FDR__Correction(Optional)",
          "explanation": "APPLY_FDR—Statistical significance will be based on the False Discovery Rate correction for a 95 percent confidence level.NO_FDR—Features with p-values less than 0.05 will appear in the COType field reflecting statistically significant clusters or outliers at a 95 percent confidence level (default).",
          "datatype": "Boolean"
        },
        {
          "name": "Number_of_Permutations(Optional)",
          "explanation": "The number of random permutations for the calculation of pseudo p-values. The default number of permutations is 499. \r\nIf you choose 0 permutations, the standard p-value is calculated.0—Permutations are not used and a standard p-value is calculated. 99—With 99 permutations, the smallest possible pseudo p-value is 0.01 and all other pseudo p-values will be multiples of this value.199—With 199 permutations, the smallest possible pseudo p-value is 0.005 and all other possible pseudo p-values will be multiples of this value.499—With 499 permutations, the smallest possible pseudo p-value is 0.002 and all other pseudo p-values will be multiples of this value.999—With 999 permutations, the smallest possible pseudo p-value is 0.001 and all other pseudo p-values will be multiples of this value.9999—With 9999 permutations, the smallest possible pseudo p-value is 0.0001 and all other pseudo p-values will be multiples of this value.",
          "datatype": "Long"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "The number of neighbors to include in the analysis.",
          "datatype": "Long"
        }
      ],
      "summary": "Identifies statistically significant hot spots, cold spots, and spatial outliers using the Anselin Local Moran's I statistic, given a set of weighted features. Learn more about how Cluster and Outlier Analysis (Anselin Local Moran's I) works",
      "extraction_date": "2025-10-01T15:18:39.938528"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Density-based Clustering",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/densitybasedclustering.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The point features for which density-based clustering will be performed.",
          "datatype": "Feature Layer"
        },
        {
          "name": "output_features",
          "explanation": "The output feature class that will receive the cluster results.",
          "datatype": "Feature Class"
        },
        {
          "name": "cluster_method",
          "explanation": "Specifies the method that will be used to define clusters.\r\nDBSCAN— A specified distance will be used to separate dense clusters from sparser noise. DBSCAN is the fastest of the clustering methods but is only appropriate if there is a clear distance to use that works well to define all clusters that may be present. This results in clusters that have similar densities. HDBSCAN— Varying distances will be used to separate clusters of varying densities from sparser noise. HDBSCAN is the most data-driven of the clustering methods and requires the least user input. OPTICS—The distance between neighbors and a reachability plot will be used to separate clusters of varying densities from noise. OPTICS offers the most flexibility in fine-tuning the clusters that are detected, though it is computationally intensive, particularly with a large search distance.",
          "datatype": "String"
        },
        {
          "name": "min_features_cluster",
          "explanation": "The minimum number of points that will be considered a cluster.\r\nAny cluster with fewer points than the number provided will be considered noise.",
          "datatype": "Long"
        },
        {
          "name": "search_distance(Optional)",
          "explanation": "The maximum distance that will be considered.For the cluster_method parameter's DBSCAN option, the min_features_cluster parameter value must be found within this distance for cluster membership. Individual clusters will be separated by at least this distance. If a point is located farther than this distance from the next closest point in the cluster, it will not be included in the cluster.  For the cluster_method parameter's OPTICS option, this parameter is optional and is used as the maximum search distance when creating the reachability plot. For OPTICS, the reachability plot, combined with the cluster_sensitivity parameter value, determines cluster membership. If no distance is specified, the tool will search all distances, which will increase processing time. If left blank, the default distance used will be the highest core distance found in the dataset, excluding those core distances in the top 1 percent (he most extreme core distances). If the time_field parameter value is provided, a search distance must be provided and does not include a default value.",
          "datatype": "Linear Unit"
        },
        {
          "name": "cluster_sensitivity",
          "explanation": "An integer between 0 and 100 that determines the compactness of clusters. A number close to 100 will result in a higher number of dense clusters. A number close to 0 will result in fewer, less compact clusters.  If left blank, the tool will find a sensitivity value using the Kullback-Leibler divergence that finds the value in which adding more clusters does not add additional information.",
          "datatype": "Long"
        },
        {
          "name": "time_field",
          "explanation": "The field containing the time stamp for each record in the dataset. This field must be of type Date. If provided,  the tool will find clusters of points that are close to each other in space and time. The search_time_interval parameter value must be provided to determine whether a point is close enough in time to a cluster to be included in the cluster.",
          "datatype": "Field"
        },
        {
          "name": "search_time_interval",
          "explanation": "The time interval that will be used to determine whether points form a space-time cluster.  The search time interval spans before and after the time of each point; for example, an interval of 3 days around a point will include all points starting 3 days before and ending 3 days after the time of the point.For the cluster_method parameter's DBSCAN option, the min_features_cluster value specified must be found within the search distance and the search time interval  to be included in a cluster.For the cluster_method parameter's OPTICS option, all points outside of the search time interval will be excluded when calculating core distances, neighbor-distances, and reachability distances.The search time interval does not control the overall time span of the resulting space-time clusters.  The time span of points within a cluster can be larger than the search time interval as long as each point has neighbors within the cluster that are within the search time interval.",
          "datatype": "Time Unit"
        }
      ],
      "summary": "Finds clusters of point features within surrounding noise based on their spatial distribution. Time can also be incorporated to find space-time clusters. Learn more about how Density-based Clustering works",
      "extraction_date": "2025-10-01T15:18:42.786244"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Hot Spot Analysis (Getis-Ord Gi*)",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/hot-spot-analysis.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class for which hot spot analysis will be performed.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Input_Field",
          "explanation": "The numeric field (for example, number of victims, crime rate, test scores, and so on) to be evaluated.",
          "datatype": "Field"
        },
        {
          "name": "Output_Feature_Class",
          "explanation": "The output feature class that will receive the z-score and p-value results.",
          "datatype": "Feature Class"
        },
        {
          "name": "Conceptualization_of_Spatial_Relationships",
          "explanation": "Specifies how spatial relationships among features will be defined.INVERSE_DISTANCE—Nearby neighboring features will have a larger influence  on the  computations for a target feature than features that are far away.INVERSE_DISTANCE_SQUARED—This is the same as INVERSE_DISTANCE except that the slope is sharper, so influence will drop off more quickly, and only a target feature's closest neighbors will exert substantial influence on  computations for that feature.FIXED_DISTANCE_BAND—Each feature will be analyzed within the context of neighboring features.  Neighboring features inside the specified critical distance (Distance_Band_or_Threshold) will receive a weight of 1  and exert influence on computations for the target feature.  Neighboring features outside the critical distance will receive a weight of 0 and have no  influence on a target feature's computations.ZONE_OF_INDIFFERENCE—Features within the specified critical distance (Distance_Band_or_Threshold) of a target feature will receive a weight of 1 and influence computations for that feature. Once the critical distance is exceeded, weights (and the influence a neighboring feature has on target feature computations) will diminish with distance.K_NEAREST_NEIGHBORS—The closest k features will be included in the analysis; k is a specified numeric parameter.CONTIGUITY_EDGES_ONLY—Only neighboring polygon features that share a boundary or overlap will influence computations for the target polygon feature.CONTIGUITY_EDGES_CORNERS—Polygon features that share a boundary, share a node, or overlap will influence computations for the target polygon feature.GET_SPATIAL_WEIGHTS_FROM_FILE—Spatial relationships will be defined by a specified spatial weights file. The path to the spatial weights file is specified by the Weights_Matrix_File parameter.",
          "datatype": "String"
        },
        {
          "name": "Distance_Method",
          "explanation": "Specifies how distances will be calculated from each feature to neighboring features.EUCLIDEAN_DISTANCE—The straight-line distance between two points (as the crow flies) will be used.MANHATTAN_DISTANCE—The distance between two points measured along axes at right angles (city block) calculated by summing the (absolute) difference between the x- and y-coordinates will be used.",
          "datatype": "String"
        },
        {
          "name": "Standardization",
          "explanation": "Row standardization has no impact on this tool: Results from this tool would be identical with or without row standardization.  This parameter is disabled; it remains only to support backward compatibility.NONE—No standardization of spatial weights is applied. ROW—No standardization of spatial weights is applied.",
          "datatype": "String"
        },
        {
          "name": "Distance_Band_or_Threshold_Distance(Optional)",
          "explanation": "The cutoff distance for the inverse distance and fixed distance options. Features outside the specified cutoff for a target feature will be ignored in analyses for that feature. However, for ZONE_OF_INDIFFERENCE, the influence of features outside the given distance will be reduced with distance, while those inside the distance threshold will be equally considered. The distance value provided should match that of the output coordinate system.For the inverse distance conceptualizations of spatial relationships, a value of 0 indicates that no threshold distance will be applied; when this parameter is left blank, a default threshold value will be computed and applied.    The default value is the Euclidean distance, which ensures that every feature has at least one neighbor.This parameter has no effect when polygon contiguity  (CONTIGUITY_EDGES_ONLY or CONTIGUITY_EDGES_CORNERS) or the GET_SPATIAL_WEIGHTS_FROM_FILE spatial conceptualization option is specified.",
          "datatype": "Double"
        },
        {
          "name": "Self_Potential_Field(Optional)",
          "explanation": "The field representing self potential, which is the distance or weight between a feature and itself.",
          "datatype": "Field"
        },
        {
          "name": "Weights_Matrix_File(Optional)",
          "explanation": "The path to a file containing weights that define spatial, and potentially temporal, relationships among features.",
          "datatype": "File"
        },
        {
          "name": "Apply_False_Discovery_Rate__FDR__Correction(Optional)",
          "explanation": "Specifies whether statistical significance will be assessed based on the FDR correction.APPLY_FDR—Statistical significance will be based on the FDR correction.NO_FDR—Statistical significance will not be based on the FDR correction; it will be based on the p-value and z-score fields. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "An integer specifying the number of neighbors that will be included in the analysis.",
          "datatype": "Long"
        }
      ],
      "summary": "Given a set of weighted features, identifies statistically significant hot spots and cold spots using the Getis-Ord Gi* statistic. Learn more about how Hot Spot Analysis (Getis-Ord Gi*) works",
      "extraction_date": "2025-10-01T15:18:45.617620"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Hot Spot Analysis Comparison",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/hot-spot-comparison.htm",
      "parameters": [
        {
          "name": "in_hot_spot_1",
          "explanation": "The first hot spot analysis result layer.",
          "datatype": "Feature Layer"
        },
        {
          "name": "in_hot_spot_2",
          "explanation": "The second hot spot analysis result layer.",
          "datatype": "Feature Layer"
        },
        {
          "name": "out_features",
          "explanation": "The output feature class that will contain the local measures of similarity and association.",
          "datatype": "Feature Class"
        },
        {
          "name": "num_neighbors(Optional)",
          "explanation": "The number of neighbors around each feature that will be used for distance weighting. Distance weighting is one component of the overall similarity, and any features with matching significance levels within the neighborhood will be considered partial matches when calculating similarity and association.",
          "datatype": "Long"
        },
        {
          "name": "num_perms(Optional)",
          "explanation": "The number of permutations that will be used to estimate the expected similarity and kappa values. A larger number of simulations will increase the precision of the estimates but will also increase calculation time.99—The analysis will use 99 permutations. 199—The analysis will use 199 permutations. 499—The analysis will use 499 permutations. This is the default.999—The analysis will use 999 permutations. 9999—The analysis will use 9,999 permutations.",
          "datatype": "Long"
        },
        {
          "name": "weighting_method(Optional)",
          "explanation": "Specifies how similarity weights between significance level categories will be defined.  Similarity weights are numbers between 0 and 1 that define the categories of one result that are expected to match the categories of the other result.  A value of 1 indicates that the categories will be considered exactly the same, and a value of 0 indicates that the categories will be considered completely different.  Values between 0 and 1 indicate degrees of partial similarity between the categories. For example, 99% significant hot spots can be considered perfectly similar to other 99% hot spots, partially similar to 95% hot spots, and completely dissimilar to 99% cold spots.FUZZY—Similarity weights will be fuzzy (nonbinary) and determined by the closeness of significance levels.  For example, 99% significant hot spots will be perfectly similar to other 99% significant hot spots (weight = 1), but they will be partially similar to 95% significant hot spots (weight=0.71) and 90% significant hot spots (weight = 0.55).  The weight between 95% significant and 90% significant is 0.78.  All hot spots will be completely dissimilar to all cold spots and nonsignificant features (weight = 0). This is the default.EXACT_MATCH—Features must have the same significance level to be considered similar. For example, 99% significant hot spots will be considered completely dissimilar to 95% and 90% significant hot spots.ABOVE_90—Features that are 90%, 95%, and 99% significant hot spots will be considered perfectly similar to each other, and all features that are 90%, 95%, and 99% significant cold spots will be considered perfectly similar to each other. This option treats all features at or above 90% significance as being the same (statistically significant) and all features below 90% confidence as being the same (nonsignificant).  This option is recommended when the hot spot analyses were performed at a 90% significance level.ABOVE_95—Features that are 95% and 99% significant hot (or cold) spots will be considered perfectly similar, and features that are 95% and 99% significant cold spots will be considered perfectly similar. For example, 90% significant hot and cold spots will be considered completely dissimilar to higher significance levels. This option treats all features at or above 95% confidence as being the same (statistically significant) and all features below 95% confidence as being the same (nonsignificant).  This option is recommended when the hot spot analyses were performed at a 95% significance level.ABOVE_99—Only features that are 99% significant hot (or cold) spots will be considered perfectly similar to each other. This option treats all features below 99% significance as being nonsignificant.  This option is recommended when the hot spot analyses were performed at a 99% significance level.CUSTOM—Custom similarity weights provided in the similarity_weights parameter will be used.TABLE—Similarity weights between significance levels will be defined by an input table. Provide the table in the in_weights_table parameter.REVERSE—The default fuzzy weights will be used, but hot spots of the first hot spot result will be considered similar to the cold spots of the second hot spot result. For example, 99% significant hot spots in one result will be considered perfectly similar to 99% cold spots in the other result  and partially similar  to 95% and 90% cold spots in the other result. This option is recommended when the hot spot analysis variables have a negative relationship. For example, you can measure how closely hot spots of infant mortality correspond to cold spots of healthcare access.",
          "datatype": "String"
        },
        {
          "name": "similarity_weights[similarity_weights,...](Optional)",
          "explanation": "The custom similarity weights between significance level categories.  \r\nThe weights are values between 0 and 1 and indicate how similar to consider the two categories. A value of 0 indicates the categories are completely dissimilar, a value of 1 indicates the values are perfectly similar, and values between 0 and 1 indicate the categories are partially similar.",
          "datatype": "Value Table"
        },
        {
          "name": "in_weights_table(Optional)",
          "explanation": "The table containing custom similarity weights for each combination of hot spot significance level categories. The table must contain CATEGORY1, CATEGORY2, and WEIGHT fields. Provide the significance level categories of the pair (the Gi_Bin field values of the input layers) in the category fields and the similarity weight between them in the weight field.  If a combination is not provided in the table, the weight for the combination is assumed to be 0.",
          "datatype": "Table View"
        },
        {
          "name": "exclude_nonsig_features(Optional)",
          "explanation": "Specifies whether pairs of features will be excluded from the comparisons if both hot spot results are nonsignificant. If excluded, conditional similarity and kappa values will be calculated that compare only the statistically significant hot and cold spots. Excluding features is recommended when you are interested only in whether the hot and cold spots of the input layers align, not whether the nonsignificant areas align, such as comparing whether hot and cold spots of median income correspond to hot and cold spots of food access.EXCLUDE—Nonsignificant features will be excluded, and the comparisons will be conditional on statistically significant hot and cold spots.NO_EXCLUDE—Nonsignificant features will be included.   This is the default.If any significance level categories are assigned a similarity weight of 1 to the nonsignificant category (indicating that the category will be treated the same as the nonsignificant category), features with that category will also be excluded from comparisons if they are paired with another nonsignificant feature.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Compares two hot spot analysis result layers and measures their similarity and association. The  similarity and association between the hot spot result layers is determined by comparing the significance level categories between corresponding features in both input layers. The similarity measures how closely the hot spots, cold spots, and nonsignificant areas of both hot spot results spatially align. The association (or dependence) measures the strength of the underlying statistical relationship between the hot spot variables (similar to correlation for continuous variables). Learn more about how Hot Spot Analysis Comparison works",
      "extraction_date": "2025-10-01T15:18:48.427974"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Multivariate Clustering",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/multivariate-clustering.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The feature class or feature layer for which clusters will be created.",
          "datatype": "Feature Layer"
        },
        {
          "name": "output_features",
          "explanation": "The output feature class that will be created containing all features, the analysis fields specified, and a field indicating to which cluster each feature belongs.",
          "datatype": "Feature Class"
        },
        {
          "name": "analysis_fields[analysis_field,...]",
          "explanation": "A list of fields that will be used to distinguish one cluster from another.",
          "datatype": "Field"
        },
        {
          "name": "clustering_method(Optional)",
          "explanation": "Specifies the clustering algorithm that will be used.The K_MEANS and K_MEDOIDS options generally produce similar results. However, K_MEDOIDS is more robust to noise and outliers in the in_features parameter value. K_MEANS is generally faster than K_MEDOIDS and is recommended for large data sets.K_MEANS—The in_features parameter value will be clustered using the K means algorithm. This is the default.K_MEDOIDS—The in_features parameter value will be clustered using the K medoids algorithm.",
          "datatype": "String"
        },
        {
          "name": "initialization_method(Optional)",
          "explanation": "Specifies how initial seeds to grow clusters are obtained.   If you indicate you want three clusters, for example, the analysis will begin with three seeds.            OPTIMIZED_SEED_LOCATIONS—Seed  features will be selected to optimize analysis results and performance. This is the default.USER_DEFINED_SEED_LOCATIONS—Nonzero entries in the initialization_field parameter value will be used as starting points to grow clusters.  RANDOM_SEED_LOCATIONS—Initial seed features will be randomly selected.",
          "datatype": "String"
        },
        {
          "name": "initialization_field(Optional)",
          "explanation": "The numeric field identifying seed features.  Features with a value of 1 for this field will be used to grow clusters.  Each seed results in a cluster, so at least two seed features must be provided.",
          "datatype": "Field"
        },
        {
          "name": "number_of_clusters(Optional)",
          "explanation": "The number of clusters that will be created.  If you leave this parameter empty,  the tool will evaluate the optimal number of clusters by computing a pseudo F-statistic for clustering solutions with 2 through 30 clusters.This parameter is disabled if the seed locations were provided in an initialization field.",
          "datatype": "Long"
        },
        {
          "name": "output_table(Optional)",
          "explanation": "The table containing the pseudo  F-statistic for clustering solutions 2 through 30,  calculated to evaluate the optimal number of clusters. The chart created from this table can be accessed in the stand-alone tables section of the Contents pane.",
          "datatype": "Table"
        }
      ],
      "summary": "Finds natural clusters of features based solely on feature attribute values. Learn more about how Multivariate Clustering works",
      "extraction_date": "2025-10-01T15:18:51.006161"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Optimized Hot Spot Analysis",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/optimized-hot-spot-analysis.htm",
      "parameters": [
        {
          "name": "Input_Features",
          "explanation": "The point or polygon feature class for which hot spot analysis will be performed.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Features",
          "explanation": "The output feature class to receive the z-score, p-value, and Gi_Bin results.",
          "datatype": "Feature Class"
        },
        {
          "name": "Analysis_Field(Optional)",
          "explanation": "The numeric field (number of incidents, crime rates, test scores, and so on) to be evaluated.",
          "datatype": "Field"
        },
        {
          "name": "Incident_Data_Aggregation_Method(Optional)",
          "explanation": "The aggregation method to use to create weighted features for analysis from incident point data.\r\nCOUNT_INCIDENTS_WITHIN_FISHNET_POLYGONS—A fishnet polygon mesh will overlay the incident point data  and the number of incidents within each polygon cell will be counted.  If no bounding polygon is provided in the Bounding_Polygons_Defining_Where_Incidents_Are_Possible parameter, only cells with at least one incident will be used in the analysis; otherwise, all cells within the bounding polygons will be analyzed.COUNT_INCIDENTS_WITHIN_HEXAGON_POLYGONS—A hexagon polygon mesh will overlay the incident point data  and the number of incidents within each polygon cell will be counted.  If no bounding polygon is provided in the Bounding_Polygons_Defining_Where_Incidents_Are_Possible parameter, only cells with at least one incident will be used in the analysis; otherwise, all cells within the bounding polygons will be analyzed.COUNT_INCIDENTS_WITHIN_AGGREGATION_POLYGONS—You provide aggregation polygons to overlay the incident point data in the Polygons_For_Aggregating_Incidents_Into_Counts parameter.  The incidents within each polygon are counted.SNAP_NEARBY_INCIDENTS_TO_CREATE_WEIGHTED_POINTS—Nearby incidents will be aggregated together to create a single weighted point.  The weight for each point is the number of aggregated incidents at that location.",
          "datatype": "String"
        },
        {
          "name": "Bounding_Polygons_Defining_Where_Incidents_Are_Possible(Optional)",
          "explanation": "A polygon feature class defining where the incident Input_Features could possibly occur.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Polygons_For_Aggregating_Incidents_Into_Counts(Optional)",
          "explanation": "The polygons to use to aggregate the incident Input_Features in order to get an incident count for each polygon feature.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Density_Surface(Optional)",
          "explanation": "The Density_Surface parameter is disabled; it\r\nremains as a tool parameter only to support backwards\r\ncompatibility.\r\nThe Kernel Density tool can be used if you would like a density surface visualization of your weighted points.",
          "datatype": "Raster Dataset"
        },
        {
          "name": "Cell_Size(Optional)",
          "explanation": "The size of the grid cells used to aggregate the Input_Features.  When aggregating into a hexagon grid, this distance is used as the height to construct the hexagon polygons.",
          "datatype": "Linear Unit"
        },
        {
          "name": "Distance_Band(Optional)",
          "explanation": "The spatial extent of the analysis neighborhood.  This value determines which features are analyzed together in order to assess local clustering.",
          "datatype": "Linear Unit"
        }
      ],
      "summary": "Creates a map of statistically significant hot and cold spots using the Getis-Ord Gi* statistic, given incident points or weighted features (points or polygons). The tool evaluates the characteristics of the input feature class to produce optimal results. Learn more about how Optimized Hot Spot Analysis works",
      "extraction_date": "2025-10-01T15:18:53.883224"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Optimized Outlier Analysis",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/optimizedoutlieranalysis.htm",
      "parameters": [
        {
          "name": "Input_Features",
          "explanation": "The point or polygon feature class for which the cluster and outlier analysis will be performed.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Features",
          "explanation": "The output feature class to receive the result fields.",
          "datatype": "Feature Class"
        },
        {
          "name": "Analysis_Field(Optional)",
          "explanation": "The numeric field (number of incidents, crime rates, test scores, and so on) to be evaluated.",
          "datatype": "Field"
        },
        {
          "name": "Incident_Data_Aggregation_Method(Optional)",
          "explanation": "The aggregation method to use to create weighted features for analysis from incident point data.\r\nCOUNT_INCIDENTS_WITHIN_FISHNET_POLYGONS—A fishnet polygon mesh will overlay the incident point data  and the number of incidents within each polygon cell will be counted.  If no bounding polygon is provided in the Bounding_Polygons_Defining_Where_Incidents_Are_Possible parameter, only cells with at least one incident will be used in the analysis; otherwise, all cells within the bounding polygons will be analyzed. This is the default.COUNT_INCIDENTS_WITHIN_HEXAGON_POLYGONS—A hexagon polygon mesh will overlay the incident point data  and the number of incidents within each polygon cell will be counted.  If no bounding polygon is provided in the Bounding_Polygons_Defining_Where_Incidents_Are_Possible parameter, only cells with at least one incident will be used in the analysis; otherwise, all cells within the bounding polygons will be analyzed.COUNT_INCIDENTS_WITHIN_AGGREGATION_POLYGONS—You provide aggregation polygons to overlay the incident point data in the Polygons_For_Aggregating_Incidents_Into_Counts parameter.  The incidents within each polygon are counted.SNAP_NEARBY_INCIDENTS_TO_CREATE_WEIGHTED_POINTS—Nearby incidents will be aggregated together to create a single weighted point.  The weight for each point is the number of aggregated incidents at that location.",
          "datatype": "String"
        },
        {
          "name": "Bounding_Polygons_Defining_Where_Incidents_Are_Possible(Optional)",
          "explanation": "A polygon feature class defining where the incident Input_Features could possibly occur.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Polygons_For_Aggregating_Incidents_Into_Counts(Optional)",
          "explanation": "The polygons to use to aggregate the incident Input_Features in order to get an incident count for each polygon feature.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Performance_Adjustment(Optional)",
          "explanation": "This analysis utilizes permutations to create a reference distribution.  Choosing the number of permutations is a balance between precision and increased processing time. \r\nChoose your preference for speed versus precision.  More robust and precise results take longer to calculate.QUICK_199—With 199 permutations, the smallest possible pseudo p-value is 0.005 and all other pseudo p-values will be even multiples of this value.BALANCED_499—With 499 permutations, the smallest possible pseudo p-value is 0.002 and all other pseudo p-values will be even multiples of this value. This is the default.ROBUST_999—With 999 permutations, the smallest possible pseudo p-value is 0.001 and all other pseudo p-values will be even multiples of this value.",
          "datatype": "String"
        },
        {
          "name": "Cell_Size(Optional)",
          "explanation": "The size of the grid cells used to aggregate the Input_Features.  When aggregating into a hexagon grid, this distance is used as the height to construct the hexagon polygons.",
          "datatype": "Linear Unit"
        },
        {
          "name": "Distance_Band(Optional)",
          "explanation": "The spatial extent of the analysis neighborhood.  This value determines which features are analyzed together in order to assess local clustering.",
          "datatype": "Linear Unit"
        }
      ],
      "summary": "Given incident points or weighted features (points or polygons), creates a map of statistically significant hot spots, cold spots, and spatial outliers using the Anselin Local Moran's I statistic. It evaluates the characteristics of the input feature class to produce optimal results. Learn more about how Optimized Outlier Analysis works",
      "extraction_date": "2025-10-01T15:18:56.694949"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Similarity Search",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/similarity-search.htm",
      "parameters": [
        {
          "name": "Input_Features_To_Match",
          "explanation": "The layer, or a selection on a layer, containing the features you want to match; you are searching for other features that look like these features.  When more than one feature is provided, matching is based on attribute averages.Tip:When the Input Features To Match and Candidate Features values are from a single dataset layer, you can do the following:Copy the layer to the Contents pane, making a duplicate layer.Rename the duplicate layer.On the renamed layer, make a selection or set a definition query for the reference features you want to match.  Use the new layer created for the   Input Features To Match parameter.Apply a selection or set a definition query on the original layer so it excludes the reference features.  This will be the layer to use for the  Candidate Features parameter.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Candidate_Features",
          "explanation": "The layer, or a selection on a layer, containing candidate matching features.  The tool will check for features most similar (or most dissimilar) to the Input_Features_To_Match values among these candidates.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Features",
          "explanation": "The output feature class containing a record for each of the  Input_Features_To_Match values and for all the solution-matching features found.",
          "datatype": "Feature Class"
        },
        {
          "name": "Collapse_Output_To_Points",
          "explanation": "Specifies whether the geometry for the Output_Features parameter will be collapsed to points or will match the original geometry (lines or polygons) of the input features if the Input_Features_To_Match and Candidate_Features parameter values are both either lines or polygons. This parameter is only available with an Desktop Advanced license. Choosing COLLAPSE will improve tool performance for  large line and polygon datasets.COLLAPSE—The line and polygon  features will be represented as feature centroids (points).NO_COLLAPSE—The output geometry will match the line or polygon geometry of the input features. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "Most_Or_Least_Similar",
          "explanation": "Specifies whether features that are most similar or most dissimilar to the Input_Features_To_Match values will be identified.MOST_SIMILAR—Features that are most similar will be identified. This is the default.LEAST_SIMILAR—Features that are most dissimilar will be identified.  BOTH—Features that are most similar and features that are most dissimilar will both be identified.",
          "datatype": "String"
        },
        {
          "name": "Match_Method",
          "explanation": "Specifies whether matching will be based on values, ranks, or cosine relationships.ATTRIBUTE_VALUES—Matching will be based on the sum of squared standardized attribute value differences for all of the Attributes Of Interest values. This is the default.RANKED_ATTRIBUTE_VALUES—Matching will be based on the sum of squared rank differences for all of the Attributes Of Interest values.ATTRIBUTE_PROFILES—Matching will be computed as a function of cosine similarity for all of the Attributes Of Interest values.",
          "datatype": "String"
        },
        {
          "name": "Number_Of_Results",
          "explanation": "The number of solution matches to find.  Entering zero or a number larger than the total number of   Candidate_Features values will return rankings for all the candidate features. The default is 10.",
          "datatype": "Long"
        },
        {
          "name": "Attributes_Of_Interest[Attributes_Of_Interest,...]",
          "explanation": "The numeric attributes representing the matching criteria.",
          "datatype": "Field"
        },
        {
          "name": "Fields_To_Append_To_Output[Fields_To_Append_To_Output,...](Optional)",
          "explanation": "The fields to include with the Output_Features parameter. These fields are not used to determine similarity; they are only included in the  Output_Features parameter for reference.",
          "datatype": "Field"
        }
      ],
      "summary": "Identifies which candidate features are most similar or most dissimilar to one or more input features based on feature attributes. Learn more about how Similarity Search works",
      "extraction_date": "2025-10-01T15:18:59.501811"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Spatial Outlier Detection",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/spatial-outlier-detection.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The point features that will be used to build the spatial outlier\r\ndetection model. Each point will be classified as an outlier or inlier based on its local outlier factor.",
          "datatype": "Feature Layer"
        },
        {
          "name": "output_features",
          "explanation": "The output feature class containing the local outlier factor for each input feature as well as an indicator of whether the point is a spatial outlier.",
          "datatype": "Feature Class"
        },
        {
          "name": "n_neighbors(Optional)",
          "explanation": "The number of neighbors that will be used to detect spatial outliers for each input point. For local outlier detection, the value must be at least 2, and all features within the neighborhood will be used as neighbors.\r\nIf no value is specified, a value is estimated at run time and is displayed as a geoprocessing message.For global outlier detection, only the farthest neighbor in the neighborhood will be used, and the default is 1 (the closest neighbor). For example, a value of 3 indicates that global outliers are detected using distances to the third nearest neighbor of each point.",
          "datatype": "Long"
        },
        {
          "name": "percent_outlier(Optional)",
          "explanation": "The percent of locations that will be identified as spatial outliers by defining the threshold of the local outlier factor.  If no value is specified, a value is estimated at run time and is displayed as a geoprocessing message. A maximum of 50 percent of the features can be identified as spatial outliers.",
          "datatype": "Double"
        },
        {
          "name": "output_raster(Optional)",
          "explanation": "The output raster containing the local\r\noutlier factors at each cell, which is calculated based on the spatial distribution of the input features. This parameter is only available with a Desktop Advanced license.",
          "datatype": "Raster Dataset"
        },
        {
          "name": "outlier_type(Optional)",
          "explanation": "Specifies the type of outlier that will be detected. A global outlier is a point that is far away from all other points in the feature class.  A local outlier is a point that is farther away from its neighbors than would be expected by the density of points in the surrounding area.GLOBAL—Global outliers of input points will be detected. This is the default.LOCAL—Local outliers of input points will be detected.",
          "datatype": "String"
        },
        {
          "name": "sensitivity(Optional)",
          "explanation": "Specifies the sensitivity level that will be used to detect global outliers. The higher the sensitivity, the more points that will be detected as outliers.The sensitivity value will determine the threshold, and any point with a neighbor distance larger than this threshold will be identified as a global outlier. The thresholds are determined using the box plot rule, in which the threshold for high sensitivity is one interquartile range above the third quartile. For medium sensitivity, the threshold is 1.5 interquartile ranges above the third quartile.  For low sensitivity, the threshold is two interquartile ranges above the third quartile.LOW—Outliers will be detected using low sensitivity.  This option will detect the fewest outliers.MEDIUM—Outliers will be detected using moderate sensitivity.  This is the default.HIGH—Outliers will be detected using high sensitivity.  This option will detect the most outliers.",
          "datatype": "String"
        },
        {
          "name": "keep_type(Optional)",
          "explanation": "Specifies whether the output features will contain all input features or only features identified as spatial outliers.KEEP_OUTLIER—The output features will only contain features identified as spatial outliers.KEEP_ALL—The output features will contain all input features. This is the default.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Identifies global or local spatial outliers in point features. A global outlier is a point that is far away from all other points in a feature class.   Global outliers are detected by examining distances between each point and one of its closest neighbors (by default, the closest neighbor) and detecting points where the distance is large. A local outlier is a point that is farther away from its neighbors than would be expected by the density of points in the surrounding area.  Local outliers are detected by calculating the local outlier factor (LOF) of each feature.  The LOF is a measure that describes how isolated a location is compared to its local neighbors. A higher LOF value indicates greater isolation. The tool can also be used to produce a raster prediction surface that can be used to estimate whether new features will be classified as outliers based on the spatial distribution of the data. Learn more about how Spatial Outlier Detection works",
      "extraction_date": "2025-10-01T15:19:02.087253"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Spatially Constrained Multivariate Clustering",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/spatially-constrained-multivariate-clustering.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The feature class or feature layer for which you want to create clusters.",
          "datatype": "Feature Layer"
        },
        {
          "name": "output_features",
          "explanation": "The new output feature class created containing all features, the analysis fields specified, and a field indicating to which cluster each feature belongs.",
          "datatype": "Feature Class"
        },
        {
          "name": "analysis_fields[analysis_fields,...]",
          "explanation": "A list of fields that will be used to distinguish one cluster from another.",
          "datatype": "Field"
        },
        {
          "name": "size_constraints(Optional)",
          "explanation": "Specifies cluster size based on number of features per group or a target attribute value per group.NONE—No cluster size constraints will be used.  This is the default.NUM_FEATURES—A minimum and maximum number of features per group will be used.ATTRIBUTE_VALUE—A minimum and maximum attribute value per group will be used.",
          "datatype": "String"
        },
        {
          "name": "constraint_field(Optional)",
          "explanation": "The attribute value to be summed per cluster.",
          "datatype": "Field"
        },
        {
          "name": "min_constraint(Optional)",
          "explanation": "The minimum number of features per cluster or the minimum attribute value per cluster.\r\nThis must be a positive value.",
          "datatype": "Double"
        },
        {
          "name": "max_constraint(Optional)",
          "explanation": "The maximum number of features per cluster or the maximum attribute value per cluster.  If a maximum constraint is set, the number_of_clusters parameter is disabled.\r\nThis must be a positive value.",
          "datatype": "Double"
        },
        {
          "name": "number_of_clusters(Optional)",
          "explanation": "The number of clusters to create.  If this parameter is empty,  the tool will evaluate the optimal number of clusters by computing a pseudo F-statistic value for clustering solutions with 2 through 30 clusters.This parameter will be disabled if a maximum number of features or maximum attribute value has been set.",
          "datatype": "Long"
        },
        {
          "name": "spatial_constraints(Optional)",
          "explanation": "Specifies how spatial relationships among features will be defined.CONTIGUITY_EDGES_ONLY—Clusters will contain contiguous polygon features. Only polygons that share an edge can be part of the same cluster.CONTIGUITY_EDGES_CORNERS— Clusters will contain contiguous polygon features. Only polygons that share an edge or a vertex can be part of the same cluster. This is the default for polygon features.TRIMMED_DELAUNAY_TRIANGULATION— Features in the same cluster will have at least one natural neighbor in common with another feature in the cluster. Natural neighbor relationships are based on a trimmed Delaunay triangulation. Conceptually, Delaunay triangulation creates a nonoverlapping mesh of triangles from feature centroids. Each feature is a triangle node, and nodes that share edges are considered neighbors. These triangles are then clipped to a convex hull to ensure that features cannot be neighbors with any features outside the convex hull. This is the default for point features.GET_SPATIAL_WEIGHTS_FROM_FILE—Spatial, and optionally temporal, relationships are defined by a specified spatial weights file (.swm). Create the spatial weights matrix using the Generate Spatial Weights Matrix or Generate Network Spatial Weights tool.  The path to the spatial weights file is specified by the Weights_Matrix_File parameter.",
          "datatype": "String"
        },
        {
          "name": "weights_matrix_file(Optional)",
          "explanation": "The path to a file containing spatial weights that define spatial, and potentially temporal, relationships among features.",
          "datatype": "File"
        },
        {
          "name": "number_of_permutations(Optional)",
          "explanation": "The number of random permutations \r\nfor the calculation of membership stability scores.  If 0 (zero) is chosen, probabilities will not be calculated. Calculating these probabilities uses permutations of random spanning trees and evidence accumulation.  This calculation can take a significant time to run for larger datasets.  It is recommended that you iterate and  find the optimal number of clusters for your analysis first; then calculate probabilities for your analysis in a subsequent run.  Setting the Parallel Processing Factor Environment setting to 50 may improve the run time of the tool.",
          "datatype": "Long"
        },
        {
          "name": "output_table",
          "explanation": "The table created containing the results of the F-statistic values calculated to evaluate the optimal number of clusters.  The chart created from this table can be accessed in the  Contents pane under the output feature layer.",
          "datatype": "Table"
        }
      ],
      "summary": "Finds spatially contiguous clusters of features based on a set of feature attribute values and optional cluster size limits. Learn more about how Spatially Constrained Multivariate Clustering works",
      "extraction_date": "2025-10-01T15:19:04.720737"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Central Feature",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/central-feature.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class containing a distribution of features from which to identify the most centrally located feature.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Feature_Class",
          "explanation": "The feature class that will contain the most centrally located feature in the Input Feature Class.",
          "datatype": "Feature Class"
        },
        {
          "name": "Distance_Method",
          "explanation": "Specifies how distances are calculated from each feature to neighboring features.EUCLIDEAN_DISTANCE—The straight-line distance between two points (as the crow flies) MANHATTAN_DISTANCE—The distance between two points measured along axes at right angles (city block); calculated by summing the (absolute) difference between the x- and y-coordinates",
          "datatype": "String"
        },
        {
          "name": "Weight_Field(Optional)",
          "explanation": "The numeric field used to weight distances in the origin-destination distance matrix.",
          "datatype": "Field"
        },
        {
          "name": "Self_Potential_Weight_Field(Optional)",
          "explanation": "The field representing self-potential—the distance or weight between a feature and itself.",
          "datatype": "Field"
        },
        {
          "name": "Case_Field(Optional)",
          "explanation": "Field used to group features for separate central feature computations. The case field can be of integer, date, or string type.",
          "datatype": "Field"
        }
      ],
      "summary": "Identifies the most centrally located feature in a point, line, or polygon feature class. Learn more about how Central Feature works",
      "extraction_date": "2025-10-01T15:19:09.039124"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Decompose Spatial Structure",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/decompose-spatial-structure.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The point or polygon features that will be used to create the spatial components.",
          "datatype": "Feature Layer"
        },
        {
          "name": "out_features",
          "explanation": "The output feature class that will contain the spatial components as fields. The number of fields created depends on the min_autocorrelation and max_components parameter values.",
          "datatype": "Feature Class"
        },
        {
          "name": "append_all_fields(Optional)",
          "explanation": "Specifies whether all fields will be copied from the input features to the output feature class.ALL— All fields from the input features will be copied to the output feature class. This is the default.NO_FIELDS—No fields will be copied to the output feature class.",
          "datatype": "Boolean"
        },
        {
          "name": "min_autocorrelation(Optional)",
          "explanation": "The threshold value for including a spatial component.  The value is a proportion of the largest possible Moran's I value for the spatial weights, and a component must have a larger Moran's I value than this threshold to be included. The default is 0.25, meaning that for a  component to be included, it must have a Moran's I value that is at least 25 percent of the maximum possible Moran's I value. The value must be between 0 and 1, and smaller values will result in more components.",
          "datatype": "Double"
        },
        {
          "name": "max_components(Optional)",
          "explanation": "The maximum number of spatial components that will be created. The default is 15.",
          "datatype": "Long"
        },
        {
          "name": "neighborhood_type(Optional)",
          "explanation": "Specifies how neighbors will be chosen for each input feature.  Neighboring features must be identified in order to decompose the spatial structure of the input features. \r\nDISTANCE_BAND—Features within a specified critical distance of each feature will be included as neighbors. This is the default for point features.NUMBER_OF_NEIGHBORS— The closest features will be included as neighbors. CONTIGUITY_EDGES_ONLY— Polygon features that share an edge will be included as neighbors.CONTIGUITY_EDGES_CORNERS— Polygon features that share an edge or a corner will be included as neighbors. This is the default for polygon features.DELAUNAY_TRIANGULATION—Features whose Delaunay triangulation share an edge will be included as neighbors. GET_SPATIAL_WEIGHTS_FROM_FILE— Neighbors and weights will be defined by a specified spatial weights file.",
          "datatype": "String"
        },
        {
          "name": "distance_band(Optional)",
          "explanation": "The distance within which features will be included as neighbors. If no value is provided, one will be estimated during processing and included as a geoprocessing message. If the specified distance results in more than 1,000 neighbors, only the closest 1,000 features will be included as neighbors.",
          "datatype": "Linear Unit"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "The number of neighbors that will be included for each feature. The number does not include the focal feature. The default is 8.",
          "datatype": "Long"
        },
        {
          "name": "weights_matrix_file(Optional)",
          "explanation": "The path and file name of the spatial weights matrix file (.swm) that defines the neighbors and weights between the input features.",
          "datatype": "File"
        },
        {
          "name": "local_weighting_scheme(Optional)",
          "explanation": "Specifies the weighting scheme that will be applied to neighboring features.  \r\nUNWEIGHTED—Neighbors will not be weighted.  This is the default.BISQUARE—Neighbors will be weighted using a bisquare kernel scheme.GAUSSIAN—Neighbors will be weighted using a Gaussian kernel scheme.",
          "datatype": "String"
        },
        {
          "name": "kernel_bandwidth(Optional)",
          "explanation": "The bandwidth of the bisquare or Gaussian local weighting schemes. If no value is provided, one will be estimated during processing and included as a geoprocessing message.",
          "datatype": "Linear Unit"
        },
        {
          "name": "out_swm(Optional)",
          "explanation": "The output spatial weights matrix file (.swm) of the neighbors and weights of all pairs of features.  If created, this file can be reused in tools that allow defining neighbors and weights with spatial weights matrix files.",
          "datatype": "File"
        },
        {
          "name": "id_field(Optional)",
          "explanation": "The unique ID field of the output spatial weights matrix file. The field must be an integer and must have a unique value for each input feature.",
          "datatype": "Field"
        }
      ],
      "summary": "Decomposes a feature class and neighborhood into a set of spatial components. The components represent potential spatial patterns among the features, such as clusters or trends. The components are returned as fields of the output feature class and represent variables of the input features and neighborhood that have the strongest possible spatial clustering (spatial autocorrelation).  The components are called Moran eigenvectors, and each component represents a different spatial pattern that are each independent of each other. Learn more about Moran eigenvectors",
      "extraction_date": "2025-10-01T15:19:11.633302"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Directional Distribution",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/directional-distribution.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "A feature class containing a distribution of features for which the standard deviational ellipse or ellipsoid will be calculated.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Ellipse_Feature_Class",
          "explanation": "A polygon feature class that will contain the output ellipse feature.",
          "datatype": "Feature Class"
        },
        {
          "name": "Ellipse_Size",
          "explanation": "Specifies the size of the output ellipses in standard deviations.1_STANDARD_DEVIATION—The size of the output ellipses will be one standard deviation. This is the default.2_STANDARD_DEVIATIONS—The size of the output ellipses will be two standard deviations.3_STANDARD_DEVIATIONS—The size of the output ellipses will be three standard deviations.",
          "datatype": "String"
        },
        {
          "name": "Weight_Field(Optional)",
          "explanation": "The numeric field that will be used to weight locations according to their relative importance.",
          "datatype": "Field"
        },
        {
          "name": "Case_Field(Optional)",
          "explanation": "The field that will be used to group features for separate directional distribution calculations. The case field can be of integer, date, or string type.",
          "datatype": "Field"
        }
      ],
      "summary": "Creates standard deviational ellipses or ellipsoids to summarize the spatial characteristics of geographic features: central tendency, dispersion, and directional trends. Learn how Directional Distribution (Standard Deviational Ellipse) works",
      "extraction_date": "2025-10-01T15:19:14.174035"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Directional Trend",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/directional-trend.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The input feature layer that will be used to calculate the directional trend. \r\nThe input must be point or polygon features. For polygons, the centroids of the polygons will be used to create the chart.",
          "datatype": "Feature Layer"
        },
        {
          "name": "analysis_field",
          "explanation": "The numeric field from the input feature layer that will be used to calculate the directional trend.",
          "datatype": "Field"
        },
        {
          "name": "direction(Optional)",
          "explanation": "The direction of the trend.  Provide the value as degrees clockwise from north. For example, 0 corresponds to north, 90 to east, 180 to south, and 270 to west.  The value must be between 0 and 360.  The default is 0.\r\nThis parameter does not apply if you choose to determine the direction of strongest trend.The direction will generally not correspond to true cardinal directions.  For example, 0 corresponds to the direction of the y-coordinates of the features, which may not be true north.",
          "datatype": "Double"
        },
        {
          "name": "determine_direction(Optional)",
          "explanation": "Specifies whether the direction of the strongest trend will be determined by the tool. The direction of strongest trend is determined by finding the direction that maximizes the R-squared value for the provided polynomial order.\r\nIf you specify DETERMINE_DIRECTION, the value will be rounded to a whole number.DETERMINE_DIRECTION—The direction of strongest trend will be determined by the tool.NO_DETERMINE_DIRECTION—The direction of trend will be the direction parameter value. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "order(Optional)",
          "explanation": "Specifies the order of the polynomial that will be fitted to the data values.1—First order (linear) polynomial will be used.2—Second order (quadratic) polynomial will be used.3—Third order (cubic) polynomial will be used.4—Fourth order (quartic) polynomial will be used.5—Fifth order (quintic) polynomial will be used.6—Sixth order (sextic) polynomial will be used.",
          "datatype": "Long"
        }
      ],
      "summary": "Creates a scatter plot chart on a feature layer displaying the trend of data values in a particular direction.",
      "extraction_date": "2025-10-01T15:19:16.627062"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Linear Directional Mean",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/linear-directional-mean.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class containing vectors for which the mean direction will be calculated.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Feature_Class",
          "explanation": "A line feature class that will contain the features representing the mean directions of the input feature class.",
          "datatype": "Feature Class"
        },
        {
          "name": "Orientation_Only",
          "explanation": "Specifies whether to include direction (From and To nodes) information in the analysis.\r\nDIRECTION—The From and To nodes are utilized in calculating the mean. This is the default.ORIENTATION_ONLY—The From and To node information is ignored.",
          "datatype": "Boolean"
        },
        {
          "name": "Case_Field(Optional)",
          "explanation": "Field used to group features for separate directional mean calculations. The case field can be of integer, date, or string type.",
          "datatype": "Field"
        }
      ],
      "summary": "Identifies the mean direction, length, and geographic center for a set of lines. Learn more about how Linear Directional Mean works",
      "extraction_date": "2025-10-01T15:19:19.107779"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Mean Center",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/mean-center.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "A feature class for which the mean center will be calculated.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Feature_Class",
          "explanation": "A point feature class that will contain the features representing the mean centers of the input feature class.",
          "datatype": "Feature Class"
        },
        {
          "name": "Weight_Field(Optional)",
          "explanation": "The numeric field used to create a weighted mean center.",
          "datatype": "Field"
        },
        {
          "name": "Case_Field(Optional)",
          "explanation": "Field used to group features for separate mean center calculations. The case field can be of integer, date, or string type.",
          "datatype": "Field"
        },
        {
          "name": "Dimension_Field(Optional)",
          "explanation": "A numeric field containing attribute values from which an average value will be calculated.",
          "datatype": "Field"
        }
      ],
      "summary": "Identifies the geographic center (or the center of concentration) for a set of features. Learn more about how Mean Center works",
      "extraction_date": "2025-10-01T15:19:21.544223"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Median Center",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/median-center.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "A feature class for which the median center will be calculated.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Feature_Class",
          "explanation": "A point feature class that will contain the features representing the median centers of the input feature class.",
          "datatype": "Feature Class"
        },
        {
          "name": "Weight_Field(Optional)",
          "explanation": "The numeric field used to create a weighted median center.",
          "datatype": "Field"
        },
        {
          "name": "Case_Field(Optional)",
          "explanation": "Field used to group features for separate median center calculations. The case field can be of integer, date, or string type.",
          "datatype": "Field"
        },
        {
          "name": "Attribute_Field[Attribute_Field,...]",
          "explanation": "Numeric field(s) for which the data median value will be computed.",
          "datatype": "Field"
        }
      ],
      "summary": "Identifies the location that minimizes overall Euclidean distance to the features in a dataset. Learn more about how Median Center works",
      "extraction_date": "2025-10-01T15:19:24.001148"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Neighborhood Summary Statistics",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/neighborhood-summary-statistics.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The point or polygon features that will be used to calculate the local statistics.",
          "datatype": "Feature Layer"
        },
        {
          "name": "output_features",
          "explanation": "The output feature class containing the local statistics as fields. Each statistic of each analysis field will be stored as an individual field.",
          "datatype": "Feature Class"
        },
        {
          "name": "analysis_fields[analysis_fields,...](Optional)",
          "explanation": "One or more fields that will be used to calculate local statistics. If no analysis fields are provided, only local statistics based on distances to neighbors will be calculated.",
          "datatype": "Field"
        },
        {
          "name": "local_summary_statistic(Optional)",
          "explanation": "Specifies the local summary statistic that will be calculated for each analysis field.\r\nALL—All local statistics will be calculated.  This is the default.MEAN—The local mean (average) will be calculated.MEDIAN— The local median will be calculated.STD_DEV—The local standard deviation will be calculated.IQR— The local interquartile range will be calculated.SKEWNESS— The local skewness will be calculated.QUANTILE_IMBALANCE— The local quantile imbalance will be calculated.",
          "datatype": "String"
        },
        {
          "name": "include_focal_feature(Optional)",
          "explanation": "Specifies whether the focal feature will be included when calculating local statistics for each feature.INCLUDE_FOCAL—The focal feature and all of its neighbors will be included when calculating local statistics.  This is the default.EXCLUDE_FOCAL—The focal feature will not be included when calculating local statistics. Only neighbors of the feature will be included.",
          "datatype": "Boolean"
        },
        {
          "name": "ignore_nulls(Optional)",
          "explanation": "Specifies whether null values in the analysis fields will be included or ignored in the calculations.IGNORE_NULLS—Null values will be ignored in the local calculations.INCLUDE_NULLS—Null values will be included in the local calculations.",
          "datatype": "Boolean"
        },
        {
          "name": "neighborhood_type(Optional)",
          "explanation": "Specifies which features will be included as neighbors.  To calculate local statistics, neighboring features must be identified for each input feature, and these neighbors are used to calculate the local statistics for each feature. \r\n The Delaunay triangulation option is only available with a Desktop Advanced license.DISTANCE_BAND—Features within a specified critical distance of each feature will be included as neighbors.NUMBER_OF_NEIGHBORS— The closest features will be included as neighbors. CONTIGUITY_EDGES_ONLY— Polygon features that share an edge will be included as neighbors.CONTIGUITY_EDGES_CORNERS— Polygon features that share an edge or a corner will be included as neighbors. This is the default for polygon features.DELAUNAY_TRIANGULATION—Features whose Delaunay triangulation share an edge will be included as neighbors. This is the default for point features.GET_SPATIAL_WEIGHTS_FROM_FILE— Neighbors and weights will be defined by a specified spatial weights file.",
          "datatype": "String"
        },
        {
          "name": "distance_band(Optional)",
          "explanation": "All features within this distance will be included as neighbors. If no value is provided, one will be estimated during processing and included as a geoprocessing message.\r\nIf the specified distance results in more than 1,000 neighbors, only the closest 1,000 features will be included as neighbors.",
          "datatype": "Linear Unit"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "The number of neighbors that will be included for each local calculation. The number does not include the focal feature. If the focal feature is included in calculations, one additional neighbor will be used. The default is 8.",
          "datatype": "Long"
        },
        {
          "name": "weights_matrix_file(Optional)",
          "explanation": "The path and file name of the spatial weights matrix file that defines spatial, and potentially temporal, relationships among\r\nfeatures.",
          "datatype": "File"
        },
        {
          "name": "local_weighting_scheme(Optional)",
          "explanation": "Specifies the weighting scheme that will be applied to neighbors when calculating local statistics.  \r\nUNWEIGHTED—Neighbors will not be weighted.  This is the default.BISQUARE—Neighbors will be weighted using a bisquare kernel scheme.GAUSSIAN—Neighbors will be weighted using a Gaussian kernel scheme.",
          "datatype": "String"
        },
        {
          "name": "kernel_bandwidth(Optional)",
          "explanation": "The bandwidth of the bisquare or Gaussian local weighting schemes. If no value is provided, one will be estimated during processing and included as a geoprocessing message.",
          "datatype": "Linear Unit"
        }
      ],
      "summary": "Calculates summary  statistics of one or more numeric fields using local neighborhoods around each feature.  The local statistics include mean (average), median, standard deviation, interquartile range, skewness, and quantile imbalance. All statistics can be geographically weighted using kernels to give more influence to neighbors closer to the focal feature.  Various neighborhood types can be used, including distance band, number of neighbors, polygon contiguity, Delaunay triangulation, and spatial weights matrix files (.swm). Summary statistics are also calculated for the distances to the neighbors of each feature. Learn more about how Neighborhood Summary Statistics works",
      "extraction_date": "2025-10-01T15:19:26.659334"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Standard Distance",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/standard-distance.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "A feature class containing a distribution of features for which the standard distance will be calculated.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Standard_Distance_Feature_Class",
          "explanation": "A polygon feature class that will contain a circle polygon for each input center. These circle polygons graphically portray the standard distance at each center point.",
          "datatype": "Feature Class"
        },
        {
          "name": "Circle_Size",
          "explanation": "Specifies the size of output circles in standard deviations.1_STANDARD_DEVIATION—The output circles will be 1 standard deviation. This is the default.2_STANDARD_DEVIATIONS—The output circles will be 2 standard deviations.3_STANDARD_DEVIATIONS—The output circles will be 3 standard deviations.",
          "datatype": "String"
        },
        {
          "name": "Weight_Field(Optional)",
          "explanation": "The numeric field used to weight locations according to their relative importance.",
          "datatype": "Field"
        },
        {
          "name": "Case_Field(Optional)",
          "explanation": "The field used to group features for separate standard distance calculations. The case field can be of integer, date, or string type.",
          "datatype": "Field"
        }
      ],
      "summary": "Measures the degree to which features are concentrated or dispersed around the geometric mean center. Learn more about how Standard Distance works",
      "extraction_date": "2025-10-01T15:19:29.074156"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Bivariate Spatial Association (Lee's L)",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/bivariate-spatial-association.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The input features containing the fields of the two analysis variables.",
          "datatype": "Feature Layer"
        },
        {
          "name": "analysis_field1",
          "explanation": "The field of the first analysis variable.\r\nThe field must be numeric.",
          "datatype": "Field"
        },
        {
          "name": "analysis_field2",
          "explanation": "The field of the second analysis variable.  The field must be numeric.",
          "datatype": "Field"
        },
        {
          "name": "out_features",
          "explanation": "The output features\r\ncontaining the local Lee's L statistics, spatial association categories, p-values, and the weighted averages of the neighbors of each feature.",
          "datatype": "Feature Class"
        },
        {
          "name": "neighborhood_type(Optional)",
          "explanation": "Specifies how neighbors of each feature will be determined. The feature is always included in the neighborhood, and all neighborhood weights are normalized to sum to 1.DISTANCE_BAND—Features within a specified critical distance of each feature will be included as neighbors. This is the default for point features.K_NEAREST_NEIGHBORS—The closest k features will be included as neighbors.CONTIGUITY_EDGES_ONLY— Polygon features that share an edge will be included as neighbors.CONTIGUITY_EDGES_CORNERS— Polygon features that share an edge or corner will be included as neighbors. This is the default for polygon features.DELAUNAY_TRIANGULATION—Points whose Delaunay triangulation (Thiessen polygons) share an edge or corner will be included as neighbors.GET_SPATIAL_WEIGHTS_FROM_FILE—Neighbors and weights will be defined by a spatial weights file.",
          "datatype": "String"
        },
        {
          "name": "distance_band(Optional)",
          "explanation": "The distance band that will be used to determine neighbors around the focal feature. If no value is provided, the distance will be the shortest distance such that each feature has at least one other neighbor in its neighborhood.\r\nFor polygons, the distance between centroids will be used to determine neighbors.",
          "datatype": "Linear Unit"
        },
        {
          "name": "num_neighbors(Optional)",
          "explanation": "The number of neighbors around each feature that will be included as neighbors.  The value does not include the feature.  For example, specifying 6 will use the feature and its six closest neighbors (seven features total).\r\nThe default is 8. The value must be at least 2.",
          "datatype": "Long"
        },
        {
          "name": "weights_matrix_file(Optional)",
          "explanation": "The path and file name of the spatial weights matrix file that defines the neighbors and weights between\r\nfeatures.",
          "datatype": "File"
        },
        {
          "name": "local_weighting_scheme(Optional)",
          "explanation": "Specifies the weighting scheme that will be applied to neighbors when calculating spatial associations.  \r\nUNWEIGHTED—Neighbors will not be weighted.  This is the default.BISQUARE—Neighbors will be weighted using a bisquare (quartic) kernel.",
          "datatype": "String"
        },
        {
          "name": "kernel_bandwidth(Optional)",
          "explanation": "The bandwidth for the bisquare kernel.  The bandwidth defines how quickly the weights decrease with distance.  Larger bandwidths will provide comparatively larger weights to neighbors that are farther away from the feature. For the k nearest neighbors neighborhood, the default value (empty) will use an adaptive bandwidth equal to the distance to the (k+1)th neighbor of the focal feature. For the fixed distance band neighborhood, the default (empty) will use the same value as the distance band.",
          "datatype": "Linear Unit"
        },
        {
          "name": "num_permutations(Optional)",
          "explanation": "Specifies the number of permutations that will be used to create reference distributions when calculating global and local p-values. All p-values are calculated using two-sided hypothesis tests.99—The analysis will use 99 permutations. With 99 permutations, the smallest possible p-value is 0.02, and all other p-values will be multiples of this value. 199—The analysis will use 199 permutations. With 199 permutations, the smallest possible p-value is 0.01, and all other p-values will be multiples of this value.499—The analysis will use 499 permutations. With 499 permutations, the smallest possible p-value is 0.004, and all other p-values will be multiples of this value. 999—The analysis will use 999 permutations. With 999 permutations, the smallest possible p-value is 0.002, and all other p-values will be multiples of this value. This option is recommended for 90 percent confidence tests. This is the default.4999—The analysis will use 4,999 permutations. With 4,999 permutations, the smallest possible p-value is 0.0004, and all other p-values will be multiples of this value. This option is recommended for 95 percent confidence tests.9999—The analysis will use 9,999 permutations. With 9,999 permutations, the smallest possible p-value is 0.0002, and all other p-values will be multiples of this value. This option is recommended for 99 percent confidence tests.",
          "datatype": "Long"
        }
      ],
      "summary": "Calculates the spatial association between two continuous variables using the Lee's L statistic. The Lee's L statistic characterizes both the degree of correlation and the degree of copatterning (similarity of spatial clustering) between the variables.  The value will be between -1 and 1 and is conceptually similar to a correlation coefficient but is adjusted to account for spatial autocorrelation of the two variables. Lee's L values close to 1 indicate that the variables are highly positively correlated and that each variable has high spatial autocorrelation (high and low values of the variables each tend to cluster together).  Values close to -1 indicate that the variables are highly negatively correlated and that each variable has highly positive spatial autocorrelation.  Values close to 0 indicate that the variables are uncorrelated, not spatially autocorrelated, or both. The Lee's L statistic can be partitioned to each input feature, called local Lee's L statistics, that show the local spatial association of the feature and its neighbors.  This can be used to determine areas that have higher or lower spatial association than the global Lee's L statistic. The local statistics can also be classified into one of several categories based on the values of the neighbors of each feature.  Both the global and local statistics are tested for statistical significance using permutations. Learn more about how Bivariate Spatial Association (Lee's L) works",
      "extraction_date": "2025-10-01T15:19:33.469657"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Causal Inference Analysis",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/causal-inference-analysis.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The input features or table containing fields of the exposure, outcome, and confounding variables.",
          "datatype": "Feature Layer; Table View"
        },
        {
          "name": "outcome_field",
          "explanation": "The numeric field of the outcome variable.\r\nThis is the variable that responds to changes in the exposure variable. The outcome variable must be continuous or binary (not categorical).",
          "datatype": "Field"
        },
        {
          "name": "exposure_field",
          "explanation": "The numeric field of the exposure variable (sometimes called the treatment variable).\r\nThis is the variable that causes changes in the outcome variable. The exposure variable must be continuous (not binary or categorical).",
          "datatype": "Field"
        },
        {
          "name": "confounding_variables[[var1, cat1], [var2, cat2],...]",
          "explanation": "The fields of the confounding variables. These are the variables that are related to both the exposure and outcome variables, and they must be balanced in order to estimate the causal effect between the exposure and outcome variables. The confounding variables can be continuous, categorical, or binary.\r\nText fields must be categorical, integer fields can be either categorical or continuous, and other numeric fields must be continuous.For the exposure-response function to be unbiased, all variables that are related to the exposure and outcome variables must be included as confounding variables.",
          "datatype": "Value Table"
        },
        {
          "name": "out_features",
          "explanation": "The output features or table containing the propensity scores, balancing weights, and a field indicating whether the feature was trimmed (excluded from the analysis). The exposure, outcome, and confounding variables are also included.",
          "datatype": "Feature Class; Table"
        },
        {
          "name": "ps_method(Optional)",
          "explanation": "Specifies the method that will be used for calculating the propensity scores of each observation. The propensity score of an observation is the likelihood (or probability) of receiving the observed exposure value, given the values of the confounding variables. Large propensity scores mean that the exposure is common for individuals with the associated confounding variables, and low propensity scores mean that the exposure value is uncommon for individuals with the confounding variables. For example, if an individual has high blood pressure (exposure) but has no risk factors for high blood pressure (confounders), this individual would have a low propensity score because it is uncommon to have high blood pressure without any risk factors. Conversely, high blood pressure for an individual with many risk factors would have a larger propensity score because it is more common. Propensity scores are estimated by a statistical model that predicts the exposure variable using the confounding variables as explanatory variables. You can use an OLS regression model or a machine learning model that uses gradient boosted regression trees.\r\nIt is recommended that you first use regression and only use gradient boosting if regression fails to balance the confounding variables.REGRESSION—OLS regression will be used to estimate the propensity scores. This is the default.GRADIENT_BOOSTING—Gradient boosted regression trees will be used to estimate the propensity scores.",
          "datatype": "String"
        },
        {
          "name": "balancing_method(Optional)",
          "explanation": "Specifies the method that will be used for balancing the confounding variables. Each method estimates a set of balancing weights that removes the correlation between the confounding variables and the exposure variable. It is recommended that you first use matching and only use inverse propensity score weighting if matching fails to balance the confounding variables. Inverse propensity score weighting will calculate faster than propensity score matching, so it also recommended when the calculation time of matching is not feasible for the data.MATCHING—Propensity score matching will be used to balance the confounding variables. This is the default.WEIGHTING—Inverse propensity score weighting will be used to balance the confounding variables.",
          "datatype": "String"
        },
        {
          "name": "enable_erf_popups(Optional)",
          "explanation": "Specifies whether pop-up charts that display the local ERF for the observation will be created for each observation.CREATE_POPUP—Local ERF pop-up charts will be created on the output features or table.NO_POPUP—Local ERF pop-up charts will not be created on the output features or table. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "out_erf_table(Optional)",
          "explanation": "A table containing values of the exposure-response function.\r\nThe table will contain 200 evenly spaced exposure values between the minimum and maximum exposure (after trimming) along with the estimated response from the exposure-response function. The response field represents the average value of the outcome variable if all members of the population received the associated exposure value. If bootstrapped confidence intervals are created, additional fields will be created containing the upper and lower bounds of the confidence interval for the exposure value, as well as the standard deviation and number of samples used to construct the confidence interval. If any target outcome or exposure values are provided, they will be appended to the end of the table.",
          "datatype": "Table"
        },
        {
          "name": "target_outcomes[target_outcomes,...](Optional)",
          "explanation": "A list of target outcome values from which required changes in exposure to achieve the outcomes will be calculated for each observation. \r\nFor example, if the exposure variable is an air quality index and the outcome variable is the annual asthma hospitalization rate of counties, you can determine how much the air quality index needs to decrease to achieve asthma hospitalization rates below 0.01, 0.005, and 0.001. For each provided target outcome value, two new fields will be created on the output. The first field contains the exposure value that would result in the target outcome, and the second field contains the required change in the exposure variable to produce the target outcome (positive values indicate that the exposure needs to increase, and negative values indicate that the exposure needs to decrease). In some cases, there will be no solution for some observations, so you should only provide target outcomes that are feasible to achieve by changing the exposure variable. For example, there is no PM2.5 level that can result in an asthma hospitalization rate of zero, so using a target outcome equal to zero will result in no solutions. If there are multiple exposure values that would result in the target outcome, the one that requires the smallest change in exposure will be used.If an output exposure-response function table is created, it will include any target outcome values and the associated exposure values appended to the end of the table. If there are multiple solutions, multiple records will be appended to the table with repeated outcome values. If local ERF pop-up charts are created, the target outcomes and associated exposure values will be shown in the pop-ups of each observation.",
          "datatype": "Double"
        },
        {
          "name": "target_exposures[target_exposures,...](Optional)",
          "explanation": "A list of target exposure values that will be used to calculate new outcomes for each observation. For each target exposure value, the tool estimates the new outcome value that the observation would receive if its exposure variable was changed to the target exposure. For example, if the exposure variable is an air quality index and the outcome variable is the annual asthma hospitalization rate of counties, you can estimate how the hospitalization rate for each observation would change for different levels of air quality. For each provided target exposure value, two new fields will be created on the output. The first field contains the estimated outcome value if the observation received the target exposure, and the second field contains the estimated change in the outcome variable (positive values indicate that the outcome variable will increase, and negative values indicate that the outcome variable will decrease). The target exposures must be within the range of the exposure variable after trimming.\r\nIf an output exposure-response function table is created, it will include any target exposure values and the associated response values appended to the end of the table. If local ERF pop-up charts are created, the target exposure values and associated outcomes will be shown in the pop-ups of each feature.",
          "datatype": "Double"
        },
        {
          "name": "lower_exp_trim(Optional)",
          "explanation": "The lower quantile that will be used to trim the exposure variable. Any observations with exposure values below this quantile will be excluded from the analysis before estimating propensity scores. The value must be between 0 and 1.\r\nThe default is 0.01, meaning that the bottom 1 percent of exposure values will be trimmed. It is recommended that you trim some of the lowest exposure values to improve the estimation of propensity scores.",
          "datatype": "Double"
        },
        {
          "name": "upper_exp_trim(Optional)",
          "explanation": "The upper quantile that will be used to trim the exposure variable. Any observations with exposure values above this quantile will be excluded from the analysis before estimating propensity scores. The value must be between 0 and 1.\r\nThe default is 0.99, meaning that the top 1 percent of exposure values will be trimmed. It is recommended that you trim some of the highest exposure values to improve the estimation of propensity scores.",
          "datatype": "Double"
        },
        {
          "name": "lower_ps_trim(Optional)",
          "explanation": "The lower quantile that will be used to trim the propensity scores. Any observations with propensity scores below this quantile will be excluded from the analysis before performing propensity score matching or inverse propensity score weighting. The value must be between 0 and 1.\r\nThe default is 0, meaning that no trimming will be performed.Lower propensity score trimming is often needed when using inverse propensity score weighting. Propensity scores near zero can produce large and unstable balancing weights.",
          "datatype": "Double"
        },
        {
          "name": "upper_ps_trim(Optional)",
          "explanation": "The upper quantile that will be used to trim the propensity scores. Any observations with propensity scores above this quantile will be excluded from the analysis before performing propensity score matching or inverse propensity score weighting. The value must be between 0 and 1.\r\nThe default is 1, meaning that no trimming will be performed.",
          "datatype": "Double"
        },
        {
          "name": "num_bins(Optional)",
          "explanation": "The number of exposure bins that will be used for propensity score matching. In matching, the exposure variable is divided into evenly spaced bins (equal intervals), and matching is performed within each bin. At least two exposure bins are required, and it is recommended that at least five exposure values be included within each bin.\r\nIf no value is provided, the value will be estimated while the tool runs and displayed in the messages.",
          "datatype": "Long"
        },
        {
          "name": "scale(Optional)",
          "explanation": "The relative weight (sometimes called the scale) of the propensity score to the exposure variable that will be used when performing propensity score matching. Within each exposure bin, matches are determined using the differences in the propensity scores and in the values of the exposure variable. This parameter specifies how to prioritize each criteria.\r\nFor example, a value equal to 0.5 means that the propensity score and exposure variables are given equal weight when finding matching observations. If no value is provided, the value will be estimated while the tool runs and displayed in the messages. The value that will provide the best balance is difficult to predict, so it is recommended that you allow the tool to estimate the value. Providing a manual value can be used to reduce the calculation time or to reproduce prior results. If the resulting exposure-response function shows vertical bands of observations with large weights, increasing the relative weight may provide a more realistic and accurate exposure-response function.",
          "datatype": "Double"
        },
        {
          "name": "balance_type(Optional)",
          "explanation": "Specifies the method that will be used to determine whether the confounding variables are balanced. After estimating weights with propensity score matching or inverse propensity score weighting, weighted correlations are calculated for each confounding variable. If the mean, median, or maximum absolute correlation is less than the balance threshold, the confounding variables are considered balanced, meaning they are sufficiently uncorrelated with the exposure variable.\r\nMEAN—Confounding variables will be considered balanced if the mean absolute correlation is less than the balance threshold. This is the default.MEDIAN—Confounding variables will be considered balanced if the median absolute correlation is less than the balance threshold.MAXIMUM—Confounding variables will be considered balanced if the maximum absolute correlation is less than the balance threshold.",
          "datatype": "String"
        },
        {
          "name": "balance_threshold(Optional)",
          "explanation": "The threshold value that will be compared to the weighted correlations of the confounding variables to determine if they are balanced. The value must be between 0 and 1. A larger balance threshold indicates a larger tolerance for imbalance in the confounding variables and bias in the exposure-response function. The default is 0.1.",
          "datatype": "Double"
        },
        {
          "name": "bw_method(Optional)",
          "explanation": "Specifies the method that will be used to estimate the bandwidth of the exposure-response function.\r\nPLUG_IN—A plug-in method will be used to estimate the bandwidth. This is the default.CV—The bandwidth that minimizes the mean square cross validation error will be used.MANUAL—A custom bandwidth will be used.",
          "datatype": "String"
        },
        {
          "name": "bandwidth(Optional)",
          "explanation": "The bandwidth value of the exposure-response function when using a manual bandwidth.",
          "datatype": "Double"
        },
        {
          "name": "create_bootstrap_ci(Optional)",
          "explanation": "Specifies whether 95 percent confidence intervals for the exposure-response function will be created using M-out-of-N bootstrapping.CREATE_CI—Confidence intervals for the exposure-response function will be created.NO_CI—Confidence intervals for the exposure-response function will not be created. This is the default.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Estimates the causal effect of a continuous exposure variable on a continuous outcome variable by approximating a randomized experiment and controlling for confounding variables. In statistical experiments, the cause-and-effect relationship between an exposure variable (such as the dose of a drug) and an outcome variable (such as a health outcome) is determined by randomly assigning each participant a particular exposure level so that any differences in the outcomes must be due only to the differences in the exposures and not any other attributes of the participants, such as age, preexisting conditions, and healthcare access. However, it is frequently impossible or unethical to perform controlled experiments, so relationships are often established through observational studies. For example, to study the effect of pollution on depression rates, you cannot intentionally expose individuals to high pollution to see the effect on depression. Instead, you can only observe the exposure to pollution and the depression rates of the individuals in your sample. However, because there are many variables (called confounding variables) that impact both pollution and depression, the causal effect cannot be directly estimated without controlling for these variables. To emulate the process of a randomized, controlled experiment, the tool calculates propensity scores for each observation, and the propensity scores are used to weight the observations in such a way that the causal relationship between the exposure and outcome variables is maintained, but correlations between the confounding variables and the exposure variable are removed. This weighted dataset is often called a pseudopopulation, and it has analogous properties to a controlled experiment in which each participant is randomly assigned an exposure. Using the weighted observations, the tool creates an exposure-response function (ERF) that estimates what the average outcome would be if all members of the population received a given exposure value but did not change their confounding variables. Learn more about how Causal Inference Analysis works",
      "extraction_date": "2025-10-01T15:19:36.590006"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Colocation Analysis",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/colocationanalysis.htm",
      "parameters": [
        {
          "name": "input_type",
          "explanation": "Specifies whether the in_features_of_interest  parameter values will come from the same dataset with specified categories, different datasets with specified categories, or different datasets that will be treated as their own category (for example, one dataset with all points representing cheetahs and a second dataset in which all points represent gazelles).SINGLE_DATASET—The categories to be analyzed exist in a field in a single dataset.TWO_DATASETS—The categories to be analyzed exist in fields of separate datasets.DATASETS_WITHOUT_CATEGORIES—Two separate datasets representing two categories will be analyzed.",
          "datatype": "String"
        },
        {
          "name": "in_features_of_interest",
          "explanation": "The feature class containing points with representative categories.",
          "datatype": "Feature Layer"
        },
        {
          "name": "output_features",
          "explanation": "The output feature class containing all the in_features parameter values with fields representing the local colocation quotient scores and p-values.",
          "datatype": "Feature Class"
        },
        {
          "name": "field_of_interest(Optional)",
          "explanation": "The field containing the category or categories  to be analyzed.",
          "datatype": "Field"
        },
        {
          "name": "time_field_of_interest(Optional)",
          "explanation": "A date field with an optional  time stamp for each feature to analyze points using a space-time window.  Features near each other in space and time will be considered neighbors and will be  analyzed together.",
          "datatype": "Field"
        },
        {
          "name": "category_of_interest(Optional)",
          "explanation": "The base category for the analysis.  The tool will identify, for each category_of_interest value, the degree to which the base category is attracted to or colocated with the neighboring_category parameter value.",
          "datatype": "String"
        },
        {
          "name": "input_feature_for_comparison(Optional)",
          "explanation": "The input feature class containing the points with the categories that will be compared.",
          "datatype": "Feature Layer"
        },
        {
          "name": "field_for_comparison(Optional)",
          "explanation": "The field from the input_feature_for_comparison parameter containing the category to be compared.",
          "datatype": "Field"
        },
        {
          "name": "time_field_for_comparison(Optional)",
          "explanation": "A date field with a time stamp for each feature to analyze your points using a space-time window.  Features near each other in space and time will be considered neighbors and will be  analyzed together.",
          "datatype": "Field"
        },
        {
          "name": "category_for_comparison(Optional)",
          "explanation": "The neighboring category for the analysis.  The tool will identify the degree to which the category_of_interest parameter value is attracted to or isolated from the  category_for_comparison value.",
          "datatype": "String"
        },
        {
          "name": "neighborhood_type",
          "explanation": "Specifies how the spatial relationships among features will be defined.DISTANCE_BAND—Each feature will be analyzed within the context of neighboring features. Neighboring features inside the specified critical distance specified by the distance_band parameter receive a weight of one and exert influence on computations for the target feature. Neighboring features outside the critical distance receive a weight of zero and have no influence on a target feature's computations.K_NEAREST_NEIGHBORS—The closest k features will be included in the analysis as neighbors.  The number of neighbors is specified by the number_of_neighbors parameter.  The neighbor's influence in the analysis is weighted based on the distance to the farthest neighbor. This is the default.GET_SPATIAL_WEIGHTS_FROM_FILE—When SINGLE_DATASET is used as the input_type, spatial relationships will be defined by a specified spatial weights matrix file.  The neighbor's influence in the analysis is weighted based on the distance to the farthest neighbor. The path to the spatial weights file is specified by the weights_matrix_file parameter.",
          "datatype": "String"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "The number of neighbors around each feature that will be used to test for local relationships between categories.  If no value is provided, the default of 8 is used.  The provided value must be large enough to detect the relationships between features but small enough to still identify local patterns.",
          "datatype": "Long"
        },
        {
          "name": "distance_band(Optional)",
          "explanation": "The neighborhood size is a constant or fixed distance for each feature.  All features within this distance will be used to test for local relationships between categories.  If no value is provided, the distance used will be the average distance at which each feature has at least eight neighbors.",
          "datatype": "Linear Unit"
        },
        {
          "name": "weights_matrix_file(Optional)",
          "explanation": "The path to a file containing weights that define spatial, and potentially temporal, relationships among features.",
          "datatype": "File"
        },
        {
          "name": "temporal_relationship_type(Optional)",
          "explanation": "Specifies how temporal relationships among features will be defined.\r\nBEFORE—The time window will extend back in time for each of the in_features_of_interest values.  Neighboring features must have a date/time stamp that occurs before the date/time stamp of the feature of interest to be included in the analysis. This is the default.AFTER—The time window will extend forward in time for each of the in_features_of_interest values.  Neighboring features must have a date/time stamp that occurs after the date/time stamp of the feature of interest to be included in the analysis.SPAN—The time window will extend both back and forward in time for each of the in_features_of_interest values. Neighboring features that have a date/time stamp that occurs within the time_step_interval value before or after the date/time stamp of the feature of interest will be included in the analysis. For example, if the time_step_interval parameter is set to 1 week, the window will look 1 week before and 1 week after the target feature.",
          "datatype": "String"
        },
        {
          "name": "time_step_interval(Optional)",
          "explanation": "An integer and unit of measurement representing the number of time units composing the time window.",
          "datatype": "Time Unit"
        },
        {
          "name": "number_of_permutations(Optional)",
          "explanation": "The number of permutations that will be used to create a reference distribution. Choosing the number of permutations is a balance between precision and increased processing time. Choose your preference of speed versus precision. More robust and precise results take longer to calculate.99—The analysis will use 99 permutations. With 99 permutations, the smallest possible pseudo p-value is 0.02 and all other pseudo p-values will be multiples of this value. This is the default.199—The analysis will use 199 permutations. With 199 permutations, the smallest possible pseudo p-value is 0.01 and all other pseudo p-values will be even multiples of this value.499—The analysis will use 499 permutations. With 499 permutations, the smallest possible pseudo p-value is 0.004 and all other pseudo p-values will be even multiples of this value.999—The analysis will use 999 permutations. With 999 permutations, the smallest possible pseudo p-value is 0.002 and all other pseudo p-values will be even multiples of this value.9999—The analysis will use 9,999 permutations. With 9,999 permutations, the smallest possible pseudo p-value is 0.0002 and all other pseudo p-values will be even multiples of this value.",
          "datatype": "Long"
        },
        {
          "name": "local_weighting_scheme(Optional)",
          "explanation": "Specifies the kernel type that will be used to provide the spatial weighting. The kernel defines how each feature is related to other features within its neighborhood.BISQUARE—Features will be weighted based on the distance to the farthest neighbor or the edge of the distance band, and a weight of 0 will be assigned to any feature outside the neighborhood specified.GAUSSIAN—Features will be weighted based on the distance to the farthest neighbor or the edge of the distance band but drop off more quickly than the Bisquare option.  A weight of 0 will be assigned to any feature outside the neighborhood specified.  This is the default.NONE—No weighting scheme will be applied, and all features within the neighborhood will be given a weight of 1 and contribute equally.  All features outside the neighborhood will be given a weight of 0.",
          "datatype": "String"
        },
        {
          "name": "output_table(Optional)",
          "explanation": "A table that includes the global colocation quotients between all the categories in the \r\nField of Interest parameter and all the categories in the Field Containing Neighboring Category parameter.  This table can help you determine the local categories to analyze.If Datasets without categories is used as the Input Type parameter value, global colocation quotients will be calculated for each dataset and between each dataset.",
          "datatype": "Table"
        }
      ],
      "summary": "Measures local patterns of spatial association, or colocation, between two categories of point features using the colocation quotient statistic. Learn more about how Colocation Analysis works",
      "extraction_date": "2025-10-01T15:19:39.400078"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Estimate Time to Event",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/estimate-time-to-event.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The input features or table containing fields of the age, explanatory variables, and event indicator for each observation.",
          "datatype": "Table View"
        },
        {
          "name": "age_field",
          "explanation": "The numeric field of the age of the observation. This is often the age of the observation, but in general, it is the amount of time starting from the first moment the event could have occurred and ending when the event occurred (or ending when the observation was censored). The unit of the age (hours, days, years, and so on) is not provided, but all results should be interpreted in that time unit. For example, if the age values are in days, and the tool predicts an event time two time units in the future, this means two days in the future.",
          "datatype": "Field"
        },
        {
          "name": "event_field",
          "explanation": "The field containing an indicator or whether the event has occurred for the observation. The field must only contain the values 0 or 1. A value of 0 indicates that the event has not occurred (a censored observation), and a value of 1 indicates that the event has occurred (an uncensored observation). For example, to estimate the lifespan of trees, a value of 0 means that the tree is alive (the event, tree death, has not occurred), and a value of 1 means that the tree is dead.",
          "datatype": "Field"
        },
        {
          "name": "out_features",
          "explanation": "The output features or table containing the predicted times to the event for observations in which the event has not occurred.",
          "datatype": "Feature Class; Table"
        },
        {
          "name": "explanatory_variables[[Variable, Categorical],...](Optional)",
          "explanation": "A list of fields representing the explanatory variables that help predict the time to the event. Specify the variable as CATEGORICAL if it represents classes or categories such as material type or income bracket, and specify NUMERIC if it is continuous.",
          "datatype": "Value Table"
        },
        {
          "name": "enable_survival_curve_popups(Optional)",
          "explanation": "Specifies whether pop-up charts will be generated for each output record. The pop-up charts show the baseline survival curve for each record and an additional time-to-event curve for censored observations.CREATE_POPUP—Pop-up charts will be generated for each record in the dataset. This is the default.NO_POPUP—Pop-up charts will not be generated.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Predicts the time until an event occurs based on the prior times to the event. Explanatory variables can be used to improve the predictions, and the tool can determine which variables increase or decrease the time until the event. Learn more about how Estimate Time to Event works",
      "extraction_date": "2025-10-01T15:19:41.829381"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Exploratory Regression",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/exploratory-regression.htm",
      "parameters": [
        {
          "name": "Input_Features",
          "explanation": "The feature class or feature layer containing the dependent and candidate explanatory variables to analyze.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Dependent_Variable",
          "explanation": "The numeric field containing the observed values you want to model using OLS.",
          "datatype": "Field"
        },
        {
          "name": "Candidate_Explanatory_Variables[Candidate_Explanatory_Variables,...]",
          "explanation": "A list of fields to try as OLS model explanatory variables.",
          "datatype": "Field"
        },
        {
          "name": "Weights_Matrix_File(Optional)",
          "explanation": "A file containing spatial weights that define the spatial relationships among your input features.  This file is used to assess spatial autocorrelation among regression residuals.  You can use the Generate Spatial Weights Matrix File tool to create this.  When you do not provide a spatial weights matrix file, residuals are assessed for spatial autocorrelation based on each feature's 8 nearest neighbors.   Note:  The spatial weights matrix file is only used to analyze spatial structure in model residuals; it is not used to build or to calibrate any of the OLS models.",
          "datatype": "File"
        },
        {
          "name": "Output_Report_File(Optional)",
          "explanation": "The report file contains tool results, including details about any models found that passed all the search criteria you entered.  This output file also contains diagnostics to help you fix common regression problems in the case that you don't find any passing models.",
          "datatype": "File"
        },
        {
          "name": "Output_Results_Table(Optional)",
          "explanation": "The optional output table created containing the explanatory variables and diagnostics for all of the models within the Coefficient p-value \r\nand VIF value cutoffs.",
          "datatype": "Table"
        },
        {
          "name": "Maximum_Number_of_Explanatory_Variables(Optional)",
          "explanation": "All models with explanatory variables up to the value entered here will be assessed.  If, for example, the Minimum_Number_of_Explanatory_Variables is 2 and the Maximum_Number_of_Explanatory_Variables is 3, the Exploratory Regression tool will try all models with every combination of two explanatory variables, and all models with every combination of three explanatory variables.",
          "datatype": "Long"
        },
        {
          "name": "Minimum_Number_of_Explanatory_Variables(Optional)",
          "explanation": "This value represents the minimum number of explanatory variables for models evaluated.  If, for example, the Minimum_Number_of_Explanatory_Variables is 2 and the Maximum_Number_of_Explanatory_Variables is 3, the Exploratory Regression tool will try all models with every combination of two explanatory variables, and all models with every combination of three explanatory variables.",
          "datatype": "Long"
        },
        {
          "name": "Minimum_Acceptable_Adj_R_Squared(Optional)",
          "explanation": "This is the lowest Adjusted R-Squared value you consider a passing model.  If a model passes all of your other search criteria, but has an Adjusted R-Squared value smaller than the value entered here, it will not show up as a Passing Model in the Output_Report_File.  Valid values for this parameter range from 0.0 to 1.0.  The default value is 0.5, indicating that passing models will explain at least fifty percent of the variation in the dependent variable.",
          "datatype": "Double"
        },
        {
          "name": "Maximum_Coefficient_p_value_Cutoff(Optional)",
          "explanation": "For each model evaluated, OLS computes explanatory variable coefficient p-values.  The cutoff p-value you enter here represents the confidence level you require for all coefficients in the model in order to consider the model passing.  Small p-values reflect a stronger confidence level.  Valid values for this parameter range from 1.0 down to 0.0, but will most likely be 0.1, 0.05, 0.01, 0.001, and so on.  The default value is 0.05, indicating passing models will only contain explanatory variables whose coefficients are statistically at the 95 percent confidence level (p-values smaller than 0.05).  To relax this default you would enter a larger p-value cutoff, such as 0.1.  If you are getting lots of passing models, you will likely want to make this search criteria more stringent by decreasing the default p-value cutoff from 0.05 to 0.01 or smaller.",
          "datatype": "Double"
        },
        {
          "name": "Maximum_VIF_Value_Cutoff(Optional)",
          "explanation": "This value reflects how much redundancy (multicollinearity) among model explanatory variables you will tolerate.  \r\n When the VIF (Variance Inflation Factor) value is higher than about 7.5, multicollinearity can make a model unstable; consequently, 7.5 is the default value here.  If you want your passing models to have less redundancy, you would enter a smaller value, such as 5.0, for this parameter.",
          "datatype": "Double"
        },
        {
          "name": "Minimum_Acceptable_Jarque_Bera_p_value(Optional)",
          "explanation": "The p-value returned by the Jarque-Bera diagnostic test indicates whether the model residuals are normally distributed.  If the p-value is statistically significant (small),   \r\nthe model residuals are not normal and the model is biased.  Passing models should have large Jarque-Bera p-values.  The default minimum acceptable p-value is 0.1.  Only models returning p-values larger than this minimum will be considered passing.  If you are having trouble finding unbiased passing models, and decide to relax this criterion, you might enter a smaller minimum p-value such as 0.05.",
          "datatype": "Double"
        },
        {
          "name": "Minimum_Acceptable_Spatial_Autocorrelation_p_value(Optional)",
          "explanation": "For models that pass all of the other search criteria, the Exploratory Regression tool will check model residuals for spatial clustering using Global Moran's I.\r\n When the p-value for this diagnostic test is statistically significant (small), it indicates the model is very likely missing key explanatory variables (it isn't telling the whole story).  Unfortunately, if you have spatial autocorrelation in your regression residuals, your model is misspecified, so you cannot trust your results.  Passing models should have large p-values for this diagnostic test.  The default minimum p-value is 0.1.  Only models returning p-values larger than this minimum will be considered passing.  If you are having trouble finding properly specified models because of this diagnostic test, and decide to relax this search criteria, you might enter a smaller minimum such as 0.05.",
          "datatype": "Double"
        }
      ],
      "summary": "Evaluates all possible combinations of the input candidate explanatory variables, looking for OLS models that best explain the dependent variable within the context of user-specified criteria. Learn more about how Exploratory Regression works",
      "extraction_date": "2025-10-01T15:19:44.413691"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "OLS",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/ordinary-least-squares.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class containing the dependent and independent variables for analysis.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Unique_ID_Field",
          "explanation": "An integer field containing a different value for every feature in the Input Feature Class.",
          "datatype": "Field"
        },
        {
          "name": "Output_Feature_Class",
          "explanation": "The output feature class that will receive dependent variable estimates and residuals.",
          "datatype": "Feature Class"
        },
        {
          "name": "Dependent_Variable",
          "explanation": "The numeric field containing values for what you are trying to model.",
          "datatype": "Field"
        },
        {
          "name": "Explanatory_Variables[Explanatory_Variables,...]",
          "explanation": "A list of fields representing explanatory variables in your regression model.",
          "datatype": "Field"
        },
        {
          "name": "Coefficient_Output_Table(Optional)",
          "explanation": "The full path to an optional table that will receive model coefficients, standardized coefficients, standard errors, and probabilities for each explanatory variable.",
          "datatype": "Table"
        },
        {
          "name": "Diagnostic_Output_Table(Optional)",
          "explanation": "The full path to an optional table that will receive model summary diagnostics.",
          "datatype": "Table"
        },
        {
          "name": "Output_Report_File(Optional)",
          "explanation": "The path to the optional PDF file \r\nthe tool will create.  This report file includes model diagnostics, graphs, and notes to help you interpret the OLS results.",
          "datatype": "File"
        }
      ],
      "summary": "Performs global Ordinary Least Squares (OLS) linear regression to generate predictions or to model a dependent variable in terms of its relationships to a set of explanatory variables. The functionality of this tool is included in the Generalized Linear Regression tool added at ArcGIS Pro 2.3.  The Generalized Linear Regression tool supports additional models.",
      "extraction_date": "2025-10-01T15:19:47.028294"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Forest-based and Boosted Classification and Regression",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/forestbasedclassificationregression.htm",
      "parameters": [
        {
          "name": "prediction_type",
          "explanation": "Specifies the \r\noperation mode that will be used. The tool can be run to train a model to only assess performance, predict features, or create a prediction surface.TRAIN—A model will be trained, but no predictions will be\r\ngenerated.\r\nUse this option to assess the accuracy of the model before generating predictions. This option will output model diagnostics in the messages window and a chart of variable importance. This is the default.PREDICT_FEATURES—Predictions or classifications will be generated for features. Explanatory variables must be provided for both the training features and the features to be predicted. The output of this option will be a feature class, model diagnostics in the messages window, and an optional table and chart of variable importance.PREDICT_RASTER—A prediction raster will be generated for the area where the explanatory rasters intersect.\r\nExplanatory rasters must be provided for both the training area and the area to be predicted. The output of this option will be a prediction surface, model diagnostics in the messages window, and an optional table and chart of variable importance.",
          "datatype": "String"
        },
        {
          "name": "in_features",
          "explanation": "The feature class containing the variable_predict parameter value and, optionally, the explanatory training variables from fields.",
          "datatype": "Feature Layer"
        },
        {
          "name": "variable_predict(Optional)",
          "explanation": "The variable from the in_features parameter value containing the values to be used to train the model. This field contains known (training) values of the variable that will be used to predict at unknown locations.",
          "datatype": "Field"
        },
        {
          "name": "treat_variable_as_categorical(Optional)",
          "explanation": "CATEGORICAL—The variable_predict value is a categorical variable and classification will be performed.NUMERIC—The variable_predict value is continuous and regression will be performed. This is the default",
          "datatype": "Boolean"
        },
        {
          "name": "explanatory_variables[[Variable, Categorical],...](Optional)",
          "explanation": "A list of fields representing the explanatory variables that help predict the value or category of the variable_predict value. Use the treat_variable_as_categorical parameter for any variables that represent classes or categories (such as land cover or presence or absence).\r\nSpecify the variable as CATEGORICAL if it represents classes or categories such as land cover or presence or absence, and specify NUMERIC if it is continuous.",
          "datatype": "Value Table"
        },
        {
          "name": "distance_features[distance_features,...](Optional)",
          "explanation": "The explanatory training distance features. Explanatory variables will be automatically created by calculating a distance from the provided features to the in_features values. Distances will be calculated from each of the features in the in_features value to the nearest  distance_features values. If the input distance_features values are polygons or lines, the distance attributes will be calculated as the distance between the closest segments of the pair of features.",
          "datatype": "Feature Layer"
        },
        {
          "name": "explanatory_rasters[[Variable, Categorical],...](Optional)",
          "explanation": "The explanatory training variables extracted from rasters. Explanatory training variables will be automatically created by extracting raster cell values. For each feature in the in_features parameter, the value of the raster cell is extracted at that exact location. Bilinear raster resampling is used when extracting the raster value unless it is specified as categorical, in which case nearest neighbor assignment is used. Specify the raster as CATEGORICAL if it represents classes or categories such as land cover or presence or absence, and specify NUMERIC if it is continuous.",
          "datatype": "Value Table"
        },
        {
          "name": "features_to_predict(Optional)",
          "explanation": "A feature class representing the locations where predictions will be made. This feature class must also contain any explanatory variables provided as fields that correspond to those used from the training data.",
          "datatype": "Feature Layer"
        },
        {
          "name": "output_features(Optional)",
          "explanation": "The output feature class containing the prediction results.",
          "datatype": "Feature Class"
        },
        {
          "name": "output_raster(Optional)",
          "explanation": "The output raster containing the prediction results. The default cell size will be the maximum cell size of the raster inputs. To set a different cell size, use the Cell Size environment setting.",
          "datatype": "Raster Dataset"
        },
        {
          "name": "explanatory_variable_matching[[Prediction, Training],...](Optional)",
          "explanation": "A list of the explanatory_variables values specified from the in_features parameter on the right and corresponding fields from the features_to_predict parameter on the left,\r\nfor example, [[\"LandCover2000\", \"LandCover2010\"], [\"Income\", \"PerCapitaIncome\"]].",
          "datatype": "Value Table"
        },
        {
          "name": "explanatory_distance_matching[[Prediction, Training],...](Optional)",
          "explanation": "A list of the distance_features values specified for the in_features parameter on the right and  corresponding feature sets from the features_to_predict parameter on the left. explanatory_distance_features values that are more appropriate for the features_to_predict parameter can be provided if those used for training are in a different study area or time period.",
          "datatype": "Value Table"
        },
        {
          "name": "explanatory_rasters_matching[[Prediction, Training],...](Optional)",
          "explanation": "A list of the explanatory_rasters values specified for the in_features on the right and corresponding rasters from the features_to_predict parameter or output_raster parameter to be created on the left. The explanatory_rasters values that are more appropriate for the features_to_predict parameter can be provided if those used for training are in a different study area or time period.",
          "datatype": "Value Table"
        },
        {
          "name": "output_trained_features(Optional)",
          "explanation": "The explanatory variables used for training (including sampled raster values and distance calculations), as well as the observed variable_predict field and accompanying predictions that will be used to further assess performance of the trained model.",
          "datatype": "Feature Class"
        },
        {
          "name": "output_importance_table(Optional)",
          "explanation": "The table that will contain information describing the importance of each explanatory variable (fields, distance features, and rasters) used to create the model.",
          "datatype": "Table"
        },
        {
          "name": "use_raster_values(Optional)",
          "explanation": "Specifies how polygons will be treated when training the model\r\nif the in_features values are polygons with a categorical variable_predict value and only explanatory_rasters values have been provided.TRUE—The polygon will be divided into all of the raster cells with centroids falling within the polygon. The raster values at each centroid will be extracted and used to train the model. The model will no longer be trained on the polygon; it will be trained on the raster values extracted for each cell centroid. This is the default.FALSE—Each polygon will be assigned the average value of the underlying continuous rasters and the majority for underlying categorical rasters.",
          "datatype": "Boolean"
        },
        {
          "name": "number_of_trees(Optional)",
          "explanation": "The number of trees that will be created in the Forest-based and Gradient Boosted models. The default is 100. If the model_type parameter value is FOREST-BASED, more trees will generally result in more accurate model predictions; however, the model will take longer to calculate. If the model_type parameter value is GRADIENT_BOOSTED, more trees may result in more accurate model predictions; however, they may also lead to overfitting the training data. To avoid overfitting the data, provide values for the maximum_depth, reg_lambda, gamma, and  eta parameters.",
          "datatype": "Long"
        },
        {
          "name": "minimum_leaf_size(Optional)",
          "explanation": "The minimum number of observations required to keep a leaf (that is, the terminal node on a tree without further splits). \r\nThe default minimum for regression is 5 and the default for classification is 1. For very large data, increasing these numbers will decrease the run time of the tool.",
          "datatype": "Long"
        },
        {
          "name": "maximum_depth(Optional)",
          "explanation": "The maximum number of splits that will be made down a tree. Using a large maximum depth, more splits will be created, which may increase the chances of overfitting the model. If the model_type parameter value is FOREST-BASED, the default is data driven and depends on the number of trees created and the number of variables included. If the model_type parameter value is GRADIENT_BOOSTED, the default is 6.",
          "datatype": "Long"
        },
        {
          "name": "sample_size(Optional)",
          "explanation": "The percentage of the in_features values that will be used for each decision tree. The default is 100 percent of the data. Samples for each tree are taken randomly from two-thirds of the data specified. Each decision tree in the forest is created using a random sample or subset (approximately two-thirds) of the training data available. Using a lower percentage of the input data for each decision tree decreases the run time of the tool for very large datasets.",
          "datatype": "Long"
        },
        {
          "name": "random_variables(Optional)",
          "explanation": "The number of explanatory variables that will be used to create each decision tree.Each decision tree in the forest is created using a random subset of the specified explanatory variables. Increasing the number of variables used in each decision tree will increase the chances of overfitting the model, particularly if there is one or more dominant variables. A common practice is to use the square root of the total number of explanatory variables (fields, distances, and rasters combined) if the variable_predict value is categorical or to divide the total number of explanatory variables (fields, distances, and rasters combined) by 3 if the variable_predict value is numeric.",
          "datatype": "Long"
        },
        {
          "name": "percentage_for_training(Optional)",
          "explanation": "The percentage (between 10 percent and 50 percent) of \r\nthe in_features values that will be reserved as the test dataset for validation. The model will be trained without this random subset of data, and the observed values for those features will be compared to the predicted value. The default is 10 percent.",
          "datatype": "Double"
        },
        {
          "name": "output_classification_table(Optional)",
          "explanation": "A confusion matrix that  summarizes the performance of the model created on the validation data. The matrix compares the model predicted categories for the validation data to the actual categories. This table can be used to calculate additional diagnostics that are not included in the output messages.  This parameter is available when the variable_predict value is categorical and the treat_variable_as_categorical  parameter value is CATEGORICAL.",
          "datatype": "Table"
        },
        {
          "name": "output_validation_table(Optional)",
          "explanation": "A table that contains the \r\nR2 for each model if the variable_predict value is not categorical, or the accuracy of each model if the value is categorical. This table includes a bar chart of the distribution of accuracies or the  R2 values. This distribution can be used to assess the stability of the model. This parameter is available when the number_validation_runs value is greater than 2.",
          "datatype": "Table"
        },
        {
          "name": "compensate_sparse_categories(Optional)",
          "explanation": "Specifies whether each category in the training dataset, regardless of its frequency, will be represented in each tree.\r\nThis parameter is available when the model_type parameter value is FOREST-BASED.TRUE—Each tree will include every category that is represented in the training dataset.FALSE—Each tree will be created based on a random sample of the categories in the training dataset. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "number_validation_runs(Optional)",
          "explanation": "The number of iterations of the tool. The distribution of R-squared values or accuracies of all the models  can be displayed using the output_validation_table parameter. If  the prediction_type parameter value is PREDICT_RASTER or PREDICT_FEATURES, the model that produced the median R-squared value or accuracy will be used to make predictions. Using the median value helps ensure stability of the predictions.",
          "datatype": "Long"
        },
        {
          "name": "calculate_uncertainty(Optional)",
          "explanation": "Specifies whether prediction uncertainty will be calculated when training, predicting to features, or predicting to raster.\r\nThis parameter is available when the model_type parameter value  is FOREST-BASED.TRUE— A prediction uncertainty interval will be calculated.FALSE— Uncertainty will not be calculated. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "output_trained_model(Optional)",
          "explanation": "An output model file that will save the trained model, which can be used later for prediction.",
          "datatype": "File"
        },
        {
          "name": "model_type(Optional)",
          "explanation": "Specifies the method that will be used to create the model. \r\nFOREST-BASED—A model will be created using an adaptation of the random forest algorithm. The model will use the votes from hundreds of decisions trees. Each decision tree will be created from a randomly generated subset of the original data and original variables.GRADIENT_BOOSTED—A model will be created using the Extreme Gradient Boosting (XGBoost) algorithm. The model will create a sequence of hundreds of trees in which each subsequent tree corrects the errors of the previous trees.",
          "datatype": "String"
        },
        {
          "name": "reg_lambda(Optional)",
          "explanation": "A regularization term that reduces the model's sensitivity to individual features. Increasing this value will make the model more conservative and prevent overfitting the training data.  If the value is 0, the model\r\nbecomes the traditional Gradient Boosting model. The default is 1. This parameter is available when the model_type parameter value  is GRADIENT_BOOSTED.",
          "datatype": "Double"
        },
        {
          "name": "gamma(Optional)",
          "explanation": "A threshold for the minimum loss reduction needed to split trees.Potential splits are evaluated for their loss reduction. If the candidate split has a higher loss reduction than this threshold value, the partition will occur. Higher threshold values avoid overfitting and result in more conservative models with fewer partitions. The default is 0.This parameter is available when the model_type  parameter value is GRADIENT_BOOSTED.",
          "datatype": "Double"
        },
        {
          "name": "eta(Optional)",
          "explanation": "A value that reduces the contribution of each tree to the final prediction. The value should be greater than 0 and less than or equal to 1. A lower learning rate prevents overfitting the model; however, it may require longer computation times. The default is 0.3.This parameter is available when the model_type parameter value  is GRADIENT_BOOSTED.",
          "datatype": "Double"
        },
        {
          "name": "max_bins(Optional)",
          "explanation": "The number of bins that the training data will be divided into \r\nto search for the best splitting point. The value cannot be 1. The default is 0, which corresponds to the use of a greedy algorithm.  A greedy algorithm will create a candidate split at every data point. Providing too few bins for searching is not recommended because it will lead to poor model prediction performance.This parameter is available when the model_type parameter value  is GRADIENT_BOOSTED.",
          "datatype": "Long"
        },
        {
          "name": "optimize(Optional)",
          "explanation": "Specifies whether an optimization method will be used to find the set of hyperparameters that achieve optimal model performance.\r\nTRUE—An optimization method will be used to find the set of hyperparameters. FALSE—An optimization method will not be used. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "optimize_algorithm(Optional)",
          "explanation": "Specifies the optimization method that will be used to select and test search points to find the optimal set of hyperparameters. Search points are combinations of hyperparameters within the search space specified by the model_param_setting parameter. This option is available when the optimize parameter value is TRUE.RANDOM—A stratified random sampling algorithm will be used to select the search points within the search space. This is the default.RANDOM_ROBUST—A stratified random sampling algorithm will be used to select the search points. Each search will be run 10 times using a different random seed. The result of each search will be the median best run determined by the optimize_target parameter value.  This option is available when the model_type parameter value is FOREST-BASED.GRID—Every search point within the search space will be selected.",
          "datatype": "String"
        },
        {
          "name": "optimize_target(Optional)",
          "explanation": "Specifies the objective function or value that will be minimized or maximized to find the optimal \r\nset of hyperparameters.R2—The optimization method will maximize R2 to find the optimal set of hyperparameters. This option is only available when the variable to predict is not categorical. This is the default when the variable to predict is not categorical.RMSE—The optimization method will minimize root mean square error to find the optimal set of hyperparameters. This option is only available when the variable to predict is not categorical.ACCURACY—The optimization method will maximize accuracy to find the optimal model.  This option is only available when the variable to predict is categorical. This is the default when the variable to predict is categorical.MCC—The optimization method will maximize Matthews correlation coefficient to find the optimal set of hyperparameters. This option is only available when the variable to predict is categorical.F1-SCORE—The optimization method will maximize the F1-Score to find the optimal set of hyperparameters. This option is only available when the variable to predict is categorical.",
          "datatype": "String"
        },
        {
          "name": "num_search(Optional)",
          "explanation": "The number of search points within the search space specified by the model_param_setting parameter \r\nthat will be tested. This parameter is available when the optimize_algorithm parameter value is RANDOM or RANDOM_ROBUST.",
          "datatype": "Long"
        },
        {
          "name": "model_param_setting[model_param_setting,...](Optional)",
          "explanation": "A list of hyperparameters and their search spaces. Customize the search space of each hyperparameter by providing a lower bound, upper bound, and interval.\r\nThe lower bound and upper bound specify the range of possible values for the hyperparameter.The following is the range of valid values for each hyperparameter:Number of Trees (number_of_trees)—An integer value greater than 1.Maximum Tree Depth (maximum_depth)—An integer value greater than or equal to 0.Minimum Leaf Size (minimum_leaf_size)—An integer value greater than 1.Data Available per Tree (%) (sample_size)—An integer value greater than 0 and less than or equal to 100.Number of Randomly Sampled Variables (random_variables)—An integer value less than or equal to the number of explanatory variables. This includes the explanatory variables from fields, distance features, and rasters.Learning Rate (Eta) (eta)—A double value greater than 0 and less than or equal to 1.L2 Regularization (Lambda) (reg_lambda)—A double value greater than or equal to 0.Minimum Loss Reduction for Splits (Gamma) (gamma)—A double value greater than or equal to 0.Maximum Number of Bins for Searching Splits (max_bins)—An integer value greater than 1 or the value 0. A value of 0 means the model will create a candidate split at every data point.",
          "datatype": "Value Table"
        },
        {
          "name": "output_param_tuning_table(Optional)",
          "explanation": "A table that contains the parameter settings and objective values for each optimization trial. The output includes a chart of all the trials and their objective values. This option is available when optimize  is TRUE.",
          "datatype": "Table"
        },
        {
          "name": "include_probabilities(Optional)",
          "explanation": "For categorical variables to predict, specifies whether the probability of every category of the categorical variable or only the probability of the record's category will be predicted.\r\nFor example, if a categorical variable has categories A, B, and C, and the first record has category B, use this parameter to specify whether the probability for categories A, B, and C will be predicted or only the probability of category B will be predicted.ALL_PROBABILITIES—Probabilities for all categories of the categorical variable will be predicted and included in the trained features output and predicted features output.HIGHEST_PROBABILITY_ONLY—Only the probability of the category of the record will be predicted and included in the trained features output and predicted features output. This is the default.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Creates models and generates predictions using one of two supervised machine learning methods: an adaptation of the random forest algorithm developed by Leo Breiman and Adele Cutler or the Extreme Gradient Boosting (XGBoost) algorithm developed by Tianqi Chen and Carlos Guestrin. Predictions can be performed for both categorical variables (classification) and continuous variables (regression). Explanatory variables can take the form of fields in the attribute table of the training features, raster datasets, and distance features used to calculate proximity values for use as additional variables. In addition to validation of model performance based on the training data, predictions can be made to either features or a prediction raster. Learn more about how Forest-based and Boosted Classification and Regression works",
      "extraction_date": "2025-10-01T15:19:50.198423"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Generalized Linear Regression (GLR)",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/generalized-linear-regression.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The feature class containing the dependent and independent variables.",
          "datatype": "Feature Layer"
        },
        {
          "name": "dependent_variable",
          "explanation": "The numeric field containing the observed values to be modeled.",
          "datatype": "Field"
        },
        {
          "name": "model_type",
          "explanation": "Specifies the  type of data that will be modeled.CONTINUOUS— The dependent_variable value is continuous.  The model used is Gaussian, and the tool performs  ordinary least squares regression.BINARY— The dependent_variable value represents presence or absence. This can be either conventional 1s and 0s, or continuous data that has been recoded based on a threshold value. The model used is Logistic Regression.COUNT—The dependent_variable value is discrete and represents events—for example, crime counts,   disease incidents, or traffic accidents. The model used is Poisson regression.",
          "datatype": "String"
        },
        {
          "name": "output_features",
          "explanation": "The new feature class that will contain the dependent variable estimates and residuals.",
          "datatype": "Feature Class"
        },
        {
          "name": "explanatory_variables[explanatory_variables,...]",
          "explanation": "A list of fields representing independent explanatory variables in the regression model.",
          "datatype": "Field"
        },
        {
          "name": "distance_features[distance_features,...](Optional)",
          "explanation": "Automatically creates explanatory variables by calculating a distance from the provided features to the in_features values. Distances will be calculated from each of the input distance_features values to the nearest in_features value. If the input distance_features values are polygons or lines, the distance attributes will be calculated as the distance between the closest segments of the pair of features.",
          "datatype": "Feature Layer"
        },
        {
          "name": "prediction_locations(Optional)",
          "explanation": "A feature class containing features representing locations where estimates will be computed. Each feature in this dataset should contain values for all  the explanatory variables specified. The dependent variable for these features will be estimated using the model calibrated for the input feature class data.",
          "datatype": "Feature Layer"
        },
        {
          "name": "explanatory_variables_to_match[[Field from Prediction Locations, Field from Input Features],...](Optional)",
          "explanation": "Matches the explanatory variables in the prediction_locations parameter to corresponding explanatory variables from the in_features parameter.",
          "datatype": "Value Table"
        },
        {
          "name": "explanatory_distance_matching[[Prediction Distance Features, Input Explanatory Distance Features],...](Optional)",
          "explanation": "Matches the distance features specified for the features_to_predict parameter on the left to the corresponding distance features for the in_features parameter on the right.",
          "datatype": "Value Table"
        },
        {
          "name": "output_predicted_features(Optional)",
          "explanation": "The output feature class that will receive dependent variable estimates for each prediction_location value.\r\n The output feature class that will receive dependent variable estimates for each Prediction Location value.",
          "datatype": "Feature Class"
        },
        {
          "name": "output_trained_model(Optional)",
          "explanation": "An output model file that will save the trained model, which can be used later for prediction.",
          "datatype": "File"
        }
      ],
      "summary": "Performs generalized linear regression (GLR) to generate predictions or to model a dependent variable in terms of its relationship to a set of explanatory variables.  This tool can be used to fit continuous (OLS), binary (logistic), and count (Poisson) models. Learn more about how Generalized Linear Regression works",
      "extraction_date": "2025-10-01T15:19:52.839405"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Generate Network Spatial Weights",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/updatedgeneratenetworkswm.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The point feature class representing locations on the network.  For each feature, neighbors and weights are calculated and stored in the output spatial weights matrix file.",
          "datatype": "Feature Class"
        },
        {
          "name": "Unique_ID_Field",
          "explanation": "An integer field containing a unique value for each feature in the input feature class.  If you don't have a field with unique ID values, you can  create one by adding an integer field to   your feature class table and calculating the field values to equal the FID or OBJECTID  field.",
          "datatype": "Field"
        },
        {
          "name": "Output_Spatial_Weights_Matrix_File",
          "explanation": "The output network spatial weights matrix file (.swm) that will store the neighbors and weights for each input feature.",
          "datatype": "File"
        },
        {
          "name": "Input_Network_Data_Source",
          "explanation": "The network dataset used to find neighbors of each input feature.   Network datasets usually represent street networks but can also represent other kinds of transportation networks such as railroads or walking paths. The network dataset must include at least one attribute related to distance, travel time, or cost.",
          "datatype": "Network Data Source"
        },
        {
          "name": "Travel_Mode",
          "explanation": "The mode of transportation for the analysis.  A travel mode defines how a pedestrian, car, truck, or other medium of transportation moves through the network and represents a collection\r\nof network settings, such as travel restrictions and U-turn\r\npolicies.\r\n An arcpy.na.TravelMode object and a string\r\ncontaining the valid JSON representation of a travel mode can also be\r\nused as input to the parameter.",
          "datatype": "String"
        },
        {
          "name": "Impedance_Distance_Cutoff",
          "explanation": "The maximum impedance distance allowed for neighbors of a feature. Any feature whose distance is farther than this value will not be used as a neighbor.  By default, no distance cutoff is used.",
          "datatype": "Linear Unit"
        },
        {
          "name": "Impedance_Temporal_Cutoff(Optional)",
          "explanation": "The maximum impedance travel time allowed for neighbors of a feature. Any feature whose travel time  is longer than this value will not be used as a neighbor.  By default, no temporal cutoff is used.",
          "datatype": "Time Unit"
        },
        {
          "name": "Impedance_Cost_Cutoff(Optional)",
          "explanation": "The maximum impedance cost allowed for neighbors of a feature. Any feature whose cost of travel is larger than this value will not be used as a neighbor.  By default, no cost cutoff is used.",
          "datatype": "Double"
        },
        {
          "name": "Maximum_Number_of_Neighbors(Optional)",
          "explanation": "An integer reflecting the maximum number of neighbors  for each feature. The actual number of neighbors used for each feature may be smaller due to impedance cutoffs.",
          "datatype": "Long"
        },
        {
          "name": "Time_of_Day(Optional)",
          "explanation": "The time of day traffic conditions will be considered in the analysis.  Traffic conditions can impact the distance that can be traveled over a given time.  If no date or time is provided, the analysis will not consider the impact of traffic.  Instead of\r\nusing a particular\r\ndate, you can specify a\r\nday of the week using the following\r\ndates: Today-12/30/1899 Sunday-12/31/1899 Monday-1/1/1900 Tuesday-1/2/1900 Wednesday-1/3/1900 Thursday-1/4/1900 Friday-1/5/1900 Saturday-1/6/1900\r\n For example, to specify\r\nthat travel should begin at 5:00 p.m. on Tuesday, specify\r\nthe parameter value as\r\n1/2/1900 5:00 PM.",
          "datatype": "Date"
        },
        {
          "name": "Time_Zone(Optional)",
          "explanation": "Specifies the time\r\nzone for the Time_of_Day parameter.\r\nLOCAL_TIME_AT_LOCATIONS—The time zone in which the Input_Feature_Class is located will be used. This is\r\nthe default.UTC—Coordinated universal time (UTC) will be used.",
          "datatype": "String"
        },
        {
          "name": "Barriers(Optional)",
          "explanation": "The features that represent blocked intersections, road closures, accident sites, or other locations where travel is blocked along the network.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Search_Tolerance(Optional)",
          "explanation": "The maximum distance used to assign each input feature to a location on the network.  If any of the input points do not fall exactly on a line of the network, they will be assigned to the closest location on the network for the analysis. However, if the feature is farther than the search tolerance value from any location on the network, it will not be assigned to the network and will not be included in the analysis.",
          "datatype": "Linear Unit"
        },
        {
          "name": "Conceptualization_of_Spatial_Relationships(Optional)",
          "explanation": "Specifies how weights will be defined for each neighbor.            INVERSE—Features farther in distance, time, or cost will have a smaller weight than features nearby. The weights decrease by their inverse  to an exponent. FIXED—All neighbors will be given equal weight. This is the default.",
          "datatype": "String"
        },
        {
          "name": "Exponent(Optional)",
          "explanation": "The exponent used when INVERSE option is specified for the Conceptualization_of_Spatial_Relationships parameter.  The weights assigned to each neighbor are calculated by taking the inverse distance, time, or cost to the power of the exponent. The default value is 1, and the value must be between 0.01 and 4. Weights drop off more rapidly as the exponent increases.",
          "datatype": "Double"
        },
        {
          "name": "Row_Standardization(Optional)",
          "explanation": "Specifies whether row standardization will be applied. Row standardization is recommended when the locations of the input points are potentially biased due to sampling design or an imposed aggregation scheme. It is also recommended that you standardize rows when weighting neighbors based on inverse distance, time, or cost.            ROW_STANDARDIZATION—Spatial weights will be standardized by row. Each weight is divided by its row sum. This is the default.NO_STANDARDIZATION—No standardization of spatial weights will be applied.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Constructs a spatial weights matrix file (.swm) using a network dataset, defining spatial relationships in terms of the underlying network structure. Learn more about how Generate Network Spatial Weights works",
      "extraction_date": "2025-10-01T15:19:55.523127"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Generate Spatial Weights Matrix",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/generate-spatial-weights-matrix.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class for which spatial relationships of features will be assessed.",
          "datatype": "Feature Class"
        },
        {
          "name": "Unique_ID_Field",
          "explanation": "An integer field containing a different value for every feature in the input feature class.  If you don't have a Unique ID field, you can  create one by adding an integer field to   your feature class table and calculating the field values to equal the FID or OBJECTID  field.",
          "datatype": "Field"
        },
        {
          "name": "Output_Spatial_Weights_Matrix_File",
          "explanation": "The full path for the output spatial weights matrix file (.swm).",
          "datatype": "File"
        },
        {
          "name": "Conceptualization_of_Spatial_Relationships",
          "explanation": "Specifies how spatial relationships among features will be conceptualized.INVERSE_DISTANCE—The impact of one feature on another feature will decrease with distance. FIXED_DISTANCE—Everything within a specified critical distance of each feature will be included in the analysis. Everything outside the critical distance will be excluded. K_NEAREST_NEIGHBORS—The closest k features will be included in the analysis; k is a specified numeric parameter. CONTIGUITY_EDGES_ONLY—Polygon features that share a boundary will be neighbors. CONTIGUITY_EDGES_CORNERS—Polygon features that share a boundary or share a node will be neighbors. DELAUNAY_TRIANGULATION—A mesh of nonoverlapping triangles will be created from feature centroids, and features associated with triangle nodes that share edges will be neighbors. SPACE_TIME_WINDOW—Features within a specified critical distance and specified time interval of each other will be neighbors.CONVERT_TABLE—Spatial relationships will be defined in a table.",
          "datatype": "String"
        },
        {
          "name": "Distance_Method(Optional)",
          "explanation": "Specifies how distances will be calculated from each feature to neighboring features.EUCLIDEAN—The straight-line distance between two points (as the crow flies) will be calculated. This is the default. MANHATTAN—The distance between two points measured along axes at right angles (city block) will be calculated by summing the (absolute) difference between the x- and y-coordinates.",
          "datatype": "String"
        },
        {
          "name": "Exponent(Optional)",
          "explanation": "The value for inverse distance calculation. A typical value is 1 or 2.",
          "datatype": "Double"
        },
        {
          "name": "Threshold_Distance(Optional)",
          "explanation": "The cutoff distance for the Conceptualization_of_Spatial_Relationships parameter's INVERSE_DISTANCE and FIXED_DISTANCE options. Enter this value using the units specified in the environment output coordinate system.  This defines the size of the space window for the SPACE_TIME_WINDOW option.When this parameter is left blank, a default threshold value is computed based on the output feature class extent and the number of features. For the inverse distance conceptualization of spatial relationships, a value of zero indicates that no threshold distance will be applied and all features will be neighbors of every other feature.",
          "datatype": "Double"
        },
        {
          "name": "Number_of_Neighbors(Optional)",
          "explanation": "An integer reflecting either the minimum or the exact number of neighbors. When the Conceptualization_of_Spatial_Relationships parameter is set to K_NEAREST_NEIGHBORS, each feature will have exactly this specified number of neighbors. For the INVERSE_DISTANCE or FIXED_DISTANCE option, each feature will have at least this many neighbors (the threshold distance will be temporarily extended to ensure this many neighbors, if necessary). When the CONTIGUITY_EDGES_ONLY or CONTIGUITY_EDGES_CORNERS option is chosen, each polygon will be assigned this minimum number of neighbors.  For polygons with fewer than this number of contiguous neighbors, additional neighbors will be based on feature centroid proximity.",
          "datatype": "Long"
        },
        {
          "name": "Row_Standardization(Optional)",
          "explanation": "Specifies whether spatial weights will be standardized by row. Row standardization is recommended whenever feature distribution is potentially biased due to sampling design or to an imposed aggregation scheme.ROW_STANDARDIZATION—Spatial weights will be standardized by row. Each weight is divided by its row sum. This is the default.NO_STANDARDIZATION—No standardization of spatial weights will be applied.",
          "datatype": "Boolean"
        },
        {
          "name": "Input_Table(Optional)",
          "explanation": "A table containing numeric weights relating every feature to every other feature in the input feature class. Required fields for the table are the Unique ID Field parameter value, NID (neighbor ID), and WEIGHT.",
          "datatype": "Table"
        },
        {
          "name": "Date_Time_Field(Optional)",
          "explanation": "A date field with a time stamp for each feature.",
          "datatype": "Field"
        },
        {
          "name": "Date_Time_Interval_Type(Optional)",
          "explanation": "Specifies the units that will be used for measuring time.SECONDS—The unit will be seconds.MINUTES—The unit will be minutes.HOURS—The unit will be hours.DAYS—The unit will be days.WEEKS—The unit will be weeks.MONTHS—The unit will be 30 days. YEARS—The unit will be years.",
          "datatype": "String"
        },
        {
          "name": "Date_Time_Interval_Value(Optional)",
          "explanation": "An integer reflecting the number of time units comprising the time window.For example, if you choose HOURS for the Date_Time_Interval_Type parameter and specify 3 for the Date_Time_Interval_Value parameter, the time window will be 3 hours. Features within the specified space window and within the specified time window will be neighbors.",
          "datatype": "Long"
        },
        {
          "name": "Use_Z_values",
          "explanation": "Specifies whether z-coordinates will be used in the construction of the spatial weights matrix if the input features are z-enabled.  USE_Z_VALUES—Z-values will be used in the construction of the spatial weights matrix.DO_NOT_USE_Z_VALUES—Z-values will not be used. They will be ignored and only x- and y-coordinates will be considered in the  construction of the spatial weights matrix.  This is the default.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Generates a spatial weights matrix file (.swm) to represent the spatial relationships among features in a dataset. Learn more about how Generate Spatial Weights Matrix works",
      "extraction_date": "2025-10-01T15:19:58.129316"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Geographically Weighted Regression (GWR)",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/geographicallyweightedregression.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The feature class containing the dependent and explanatory variables.",
          "datatype": "Feature Layer"
        },
        {
          "name": "dependent_variable",
          "explanation": "The numeric field containing the observed values that will be modeled.",
          "datatype": "Field"
        },
        {
          "name": "model_type",
          "explanation": "Specifies the  type of data that will be modeled.\r\nCONTINUOUS— The dependent_variable value is continuous.  The Gaussian model will be used, and the tool will perform  ordinary least squares regression.BINARY— The dependent_variable value represents presence or absence. This can be either conventional 1s and 0s or continuous data that has been coded based on a threshold value. The Logistic regression model will be used.COUNT—The dependent_variable value is discrete and represents events, such as crime counts,   disease incidents, or traffic accidents. The Poisson regression model will be used.",
          "datatype": "String"
        },
        {
          "name": "explanatory_variables[explanatory_variables,...]",
          "explanation": "A list of fields representing independent explanatory variables in the regression model.",
          "datatype": "Field"
        },
        {
          "name": "output_features",
          "explanation": "The new feature class containing the dependent variable estimates and residuals.",
          "datatype": "Feature Class"
        },
        {
          "name": "neighborhood_type",
          "explanation": "Specifies whether the neighborhood used is constructed as a fixed distance or allowed to vary in spatial extent depending on the density of the features.NUMBER_OF_NEIGHBORS— The neighborhood size is a function of a specified number of neighbors included in calculations for each feature. Where features are dense, the spatial extent of the neighborhood is smaller; where features are sparse, the spatial extent of the neighborhood is larger. DISTANCE_BAND—The neighborhood size is a constant or fixed distance for each feature.",
          "datatype": "String"
        },
        {
          "name": "neighborhood_selection_method",
          "explanation": "Specifies how the neighborhood size will be determined. The neighborhood selected with the GOLDEN_SEARCH and MANUAL_INTERVALS options is based on minimizing the AICc value.GOLDEN_SEARCH—The tool will identify an optimal distance or number of neighbors based on the characteristics of the data using the golden section search method.MANUAL_INTERVALS— The neighborhoods tested will be defined by the values specified in the minimum_number_of_neighbors and number_of_neighbors_increment parameters when NUMBER_OF_NEIGHBORS is chosen for the neighborhood_type parameter, or the minimum_search_distance and search_distance_increment parameters when DISTANCE_BAND is chosen for the neighborhood_type parameter, as well as the number_of_increments parameter.USER_DEFINED— The neighborhood size will be specified by either the number_of_neighbors  parameter or the distance_band parameter.",
          "datatype": "String"
        },
        {
          "name": "minimum_number_of_neighbors(Optional)",
          "explanation": "The minimum number of neighbors each feature will include in its calculations. It is recommended that you use at least 30 neighbors.",
          "datatype": "Long"
        },
        {
          "name": "maximum_number_of_neighbors(Optional)",
          "explanation": "The maximum number of neighbors (up to 1000) each feature will include in its calculations.",
          "datatype": "Long"
        },
        {
          "name": "minimum_search_distance(Optional)",
          "explanation": "The minimum neighborhood search distance.\r\nIt is recommended that you use a distance at which each feature has at least 30 neighbors.",
          "datatype": "Linear Unit"
        },
        {
          "name": "maximum_search_distance(Optional)",
          "explanation": "The maximum neighborhood search distance.\r\nIf a distance results in features with more than 1000 neighbors, the tool will use the first 1000 in calculations for the target feature.",
          "datatype": "Linear Unit"
        },
        {
          "name": "number_of_neighbors_increment(Optional)",
          "explanation": "The number of neighbors by which manual intervals will increase for each neighborhood test.",
          "datatype": "Long"
        },
        {
          "name": "search_distance_increment(Optional)",
          "explanation": "The distance by which manual intervals will increase for each neighborhood test.",
          "datatype": "Linear Unit"
        },
        {
          "name": "number_of_increments(Optional)",
          "explanation": "The number of neighborhood sizes that will be tested starting with the minimum_number_of_neighbors or minimum_search_distance  parameter value.",
          "datatype": "Long"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "The closest number of neighbors (up to 1000) that will be considered for each feature. The number must be an integer between 2 and 1000.",
          "datatype": "Long"
        },
        {
          "name": "distance_band(Optional)",
          "explanation": "The spatial extent of the neighborhood.",
          "datatype": "Linear Unit"
        },
        {
          "name": "prediction_locations(Optional)",
          "explanation": "A feature class containing features representing locations where estimates will be computed. Each feature in this dataset should contain values for all the explanatory variables specified. The dependent variable for these features will be estimated using the model calibrated for the input feature class data. To be predicted, these\r\nfeature locations should be within the same study area as the in_features parameter value or be close (within the extent plus 15 percent).\r\nA feature class containing features representing locations where estimates will be computed. Each feature in this dataset should contain values for all the explanatory variables specified. The dependent variable for these features will be estimated using the model calibrated for the input feature class data. To be predicted, these\r\nfeature locations should be within the same study area as the Input\r\nFeatures parameter value or be close (within the extent plus 15 percent).",
          "datatype": "Feature Layer"
        },
        {
          "name": "explanatory_variables_to_match[explanatory_variables_to_match,...](Optional)",
          "explanation": "The explanatory variables from the prediction_locations parameter that match corresponding explanatory variables from the in_features parameter.\r\n[[\"LandCover2000\", \"LandCover2010\"], [\"Income\", \"PerCapitaIncome\"]] are examples.",
          "datatype": "Value Table"
        },
        {
          "name": "output_predicted_features(Optional)",
          "explanation": "The output feature class that will receive dependent variable estimates for each prediction_location value.",
          "datatype": "Feature Class"
        },
        {
          "name": "robust_prediction(Optional)",
          "explanation": "Specifies the features that will be used in prediction calculations.ROBUST—Features with values more than three standard\r\ndeviations from the mean (value outliers) and features with\r\nweights of 0 (spatial outliers) will be excluded from prediction\r\ncalculations but will receive predictions in the output feature\r\nclass. This is the default.NON_ROBUST—All features will be used in prediction calculations",
          "datatype": "Boolean"
        },
        {
          "name": "local_weighting_scheme(Optional)",
          "explanation": "Specifies the kernel type that will be used to provide the spatial weighting in the model. The kernel defines how each feature is related to other features within its neighborhood.BISQUARE—A weight of 0 will be assigned to any feature outside the neighborhood specified. This is the default.GAUSSIAN—All features will receive weights, but weights become exponentially smaller the farther away they are from the target feature.",
          "datatype": "String"
        },
        {
          "name": "coefficient_raster_workspace(Optional)",
          "explanation": "The workspace where the coefficient rasters will be created. When this workspace is provided, rasters are created for the intercept and every explanatory variable. This parameter is only available with a Desktop Advanced license.",
          "datatype": "Workspace"
        },
        {
          "name": "scale(Optional)",
          "explanation": "Specifies whether the values of the explanatory and dependent variables will be scaled to  have mean zero and standard deviation one before fitting the model.SCALE_DATA—The values of the variables will be scaled. The results will contain scaled and unscaled versions of the explanatory variable coefficients.NO_SCALE_DATA—The values of the variables  will not be scaled. All coefficients will be unscaled and in original data units.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Performs Geographically Weighted Regression, which is a local form of linear regression that is used to model spatially varying relationships. Learn more about how Geographically Weighted Regression (GWR) works",
      "extraction_date": "2025-10-01T15:20:00.919444"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Local Bivariate Relationships",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/localbivariaterelationships.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The feature class containing fields representing the dependent_variable and explanatory_variable values.",
          "datatype": "Feature Layer"
        },
        {
          "name": "dependent_variable",
          "explanation": "The numeric field representing the values of the dependent variable. When categorizing the relationships, the explanatory_variable value  is used to predict the dependent_variable value.",
          "datatype": "Field"
        },
        {
          "name": "explanatory_variable",
          "explanation": "The numeric field representing the values of the explanatory variable. When categorizing the relationships, the explanatory_variable value is used to predict the dependent_variable value.",
          "datatype": "Field"
        },
        {
          "name": "output_features",
          "explanation": "The output feature class containing all input features with fields representing the dependent_variable value, explanatory_variable value, entropy score, pseudo p-value, level of significance, type of categorized relationship, and diagnostics related to the categorization.",
          "datatype": "Feature Class"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "The number of neighbors around each feature (including the feature) that will be used to test for a local relationship between the variables. The number of neighbors must be between 30 and 1,000, and the default is 30. The provided value should be large enough to detect the relationship between features, but small enough to still identify local patterns.",
          "datatype": "Long"
        },
        {
          "name": "number_of_permutations(Optional)",
          "explanation": "Specifies the number of permutations that will be used to calculate the pseudo p-value for each feature. Choosing a number of permutations is a balance between precision in the pseudo p-value and increased processing time.99—With 99 permutations, the smallest possible pseudo p-value is 0.01, and all other pseudo p-values will be multiples of this value.199—With 199 permutations, the smallest possible pseudo p-value is 0.005, and all other pseudo p-values will be multiples of this value. This is the default.499—With 499 permutations, the smallest possible pseudo p-value is 0.002, and all other pseudo p-values will be multiples of this value.999—With 999 permutations, the smallest possible pseudo p-value is 0.001, and all other pseudo p-values will be multiples of this value.",
          "datatype": "Long"
        },
        {
          "name": "enable_local_scatterplot_popups(Optional)",
          "explanation": "Specifies whether scatterplot pop-ups will be generated for each output feature. Each scatterplot displays the values of the explanatory (horizontal axis) and dependent (vertical axis) variables in the local neighborhood along with a fitted line or curve visualizing the form of the relationship.  Scatterplot charts are not supported for shapefile outputs.CREATE_POPUP—Local scatterplot pop-ups will be generated for each feature in the dataset. This is the default.NO_POPUP—Local scatterplot pop-ups will not be generated.",
          "datatype": "Boolean"
        },
        {
          "name": "level_of_confidence(Optional)",
          "explanation": "Specifies a confidence level of the hypothesis test for significant relationships.90%—The confidence level is 90 percent. This is the default.95%—The confidence level is 95 percent. 99%—The confidence level is 99 percent.",
          "datatype": "String"
        },
        {
          "name": "apply_false_discovery_rate_fdr_correction(Optional)",
          "explanation": "Specifies whether False Discover Rate (FDR) correction will be applied to the pseudo p-values.APPLY_FDR—Statistical significance will be based on the FDR correction. This is the default.NO_FDR—Statistical significance will be based on the pseudo p-value.",
          "datatype": "Boolean"
        },
        {
          "name": "scaling_factor(Optional)",
          "explanation": "The level of sensitivity to subtle relationships between the variables. Larger values (closer to one) can detect relatively weak relationships, while smaller values (closer to zero) will only detect strong relationships. Smaller values are also more robust to outliers. The value must be between 0.01 and 1, and the default is 0.5.",
          "datatype": "Double"
        }
      ],
      "summary": "Analyzes two variables for statistically significant relationships using local entropy. Each feature is classified into one of six categories based on the type of relationship. The output can be used to visualize areas where the variables are related and explore how their relationship changes across the study area. Learn more about how Local Bivariate Relationships works",
      "extraction_date": "2025-10-01T15:20:03.268814"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Multiscale Geographically Weighted Regression (MGWR)",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/multiscale-geographically-weighted-regression.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The feature class containing the dependent and explanatory variables.",
          "datatype": "Feature Layer"
        },
        {
          "name": "dependent_variable",
          "explanation": "The numeric field containing the observed values that will be modeled.",
          "datatype": "Field"
        },
        {
          "name": "model_type",
          "explanation": "Specifies the regression model based on the values of the dependent variable.  Currently, only continuous data is supported, and the parameter is hidden in the Geoprocessing pane.  Do not use categorical, count, or binary dependent variables.CONTINUOUS—The dependent variable represents continuous values. This is the default.",
          "datatype": "String"
        },
        {
          "name": "explanatory_variables[explanatory_variables,...]",
          "explanation": "A list of fields that will be used as independent explanatory variables in the regression model.",
          "datatype": "Field"
        },
        {
          "name": "output_features",
          "explanation": "The new feature class containing the coefficients, residuals, and significance levels of the MGWR model.",
          "datatype": "Feature Class"
        },
        {
          "name": "neighborhood_type",
          "explanation": "Specifies whether the neighborhood  will be a fixed distance or allowed to vary spatially depending on the density of the features.\t\t\t\t\t\tNUMBER_OF_NEIGHBORS— The neighborhood size will be a specified number of closest neighbors for each feature. Where features are dense, the spatial extent of the neighborhood will be smaller; where features are sparse, the spatial extent of the neighborhood will be larger. DISTANCE_BAND—The neighborhood size will be a constant or fixed distance for each feature.",
          "datatype": "String"
        },
        {
          "name": "neighborhood_selection_method",
          "explanation": "Specifies how the neighborhood size will be determined. \t\t\t\t\t\tGOLDEN_SEARCH—An optimal distance or number of neighbors will be identified by minimizing the AICc value using the Golden Search algorithm. This option takes the longest time to calculate, especially for large or high-dimensional datasets.GRADIENT_SEARCH—An optimal distance or number of neighbors will be identified by minimizing the AICc value using the gradient-based optimization algorithm. This option runs the fastest and requires significantly less memory usage than Golden Search.MANUAL_INTERVALS—A distance or number of neighbors will be identified by testing a range of values and determining the value with the smallest AICc.  If the neighborhood_type parameter is set to DISTANCE_BAND, the minimum value of this range is provided by  the minimum_search_distance parameter. The minimum value is then incremented by the value specified in  the search_distance_increment parameter. This is repeated  the number of times specified by the number_of_increments parameter. If the neighborhood_type parameter is set to NUMBER_OF_NEIGHBORS, the minimum value, increment size, and number of increments are provided by the minimum_number_of_neighbors, number_of_neighbors_increment, and number_of_increments parameters, respectively. USER_DEFINED— The neighborhood size will be specified by either the number_of_neighbors parameter  value or the distance_band parameter value.",
          "datatype": "String"
        },
        {
          "name": "minimum_number_of_neighbors(Optional)",
          "explanation": "The minimum number of neighbors that each feature will include in its calculation. \r\nIt is recommended that you use at least 30 neighbors.",
          "datatype": "Long"
        },
        {
          "name": "maximum_number_of_neighbors(Optional)",
          "explanation": "The maximum number of neighbors that each feature will include in its calculations.",
          "datatype": "Long"
        },
        {
          "name": "distance_unit(Optional)",
          "explanation": "Specifies the unit of distance that will be used to measure the distances between features. FEETINT—Distances will be measured in international feet.MILESINT—Distances will be measured in statute miles.FEET—Distances will be measured in US survey feet.METERS—Distances will be measured in meters.KILOMETERS—Distances will be measured in kilometers.MILES—Distances will be measured in US survey miles.",
          "datatype": "String"
        },
        {
          "name": "minimum_search_distance(Optional)",
          "explanation": "The minimum search distance that will be applied to every explanatory variable. It is recommended that you provide a minimum distance that includes at least 30 neighbors for each feature.",
          "datatype": "Double"
        },
        {
          "name": "maximum_search_distance(Optional)",
          "explanation": "The maximum neighborhood search distance that will be applied to all variables.",
          "datatype": "Double"
        },
        {
          "name": "number_of_neighbors_increment(Optional)",
          "explanation": "The number of neighbors by which manual intervals will increase for each neighborhood test.",
          "datatype": "Long"
        },
        {
          "name": "search_distance_increment(Optional)",
          "explanation": "The distance by which manual intervals will increase for each neighborhood test.",
          "datatype": "Double"
        },
        {
          "name": "number_of_increments(Optional)",
          "explanation": "The number of neighborhood sizes to test when using manual intervals. The  first neighborhood size is the value of the minimum_number_of_neighbors or minimum_search_distance parameter.",
          "datatype": "Long"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "The number of neighbors that will be used for the user-defined neighborhood type.",
          "datatype": "Long"
        },
        {
          "name": "distance_band(Optional)",
          "explanation": "The size of the distance band that will be used for the user-defined neighborhood type. All features within this distance will be included as neighbors in the local models.",
          "datatype": "Double"
        },
        {
          "name": "number_of_neighbors_golden[number_of_neighbors_golden,...](Optional)",
          "explanation": "The customized Golden Search options for individual explanatory variables. For each explanatory variable to be customized, provide the variable, the minimum number of neighbors, and the maximum number of neighbors in the columns.",
          "datatype": "Value Table"
        },
        {
          "name": "number_of_neighbors_manual[number_of_neighbors_manual,...](Optional)",
          "explanation": "The customized  manual intervals options for individual explanatory variables. For each explanatory variable to be customized, provide the minimum number of neighbors, number of neighbors increment, and number of increments in the columns.",
          "datatype": "Value Table"
        },
        {
          "name": "number_of_neighbors_defined[number_of_neighbors_defined,...](Optional)",
          "explanation": "The customized user-defined options for individual explanatory variables. For each explanatory variable to be customized, provide the number of neighbors.",
          "datatype": "Value Table"
        },
        {
          "name": "distance_golden[distance_golden,...](Optional)",
          "explanation": "The customized Golden Search options for individual explanatory variables. For each explanatory variable to be customized, provide the variable, the minimum search distance, and the maximum search distance in the columns.",
          "datatype": "Value Table"
        },
        {
          "name": "distance_manual[distance_manual,...](Optional)",
          "explanation": "The customized manual intervals options for individual explanatory variables. For each variable to be customized, provide the variable, the minimum search distance, search distance increments, and number of increments in the columns.",
          "datatype": "Value Table"
        },
        {
          "name": "distance_defined[distance_defined,...](Optional)",
          "explanation": "The customized user-defined options  for individual explanatory variables. For each variable to be customized, provide the variable and the distance band in the columns.",
          "datatype": "Value Table"
        },
        {
          "name": "prediction_locations(Optional)",
          "explanation": "A feature class with the locations where estimates will be computed. Each feature in this dataset should contain a value for every explanatory variables specified. The dependent variable for these features will be estimated using the model calibrated for the input feature class data. These feature locations should be close to (within 115 percent of the extent) or \r\nwithin the same study area as the input features.",
          "datatype": "Feature Layer"
        },
        {
          "name": "explanatory_variables_to_match[explanatory_variables_to_match,...](Optional)",
          "explanation": "The explanatory variables from the prediction locations that match corresponding explanatory variables from the input features.",
          "datatype": "Value Table"
        },
        {
          "name": "output_predicted_features(Optional)",
          "explanation": "The output feature class that will receive dependent variable estimates for every prediction location.",
          "datatype": "Feature Class"
        },
        {
          "name": "robust_prediction(Optional)",
          "explanation": "Specifies the features that will be used in the prediction calculations.ROBUST—Features with values greater than three standard deviations from the mean (value outliers) and features with weights of 0 (spatial outliers) will be excluded from the prediction calculations but will receive predictions in the output feature class. This is the default.NON_ROBUST—Every feature will be used in the prediction calculations.",
          "datatype": "Boolean"
        },
        {
          "name": "local_weighting_scheme(Optional)",
          "explanation": "Specifies the kernel type that will be used to provide the spatial weighting in the model. The kernel defines how each feature is related to other features within its neighborhood.\r\nBISQUARE—A weight of zero will be assigned to any feature outside the neighborhood specified. This is the default.GAUSSIAN—All features will receive weights, but weights become exponentially smaller the farther away they are from the target feature.",
          "datatype": "String"
        },
        {
          "name": "output_table(Optional)",
          "explanation": "A table containing the output statistics of the MGWR model. A bar chart of estimated bandwidths or numbers of neighbors will be included with the output.",
          "datatype": "Table"
        },
        {
          "name": "coefficient_raster_workspace(Optional)",
          "explanation": "The workspace where the coefficient rasters will be created. When this workspace is provided, rasters are created for the intercept and every explanatory variable.\r\nThis parameter is only available with a Desktop Advanced license. If a directory is provided, the rasters will be TIFF (.tif) raster type.",
          "datatype": "Workspace"
        },
        {
          "name": "scale(Optional)",
          "explanation": "Specifies whether the values of the explanatory and dependent variables will be scaled to  have mean zero and standard deviation one prior to fitting the model.SCALE_DATA—The values of the variables will be scaled. The results will contain scaled and unscaled versions of the explanatory variable coefficients.NO_SCALE_DATA—The values of the variables  will not be scaled. All coefficients will be unscaled and in original data units.",
          "datatype": "Boolean"
        },
        {
          "name": "number_of_neighbors_gradient[number_of_neighbors_gradient,...](Optional)",
          "explanation": "The customized Gradient Search options for individual explanatory variables. For each explanatory variable to be customized, provide the variable, the minimum number of neighbors, and the maximum number of neighbors in the columns.",
          "datatype": "Value Table"
        },
        {
          "name": "distance_gradient[distance_gradient,...](Optional)",
          "explanation": "The customized Gradient Search options for individual explanatory variables. For each explanatory variable to be customized, provide the variable, the minimum search distance, and the maximum search distance in the columns.",
          "datatype": "Value Table"
        }
      ],
      "summary": "Performs Multiscale Geographically Weighted Regression (MGWR), which is a local form of linear regression that models spatially varying relationships. MGWR builds upon geographically weighted regression (GWR). It is a local regression model that allows the coefficients of the explanatory variables to vary across space. Each explanatory variable may operate at a different spatial scale. GWR does not account for this, but MGWR does by allowing a different neighborhood (bandwidth) for each explanatory variable. The neighborhood (bandwidth) of an explanatory variable determines the features that are used to estimate the coefficient of that explanatory variable in the linear regression model that is fit at a target feature. Learn more about how Multiscale Geographically Weighted Regression (MGWR)\r\nworks",
      "extraction_date": "2025-10-01T15:20:06.045716"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Ordinary Least Squares (OLS)",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/ordinary-least-squares.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class containing the dependent and independent variables for analysis.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Unique_ID_Field",
          "explanation": "An integer field containing a different value for every feature in the Input Feature Class.",
          "datatype": "Field"
        },
        {
          "name": "Output_Feature_Class",
          "explanation": "The output feature class that will receive dependent variable estimates and residuals.",
          "datatype": "Feature Class"
        },
        {
          "name": "Dependent_Variable",
          "explanation": "The numeric field containing values for what you are trying to model.",
          "datatype": "Field"
        },
        {
          "name": "Explanatory_Variables[Explanatory_Variables,...]",
          "explanation": "A list of fields representing explanatory variables in your regression model.",
          "datatype": "Field"
        },
        {
          "name": "Coefficient_Output_Table(Optional)",
          "explanation": "The full path to an optional table that will receive model coefficients, standardized coefficients, standard errors, and probabilities for each explanatory variable.",
          "datatype": "Table"
        },
        {
          "name": "Diagnostic_Output_Table(Optional)",
          "explanation": "The full path to an optional table that will receive model summary diagnostics.",
          "datatype": "Table"
        },
        {
          "name": "Output_Report_File(Optional)",
          "explanation": "The path to the optional PDF file \r\nthe tool will create.  This report file includes model diagnostics, graphs, and notes to help you interpret the OLS results.",
          "datatype": "File"
        }
      ],
      "summary": "Performs global Ordinary Least Squares (OLS) linear regression to generate predictions or to model a dependent variable in terms of its relationships to a set of explanatory variables. The functionality of this tool is included in the Generalized Linear Regression tool added at ArcGIS Pro 2.3.  The Generalized Linear Regression tool supports additional models.",
      "extraction_date": "2025-10-01T15:20:08.616813"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Predict Using Spatial Statistics Model File",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/predict-using-spatial-statistics-model-file.htm",
      "parameters": [
        {
          "name": "input_model",
          "explanation": "The spatial statistics model file that will be used to make new predictions.",
          "datatype": "File"
        },
        {
          "name": "prediction_type",
          "explanation": "Specifies the operation mode that will be used. The tool can predict new features or create a prediction raster surface.\r\nPREDICT_FEATURES—Predictions or classifications will be generated for features. Explanatory variables must be provided to match variables used to train the input model file. The output of this option will be a feature class and model diagnostics in the messages window.PREDICT_RASTER—A prediction raster will be generated for the area where the explanatory rasters intersect. Explanatory rasters must be provided to match the rasters used to train the input model file. The output of this option will be a prediction surface and model diagnostics in the messages window",
          "datatype": "String"
        },
        {
          "name": "features_to_predict(Optional)",
          "explanation": "The feature class representing locations where predictions will be made. This feature class must also contain any explanatory variables provided as fields that correspond to those used to train the input model.",
          "datatype": "Feature Layer"
        },
        {
          "name": "output_features(Optional)",
          "explanation": "The \r\n output feature class containing the prediction results.",
          "datatype": "Feature Class"
        },
        {
          "name": "output_raster(Optional)",
          "explanation": "The output raster containing the prediction results. The default cell size will be the maximum cell size of the input rasters.",
          "datatype": "Raster Dataset"
        },
        {
          "name": "explanatory_variable_matching[[pred1, train1, cat1], [pred2, train2, cat2],...](Optional)",
          "explanation": "A list of the explanatory variables of the input model and corresponding fields of the input prediction features. For each explanatory variable in the Training column, provide the corresponding prediction field in the Prediction column. The Categorical column specifies whether the variable is categorical or continuous.",
          "datatype": "Value Table"
        },
        {
          "name": "explanatory_distance_matching[[pred1, cat1], [pred2, cat2],...](Optional)",
          "explanation": "A list of the explanatory distance features of the input model and corresponding prediction distance features. For each explanatory distance feature in the Training column, provide the corresponding prediction distance feature in the Prediction column.",
          "datatype": "Value Table"
        },
        {
          "name": "explanatory_rasters_matching[[pred1, train1, cat1], [pred2, train2, cat2],...](Optional)",
          "explanation": "A list of the explanatory rasters of the input model and corresponding prediction rasters. For each explanatory raster in the Training column, provide the corresponding prediction raster in the Prediction column. The Categorical column specifies whether the raster is categorical or continuous.",
          "datatype": "Value Table"
        }
      ],
      "summary": "Predicts continuous or categorical values using a trained spatial statistics model (.ssm file). Learn more about spatial statistics model files",
      "extraction_date": "2025-10-01T15:20:11.596668"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Presence-only Prediction",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/presence-only-prediction.htm",
      "parameters": [
        {
          "name": "input_point_features",
          "explanation": "The point features representing locations where presence of a phenomenon of interest is known to occur.",
          "datatype": "Feature Layer"
        },
        {
          "name": "contains_background(Optional)",
          "explanation": "Specifies whether the input point features contain background points.\r\nIf the input points do not contain background points, the tool will generate background points\r\nusing cells in the explanatory training rasters. The tool uses background points to model the characteristics of the landscape in unknown\r\nlocations and compare them to landscape characteristics in known\r\npresence locations. Therefore, background points can be considered\r\nas the study area. Generally, these are locations where presence of\r\na phenomenon of interest is unknown. However, if any information is known about the background points, the relative_weight parameter can be used to\r\nindicate this.PRESENCE_AND_BACKGROUND_POINTS—The input point features include background points.PRESENCE_ONLY_POINTS—The input point features do not include background points. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "presence_indicator_field(Optional)",
          "explanation": "The field from the input point features containing binary values that indicate each point as presence (1) or background (0). The field must be numeric.",
          "datatype": "Field"
        },
        {
          "name": "explanatory_variables[[Variable, Categorical],...](Optional)",
          "explanation": "A list of fields representing the explanatory variables that will help predict the probability of presence. You can specify whether each variable is categorical or numeric. Specify the CATEGORICAL option for each variable that represents a class or category (such as land cover).",
          "datatype": "Value Table"
        },
        {
          "name": "distance_features[distance_features,...](Optional)",
          "explanation": "A list of feature layers or feature classes that will be used to automatically create explanatory variables that represent the distance from the input point features to the nearest provided distance features. If the input explanatory training distance features are polygons or lines, the distance attributes are calculated as the distance between the closest segment and the point.",
          "datatype": "Feature Layer"
        },
        {
          "name": "explanatory_rasters[[Variable, Categorical],...](Optional)",
          "explanation": "A list of rasters that will be used to automatically create\r\nexplanatory training variables in the model whose values are\r\nextracted from rasters. For each feature (presence and background\r\npoints) in the input point features, the value of the raster\r\ncell will be extracted at that exact location.Bilinear raster resampling will be used when extracting the raster\r\nvalue for continuous rasters. Nearest neighbor assignment will be used\r\nwhen extracting a raster value from categorical rasters. You can specify whether each raster value is categorical or numeric. Specify the CATEGORICAL option for each\r\nraster that represents a class or category (such as land cover).",
          "datatype": "Value Table"
        },
        {
          "name": "basis_expansion_functions[basis_expansion_functions,...](Optional)",
          "explanation": "Specifies the basis function that will be used to transform the provided explanatory variables for use in the model. If multiple basis functions are selected, the tool will produce multiple transformed variables and attempt to use them in the model.LINEAR— A linear transformation to the input variables will be applied. This is the defaultPRODUCT— A pairwise multiplication on continuous explanatory variables will be used, yielding interaction variables. This option is only available when multiple explanatory variables have been provided.HINGE— The continuous explanatory variable values will be converted into two segments, a static segment (composed of zeroes or ones) and a linear function segment (increasing or decreasing).THRESHOLD— The continuous explanatory variable values will be converted into a binary variable composed of zeroes and ones.QUADRATIC— The square of each continuous explanatory variable value will be returned.",
          "datatype": "String"
        },
        {
          "name": "number_knots(Optional)",
          "explanation": "The number of knots that will be used by the hinge and\r\nthreshold explanatory variable expansions.\r\nThe value controls how many thresholds are created, which are\r\nused to create multiple explanatory variable expansions using\r\neach threshold. The value must be between 2\r\nand 50. The default is 10.",
          "datatype": "Long"
        },
        {
          "name": "study_area_type(Optional)",
          "explanation": "Specifies the type of study area that will be used to define where presence is possible when the input point features do not contain background points.CONVEX_HULL— The smallest convex polygon that encloses all the presence points in the input point features will be used. This is the defaultRASTER_EXTENT—The extent of the intersection of the explanatory training rasters will be used.STUDY_POLYGON—A custom study area that is defined by a polygon feature class will be used.",
          "datatype": "String"
        },
        {
          "name": "study_area_polygon(Optional)",
          "explanation": "A feature class containing the polygons that define a custom study area. The input point features must be located within the custom study area covered by the polygon features. A study area can be composed of multiple polygons.",
          "datatype": "Feature Layer"
        },
        {
          "name": "spatial_thinning(Optional)",
          "explanation": "Specifies whether spatial thinning will be applied to presence and background points before training the model.Spatial thinning helps to reduce sampling bias by removing\r\npoints and ensuring that remaining points have a minimum nearest-neighbor distance, set in the thinning_distance_bandparameter. Spatial thinning is also applied to background\r\npoints whether they are provided in input point features or\r\ngenerated by the tool.\r\nTHINNING—Spatial thinning will be applied.NO_THINNING—Spatial thinning will not be applied. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "thinning_distance_band(Optional)",
          "explanation": "The minimum distance between any two presence points or any two background points when spatial thinning is applied.",
          "datatype": "Linear Unit"
        },
        {
          "name": "number_of_iterations(Optional)",
          "explanation": "The number of runs that will be used to find the optimal spatial thinning solution, seeking to maintain as many presence and background points as possible while ensuring that no two presence or two background points are within the specified thinning_distance_band parameter value. The minimum possible is 1 iteration and the maximum possible is 50 iterations. The default is 10.\r\nThis parameter is only applicable for spatial thinning applied to presence and background points in the input point features. Spatial thinning that is applied to background points generated from raster cells undergo spatial thinning by resampling the raster cells to the specified thinning_distance_band parameter value, without needing to iterate for an optimal solution.",
          "datatype": "Long"
        },
        {
          "name": "relative_weight(Optional)",
          "explanation": "A value between 1 and 100 that specifies the relative\r\ninformation weight of presence points to background points. The\r\ndefault is 100.A higher value indicates that presence points are the primary\r\nsource of information; it is unknown whether background points\r\nrepresent presence or absence and background points receive lower\r\nweight in the model. A lower value indicates that background points also contribute valuable information that can be used in\r\nconjunction with presence points; there is greater confidence that\r\nbackground points represent absence and their information can\r\nbe used in the model as absence\r\nlocations.",
          "datatype": "Long"
        },
        {
          "name": "link_function(Optional)",
          "explanation": "Specifies the function that will convert the unbounded outputs of the model to a number between 0 and 1. This value can be interpreted as the probability of presence at the location. Each option converts the same continuous value to a different probability.CLOGLOG— The C-log-log link function will be used to convert the predictions to probabilities. This option is recommended when the presence and location of a phenomenon is unambiguous, for example, when modeling the presence of an immobile plant species. This is the default.LOGISTIC—The logistic link function will be used to convert predictions to probabilities. This option is recommended when the presence and location of a phenomenon is ambiguous, for example, when modeling the presence of a migratory animal species.",
          "datatype": "String"
        },
        {
          "name": "presence_probability_cutoff(Optional)",
          "explanation": "A cutoff value between 0.01 and 0.99 that establishes which probabilities correspond with presence in the resulting classification. The cutoff value is used to help evaluate the model's performance using training data and known presence points. Classification diagnostics are provided in geoprocessing messages and in the output trained features.",
          "datatype": "Double"
        },
        {
          "name": "output_trained_features(Optional)",
          "explanation": "An output feature class that will contain all features and explanatory variables used in the training of the model.",
          "datatype": "Feature Class"
        },
        {
          "name": "output_trained_raster(Optional)",
          "explanation": "The output raster with cell values indicating the probability of presence using the selected link function.\r\nThe default cell size is the maximum of the cell sizes of the explanatory training rasters. An output trained raster can only be created if the input point features do not contain background points.",
          "datatype": "Raster Dataset"
        },
        {
          "name": "output_response_curve_table(Optional)",
          "explanation": "The output table that will contain diagnostics from the\r\ntraining model that indicate the effect of each explanatory\r\nvariable on the probability of presence after accounting for the\r\naverage effects of all other explanatory variables in the\r\nmodel. The table will have up to two derived charts\r\nof partial dependence plots: one set of line charts for continuous\r\nvariables and one set of bar charts for categorical\r\nvariables.",
          "datatype": "Table"
        },
        {
          "name": "output_sensitivity_table(Optional)",
          "explanation": "The output table that will contain diagnostics of training model accuracy as the probability presence cutoff changes from 0 to 1.",
          "datatype": "Table"
        },
        {
          "name": "features_to_predict(Optional)",
          "explanation": "The feature class representing locations where predictions will be\r\nmade. The feature class must contain any provided explanatory\r\nvariable fields that were used from the input point features. When using spatial thinning, you can\r\nuse the original input point features as input prediction features to receive a prediction for the entire\r\ndataset.",
          "datatype": "Feature Layer"
        },
        {
          "name": "output_pred_features(Optional)",
          "explanation": "The output feature class that will contain the results of the prediction model applied to the input prediction features.",
          "datatype": "Feature Class"
        },
        {
          "name": "output_pred_raster(Optional)",
          "explanation": "The output raster containing the prediction results at each cell of the matched explanatory rasters.\r\nThe default cell size is the maximum of the cell sizes of the explanatory training rasters.",
          "datatype": "Raster Dataset"
        },
        {
          "name": "explanatory_variable_matching[[Prediction, Training],...](Optional)",
          "explanation": "The matching explanatory variable fields for the input point features and input prediction features.",
          "datatype": "Value Table"
        },
        {
          "name": "explanatory_distance_matching[[Prediction, Training],...](Optional)",
          "explanation": "The matching distance features for the training and prediction.",
          "datatype": "Value Table"
        },
        {
          "name": "explanatory_rasters_matching[[Prediction, Training],...](Optional)",
          "explanation": "The matching rasters for the training and prediction.",
          "datatype": "Value Table"
        },
        {
          "name": "allow_predictions_outside_of_data_ranges(Optional)",
          "explanation": "ALLOWED—The prediction will allow extrapolation beyond the range of values used in training. This is the default.NOT_ALLOWED—The prediction will not allow extrapolation beyond the range of values used in training.",
          "datatype": "Boolean"
        },
        {
          "name": "resampling_scheme(Optional)",
          "explanation": "Specifies the method that will be used to perform cross validation of the prediction model. Cross validation excludes a portion of the data during training of the model and uses it to test the model's performance after it is trained.NONE—Cross validation will not be performed. This is the defaultRANDOM— The points will be randomly divided into groups, and each group will be left out once when performing cross validation. The number of groups is specified in the number_of_groups parameter.",
          "datatype": "String"
        },
        {
          "name": "number_of_groups(Optional)",
          "explanation": "The number of groups that will be used in cross validation\r\nfor the random resampling scheme. A field in the\r\noutput trained features indicates the group that each point\r\nwas assigned to. The default is 3. A minimum of 2 groups\r\nand a maximum of 10 groups are allowed.",
          "datatype": "Long"
        },
        {
          "name": "output_trained_model(Optional)",
          "explanation": "An output model file that will save the trained model, which can be used later for prediction.",
          "datatype": "File"
        }
      ],
      "summary": "Models the presence of a phenomenon given known presence locations and explanatory variables using a maximum entropy approach (MaxEnt). The tool provides output features and rasters that include the probability of presence and can be applied to problems in which only presence is known and absence is not known. Learn more about how Presence-only Prediction (MaxEnt) works",
      "extraction_date": "2025-10-01T15:20:14.580036"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Spatial Association Between Zones",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/spatial-association-between-zones.htm",
      "parameters": [
        {
          "name": "input_feature_or_raster",
          "explanation": "The dataset representing the  zones of the first regionalization.  The zones can be defined using polygon features or a raster.",
          "datatype": "Feature Layer; Raster Layer; Image Service"
        },
        {
          "name": "categorical_zone_field",
          "explanation": "The field representing the zone category of the input zones. Each unique value of this field defines an individual zone. For features, the field must be integer or text.  For rasters, the VALUE field is also supported.",
          "datatype": "Field"
        },
        {
          "name": "overlay_feature_or_raster",
          "explanation": "The dataset representing the zones of the second regionalization.  The zones can be polygon features or a raster.",
          "datatype": "Feature Layer; Raster Layer; Image Service"
        },
        {
          "name": "categorical_overlay_zone_field",
          "explanation": "The field representing the zone category of the overlay zones.\r\nEach unique value of this field defines an individual zone. For features, the field must be integer or text.  For rasters, the VALUE field is also supported.",
          "datatype": "Field"
        },
        {
          "name": "output_features(Optional)",
          "explanation": "The output polygon features containing spatial association measures at all intersections of the input and overlay zones.\r\nThe output features can be used to measure the association between specific combinations of input and overlay zones, such as the association between areas of corn production (crop type) and areas of well-drained soil (soil drainage class).  This parameter is only enabled if the input and overlay zones are both polygon features.",
          "datatype": "Feature Class"
        },
        {
          "name": "output_raster(Optional)",
          "explanation": "The output raster containing spatial association measures\r\nbetween the input and overlay zones. The output raster will have three fields to indicate the spatial association measures for  intersections of the input and overlay zones, correspondence of overlay zones within input zones, and correspondence of input zones within overlay zones. This parameter is only enabled if at least one of the input and overlay zones is a raster.",
          "datatype": "Raster Dataset"
        },
        {
          "name": "correspondence_overlay_to_input(Optional)",
          "explanation": "The output polygon features containing the correspondence measures of the overlay zones  within the input zones.\r\nThis output will have the same geometry as the input zones and can be used to identify which input zones closely correspond overall to the overlay zones. Specific zone combinations can then be investigated with the output features. This parameter is only enabled if the input and overlay zones are both polygon features.",
          "datatype": "Feature Class"
        },
        {
          "name": "correspondence_input_to_overlay(Optional)",
          "explanation": "The output polygon features containing the correspondence measures of the input zones  within the overlay zones.\r\nThis output will have the same geometry as the overlay zones and can be used to identify which overlay zones closely correspond overall to the input zones. Specific zone combinations can then be investigated with the output features. This parameter is only enabled if the input and overlay zones are both polygon features.",
          "datatype": "Feature Class"
        }
      ],
      "summary": "Measures the degree of spatial association between two regionalizations of the same study area in which each regionalization is composed of a set of categories, called zones.  The association between the regionalizations is determined by the area overlap between zones of each regionalization. The association is highest when each zone of one regionalization closely corresponds to a zone of the other regionalization.  Similarly, spatial association is lowest when the zones of one regionalization have large overlap with many different zones of the other regionalization.   The primary output of the tool is a global measure of spatial association between the categorical variables: a single number ranging from 0 (no correspondence) to 1 (perfect spatial alignment of zones). Optionally, this global association can be calculated and visualized for specific zones of either regionalization or for specific combinations of zones between regionalizations. For example, you can use this tool to compare two sets of categorical zones, such as the crop type and soil drainage class of an agricultural area to measure how closely particular crops correspond to a specific class of soil drainage. However, you can also use this tool to measure the degree of change of the same categorical zones over time.  For example, climate zones from 1990 can be compared to climate zones from 2020 to measure how much the climate zones changed over three decades. Using optional outputs, you can determine how each individual climate zone changed, such as whether arid climate zones expanded into areas that were\r\npreviously semiarid. Learn more about how Spatial Association Between Zones works",
      "extraction_date": "2025-10-01T15:20:17.151920"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Spatial Autoregression",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/spatial-autoregression.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The input features containing the dependent and explanatory variables.",
          "datatype": "Feature Layer"
        },
        {
          "name": "dependent_variable",
          "explanation": "The numeric field that will be predicted in the regression model.",
          "datatype": "Field"
        },
        {
          "name": "explanatory_variables[explanatory_variables,...]",
          "explanation": "A list of fields that will be used to predict the dependent variable in the regression model.",
          "datatype": "Field"
        },
        {
          "name": "out_features",
          "explanation": "The output feature class containing the predicted values of the dependent variable and the residuals.",
          "datatype": "Feature Class"
        },
        {
          "name": "model_type",
          "explanation": "The model type that will be used for the estimation. By default, LM diagnostic tests will be used to determine the model that is the most appropriate for the input data.AUTO—LM diagnostic tests will be used to determine whether an OLS, SLM, SEM, or SAC will be estimated. This is the default.ERROR—A SEM will be estimated regardless of the LM diagnostics.LAG—A SLM will be estimated  regardless of the LM diagnostics.COMBINED—A SAC will be estimated regardless of the LM diagnostics.",
          "datatype": "String"
        },
        {
          "name": "neighborhood_type(Optional)",
          "explanation": "Specifies how neighbors will be chosen for each input feature. To identify local spatial patterns, neighboring features must be identified for each input feature.DISTANCE_BAND—Features within a specified distance of each feature will be considered neighbors. K_NEAREST_NEIGHBORS—The closest k features will be considered neighbors. The number of neighbors is specified using the number_of_neighbors parameter.CONTIGUITY_EDGES_ONLY—Polygon features that share an edge will be included as neighbors.CONTIGUITY_EDGES_CORNERS—Polygon features that share an edge or corner will be included as neighbors. This is the default for polygon features.DELAUNAY_TRIANGULATION—Features whose Delaunay triangulation share an edge or corner will be included as neighbors. This is the default for point features.GET_SPATIAL_WEIGHTS_FROM_FILE—Neighbors and weights will be defined by a specified spatial weights file. The file is specified using the weights_matrix_file parameter.",
          "datatype": "String"
        },
        {
          "name": "distance_band(Optional)",
          "explanation": "The distance within which features will be included as neighbors. If no value is provided, one will be estimated during processing and included as a geoprocessing message.",
          "datatype": "Linear Unit"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "The number of neighbors that will be included as neighbors. The number does not include the focal feature. The default is 8.",
          "datatype": "Long"
        },
        {
          "name": "weights_matrix_file(Optional)",
          "explanation": "The path and file name of the spatial weights matrix file that defines spatial relationships among features.",
          "datatype": "File"
        },
        {
          "name": "local_weighting_scheme(Optional)",
          "explanation": "Specifies the weighting scheme that will be applied to neighbors. Weights will always be row-standardized unless a spatial weights matrix file is provided.UNWEIGHTED—Neighbors will be assigned a weight equal to 1.  This is the default.BISQUARE—Neighbors will be weighted using a bisquare (quartic) kernel.GAUSSIAN—Neighbors will be weighted using a Gaussian (normal distribution) kernel.",
          "datatype": "String"
        },
        {
          "name": "kernel_bandwidth(Optional)",
          "explanation": "The bandwidth of the weighting kernel. If no value is provided, an adaptive kernel will be used. An adaptive kernel uses the maximum distance from a neighbor to a focal feature as the bandwidth.",
          "datatype": "Linear Unit"
        }
      ],
      "summary": "Estimates a global spatial regression model for a point or polygon feature class. The assumptions of traditional linear regression models are often violated when using spatial data. When spatial autocorrelation is present in a dataset, coefficient estimates may be biased and lead to overconfident inference. This tool can be used to estimate a regression model that is robust in the presence of spatial dependence and heteroskedasticity, as well as measure spatial spillovers. The tool uses Lagrange Multiplier (LM), also known as a Rao Score, diagnostic tests to determine the model that is most appropriate. Based on the LM diagnostics, either an ordinary least square (OLS), spatial lag model (SLM), spatial error model (SEM), or spatial autoregressive combined model (SAC) may be estimated. Learn more about how Spatial Autoregression works",
      "extraction_date": "2025-10-01T15:20:19.519031"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Moran eigenvectors",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/understanding-moran-eigenvectors.htm",
      "parameters": [],
      "summary": "",
      "extraction_date": "2025-10-01T15:20:23.617899"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Compare Neighborhood Conceptualizations",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/compare-neighborhood-conceptualizations.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The input features containing the fields that will be used to select the SWM.",
          "datatype": "Feature Layer"
        },
        {
          "name": "input_fields[input_fields,...]",
          "explanation": "The input fields that will be used to select the SWM.",
          "datatype": "Field"
        },
        {
          "name": "out_swm",
          "explanation": "The output .swm file of the neighbors and weights selected by the tool.",
          "datatype": "File"
        },
        {
          "name": "id_field",
          "explanation": "The unique ID field of the output .swm file. The field must be an integer and must have a unique value for each input feature.",
          "datatype": "Field"
        },
        {
          "name": "in_swm[in_swm,...](Optional)",
          "explanation": "The input .swm files that will be used as candidates for the SWM that best represents the spatial patterns (such as trends or clusters) of one or more numeric fields. If no files are provided, the tool will test 28 different neighborhoods.",
          "datatype": "File"
        },
        {
          "name": "compare_only_inputs(Optional)",
          "explanation": "Specifies whether only the .swm files provided in the in_swm parameter will be tested or whether 28 additional neighborhoods will also be tested. The tool will use the SWM that creates spatial components that best represents the spatial patterns (such as trends or clusters) of one or more numeric fields. This parameter only applies if at least one input .swm file is provided.COMPARE_INPUTS—Only the input .swm files provided in the in_swm parameter will be tested. This is the default.COMPARE_ALL—The input .swm files provided in the in_swm parameter and an additional 28 neighborhoods will be tested.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Selects the spatial weights matrix (SWM) from a set of candidate SWMs that best represents the spatial patterns (such as trends or clusters) of one or more numeric fields. The output spatial weights matrix  file can then be used in tools that allow .swm files for their Neighborhood Type or Conceptualization of Spatial Relationships parameter values, such as the Bivariate Spatial Association (Lee's L), Hot Spot Analysis (Getis-Ord Gi*), and Cluster and Outlier Analysis (Anselin Local Moran's I) tools. The tool selects the SWM by creating spatial components (called Moran eigenvectors) from each candidate SWM and testing how effectively the components represent the spatial patterns of the input fields. Learn more about Moran eigenvectors",
      "extraction_date": "2025-10-01T15:20:26.078462"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Create Spatial Component Explanatory Variables",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/create-spatial-component-explanatory-variables.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The input features containing fields of the explanatory and dependent variables that will be used in a prediction model.",
          "datatype": "Feature Layer"
        },
        {
          "name": "input_fields[input_fields,...]",
          "explanation": "The input fields of the explanatory and dependent variables that will be used in a prediction model.",
          "datatype": "Field"
        },
        {
          "name": "out_features",
          "explanation": "The output features that will contain fields of the spatial components that can be used as additional explanatory variables in a prediction model.",
          "datatype": "Feature Class"
        },
        {
          "name": "append_all_fields(Optional)",
          "explanation": "Specifies whether all fields will be copied from the input features to the output feature class.ALL— All fields from the input features will be copied to the output feature class. This is the default.NO_FIELDS—Only the input fields will be copied to the output feature class.",
          "datatype": "Boolean"
        },
        {
          "name": "in_swm[in_swm,...](Optional)",
          "explanation": "A list of input SWM files (.swm) that will be used as candidates for the SWM that will be used to create the spatial component explanatory variables. If no files are provided, the tool will test 28 different neighborhoods.",
          "datatype": "File"
        },
        {
          "name": "out_swm(Optional)",
          "explanation": "The output SWM file (.swm) of the neighbors and weights selected by the tool.  This parameter does not apply if you provide an input .swm file.",
          "datatype": "File"
        },
        {
          "name": "id_field(Optional)",
          "explanation": "The unique ID field of the output .swm file. The field must be an integer and must have a unique value for each input feature.",
          "datatype": "Field"
        },
        {
          "name": "compare_only_inputs(Optional)",
          "explanation": "Specifies whether only the .swm files provided in the in_swm parameter will be tested or whether 28 additional neighborhoods will also be tested. The tool will use the SWM that creates spatial components that most accurately predict the values of the input fields. This parameter only applies if at least one input SWM is provided.COMPARE_INPUTS—Only the input .swm files provided in the in_swm parameter will be tested. This is the default.COMPARE_ALL—The input .swm files provided in the in_swm parameter and an additional 28 neighborhoods will be tested.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Creates a set of spatial component fields that best describe the spatial patterns of one or more numeric fields and serve as useful explanatory variables in a prediction or regression model. The input fields should be the explanatory and dependent variables that will be used in a prediction model. The resulting spatial component fields (called Moran eigenvectors) can be used as explanatory variables (in addition to the original explanatory variables) that will often improve the predictive power of the model by accounting for spatial patterns of the other variables. Learn more about Moran eigenvectors",
      "extraction_date": "2025-10-01T15:20:28.676041"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Decompose Spatial Structure (Moran Eigenvectors)",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/decompose-spatial-structure.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The point or polygon features that will be used to create the spatial components.",
          "datatype": "Feature Layer"
        },
        {
          "name": "out_features",
          "explanation": "The output feature class that will contain the spatial components as fields. The number of fields created depends on the min_autocorrelation and max_components parameter values.",
          "datatype": "Feature Class"
        },
        {
          "name": "append_all_fields(Optional)",
          "explanation": "Specifies whether all fields will be copied from the input features to the output feature class.ALL— All fields from the input features will be copied to the output feature class. This is the default.NO_FIELDS—No fields will be copied to the output feature class.",
          "datatype": "Boolean"
        },
        {
          "name": "min_autocorrelation(Optional)",
          "explanation": "The threshold value for including a spatial component.  The value is a proportion of the largest possible Moran's I value for the spatial weights, and a component must have a larger Moran's I value than this threshold to be included. The default is 0.25, meaning that for a  component to be included, it must have a Moran's I value that is at least 25 percent of the maximum possible Moran's I value. The value must be between 0 and 1, and smaller values will result in more components.",
          "datatype": "Double"
        },
        {
          "name": "max_components(Optional)",
          "explanation": "The maximum number of spatial components that will be created. The default is 15.",
          "datatype": "Long"
        },
        {
          "name": "neighborhood_type(Optional)",
          "explanation": "Specifies how neighbors will be chosen for each input feature.  Neighboring features must be identified in order to decompose the spatial structure of the input features. \r\nDISTANCE_BAND—Features within a specified critical distance of each feature will be included as neighbors. This is the default for point features.NUMBER_OF_NEIGHBORS— The closest features will be included as neighbors. CONTIGUITY_EDGES_ONLY— Polygon features that share an edge will be included as neighbors.CONTIGUITY_EDGES_CORNERS— Polygon features that share an edge or a corner will be included as neighbors. This is the default for polygon features.DELAUNAY_TRIANGULATION—Features whose Delaunay triangulation share an edge will be included as neighbors. GET_SPATIAL_WEIGHTS_FROM_FILE— Neighbors and weights will be defined by a specified spatial weights file.",
          "datatype": "String"
        },
        {
          "name": "distance_band(Optional)",
          "explanation": "The distance within which features will be included as neighbors. If no value is provided, one will be estimated during processing and included as a geoprocessing message. If the specified distance results in more than 1,000 neighbors, only the closest 1,000 features will be included as neighbors.",
          "datatype": "Linear Unit"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "The number of neighbors that will be included for each feature. The number does not include the focal feature. The default is 8.",
          "datatype": "Long"
        },
        {
          "name": "weights_matrix_file(Optional)",
          "explanation": "The path and file name of the spatial weights matrix file (.swm) that defines the neighbors and weights between the input features.",
          "datatype": "File"
        },
        {
          "name": "local_weighting_scheme(Optional)",
          "explanation": "Specifies the weighting scheme that will be applied to neighboring features.  \r\nUNWEIGHTED—Neighbors will not be weighted.  This is the default.BISQUARE—Neighbors will be weighted using a bisquare kernel scheme.GAUSSIAN—Neighbors will be weighted using a Gaussian kernel scheme.",
          "datatype": "String"
        },
        {
          "name": "kernel_bandwidth(Optional)",
          "explanation": "The bandwidth of the bisquare or Gaussian local weighting schemes. If no value is provided, one will be estimated during processing and included as a geoprocessing message.",
          "datatype": "Linear Unit"
        },
        {
          "name": "out_swm(Optional)",
          "explanation": "The output spatial weights matrix file (.swm) of the neighbors and weights of all pairs of features.  If created, this file can be reused in tools that allow defining neighbors and weights with spatial weights matrix files.",
          "datatype": "File"
        },
        {
          "name": "id_field(Optional)",
          "explanation": "The unique ID field of the output spatial weights matrix file. The field must be an integer and must have a unique value for each input feature.",
          "datatype": "Field"
        }
      ],
      "summary": "Decomposes a feature class and neighborhood into a set of spatial components. The components represent potential spatial patterns among the features, such as clusters or trends. The components are returned as fields of the output feature class and represent variables of the input features and neighborhood that have the strongest possible spatial clustering (spatial autocorrelation).  The components are called Moran eigenvectors, and each component represents a different spatial pattern that are each independent of each other. Learn more about Moran eigenvectors",
      "extraction_date": "2025-10-01T15:20:31.287964"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Filter Spatial Autocorrelation From Field",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/filter-spatial-autocorrelation-from-field.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The input features containing the field that will be spatially filtered.",
          "datatype": "Feature Layer"
        },
        {
          "name": "input_field",
          "explanation": "The input field that will be spatially filtered.",
          "datatype": "Field"
        },
        {
          "name": "out_features",
          "explanation": "The output features containing a field of the spatially filtered input field and fields of the spatial components used to filter it.",
          "datatype": "Feature Class"
        },
        {
          "name": "append_all_fields(Optional)",
          "explanation": "Specifies whether all fields will be copied from the input features to the output feature class.ALL— All fields from the input features will be copied to the output feature class. This is the default.NO_FIELDS—Only the input field will be copied to the output feature class.",
          "datatype": "Boolean"
        },
        {
          "name": "in_swm[in_swm,...](Optional)",
          "explanation": "A list of input SWM files (.swm) that will be used as candidates for the SWM that will be used to filter the spatial autocorrelation from the input field. The SWM that most effectively filters spatial autocorrelation will be used. If no files are provided, the tool will test 28 different neighborhoods.",
          "datatype": "File"
        },
        {
          "name": "out_swm(Optional)",
          "explanation": "The output SWM file (.swm) of the neighbors and weights selected by the tool.",
          "datatype": "File"
        },
        {
          "name": "id_field(Optional)",
          "explanation": "The unique ID field of the output .swm file. The field must be an integer and must have a unique value for each input feature.",
          "datatype": "Field"
        },
        {
          "name": "compare_only_inputs(Optional)",
          "explanation": "Specifies whether only the .swm files provided in the in_swm parameter will be tested or whether 28 additional neighborhoods will also be tested. The tool will use the SWM that creates spatial components that most accurately predict the values of the input fields. This parameter only applies if at least one input .swm file is provided.COMPARE_INPUTS—Only the input .swm files provided in the in_swm parameter will be tested. This is the default.COMPARE_ALL—The input .swm files provided in the in_swm parameter and an additional 28 neighborhoods will be tested.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Creates a spatially filtered version of an input field.  The filtered variable will have no statistically significant spatial clustering but will maintain the core statistical properties of the field. The spatially filtered version of the field can then be used in analytical workflows (such as correlation or regression analysis) that assume the values at each location are spatially independent (not spatially clustered). The tool filters spatial autocorrelation by splitting the field in a nonspatial component (the filtered field) and a set of spatial components (called Moran eigenvectors). When the input field is a field of residuals or standardized residuals from a prediction or regression model, including the spatial components as explanatory variables in the model (in addition to the original explanatory variables) will reduce or eliminate spatial autocorrelation of the residual term, which is an assumption of various prediction models. Learn more about Moran eigenvectors",
      "extraction_date": "2025-10-01T15:20:33.876045"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Calculate Distance Band from Neighbor Count",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/calculate-distance-band-from-neighbor-count.htm",
      "parameters": [
        {
          "name": "Input_Features",
          "explanation": "The feature class or layer used to calculate distance statistics.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Neighbors",
          "explanation": "The number of neighbors (N) to consider for each feature. This number should be any integer between one and the total number of features in the feature class. A list of distances between each feature and its Nth neighbor is compiled, and the maximum, minimum, and average distances are output to the Results window.",
          "datatype": "Long"
        },
        {
          "name": "Distance_Method",
          "explanation": "Specifies how distances are calculated from each feature to neighboring features.EUCLIDEAN_DISTANCE—The straight-line distance between two points (as the crow flies) MANHATTAN_DISTANCE—The distance between two points measured along axes at right angles (city block); calculated by summing the (absolute) difference between the x- and y-coordinates",
          "datatype": "String"
        }
      ],
      "summary": "Returns the minimum, the maximum, and the average distance to the specified Nth nearest neighbor (N is an input parameter) for a set of features.  Results are written as tool execution messages.",
      "extraction_date": "2025-10-01T15:20:37.996507"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Calculate Rates",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/calculate-rates.htm",
      "parameters": [
        {
          "name": "in_table",
          "explanation": "The table or features containing count fields and population fields to calculate rates.",
          "datatype": "Table View"
        },
        {
          "name": "rate_fields[[count_field, population_field],...]",
          "explanation": "The count and population fields that will be used to calculate rates.",
          "datatype": "Value Table"
        },
        {
          "name": "append_to_input(Optional)",
          "explanation": "Specifies whether fields will be appended to the input dataset or saved to an output table or feature class.\r\nAPPEND—  Fields will be appended to the input features. This modifies the input data.NO_APPEND—An output table or feature class containing the fields will be created. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "out_table(Optional)",
          "explanation": "The output table or feature class containing the rates and additional fields to help evaluate the rates.",
          "datatype": "Feature Class; Table"
        },
        {
          "name": "rate_method(Optional)",
          "explanation": "Specifies the method that will be used to calculate rates.\r\nCRUDE_RATE—The rates will be calculated by dividing the count field values by the population field values. This is the default.GLOBAL_EMPIRICAL_BAYES—The rates will be the weighted average of the crude rate and the global average rate. The weight will depend on the feature's population size.LOCAL_EMPIRICAL_BAYES—The rates will be the weighted average of the focal feature's crude rate and the weighted average rate of its neighborhood.LOCALLY_WEIGHTED_AVERAGE— The rates will be the spatially weighted average rate of each feature and its neighborhood.LOCALLY_WEIGHTED_MEDIAN— The rates will be the spatially weighted median rate of each feature and its neighborhood.",
          "datatype": "String"
        },
        {
          "name": "probability_distribution",
          "explanation": "Specifies the probability distribution of the count field.\r\nPOISSON—The count field is assumed to follow a Poisson distribution. This is the default.BINOMIAL—The count field is assumed to follow a binomial distribution.",
          "datatype": "String"
        },
        {
          "name": "neighborhood_type(Optional)",
          "explanation": "Specifies the method that will be used to identify the neighbors of each feature.\r\nDISTANCE_BAND—A threshold distance is applied to identify neighbors. Every feature that is within the threshold distance of a focal feature is considered a neighbor. If the input contains point or line features, this is the default.CONTIGUITY_EDGES_ONLY— Polygon features that share an edge or overlap a feature become neighbors of that feature.CONTIGUITY_EDGES_CORNERS— Features that overlap, share an edge, or share a vertex with a feature are neighbors of that feature.  If the input contains polygon features, this is the default.K_NEAREST_NEIGHBORS—The same number of neighbors, k, is assigned to every feature. The k nearest features to a feature become its neighbors.DELAUNAY_TRIANGULATION—A nonoverlapping mesh of triangles is created from feature centroids. Each feature is a triangle node and nodes that share edges are considered neighbors.GET_SPATIAL_WEIGHTS_FROM_FILE—The spatial relationships between features is defined in a spatial weights matrix (.swm) file.",
          "datatype": "String"
        },
        {
          "name": "distance_band(Optional)",
          "explanation": "The distance from each feature that will be used to search for neighbors. All features within this distance will be included as neighbors.",
          "datatype": "Linear Unit"
        },
        {
          "name": "number_of_neighbors(Optional)",
          "explanation": "The number of neighbors that will be included in a feature's neighborhood.",
          "datatype": "Long"
        },
        {
          "name": "weights_matrix_file(Optional)",
          "explanation": "The path and file name of the spatial weights matrix file that defines the spatial relationships among features.",
          "datatype": "File"
        },
        {
          "name": "local_weighting_scheme(Optional)",
          "explanation": "Specifies the weighting scheme that will be applied to neighbors when calculating local statistics.UNWEIGHTED— Neighbors will not be weighted. This is the default.BISQUARE—Neighbors will be weighted using a bisquare kernel scheme.GAUSSIAN—Neighbors will be weighted using a Gaussian kernel scheme.",
          "datatype": "String"
        },
        {
          "name": "kernel_bandwidth(Optional)",
          "explanation": "The bandwidth of the bisquare or Gaussian local weighting schemes.\r\nIf no value is provided, one will be estimated during processing and included as a geoprocessing message.",
          "datatype": "Linear Unit"
        },
        {
          "name": "rate_multiplier",
          "explanation": "A constant value that will be multiplied by the rates. This parameter can be used to scale the rates or to report the rates per specific unit of population. For example, when the value is set to 10,000, the rates will be reported as a number per 10,000 people.",
          "datatype": "Long"
        }
      ],
      "summary": "Calculates crude or smoothed rates. The global empirical Bayes rate method smooths the rates toward a global reference rate. The local empirical Bayes, locally weighted average, and locally weighted median rate methods use local neighbors to spatially smooth rates. Learn more about how Calculate Rates works",
      "extraction_date": "2025-10-01T15:20:40.560536"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Collect Events",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/collect-events.htm",
      "parameters": [
        {
          "name": "Input_Incident_Features",
          "explanation": "The features representing event or incident data.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Output_Weighted_Point_Feature_Class",
          "explanation": "The output feature class that will contain the weighted point data.",
          "datatype": "Feature Class"
        }
      ],
      "summary": "Converts event data, such as crime or disease incidents, to weighted point data.",
      "extraction_date": "2025-10-01T15:20:42.966580"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Convert Spatial Statistics Popup Charts for Web Display",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/convert-spatial-statistics-popup-charts-for-web-display.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The feature class that contains the HTML_CHART field with the HTML code to create a pop-up chart. The feature class must have a 32 bit ObjectID - 64 bit Object IDs are not supported.",
          "datatype": "Feature Layer"
        },
        {
          "name": "out_feature_class",
          "explanation": "The output feature class that will contain the pop-up chart of each feature saved as an image attachment.",
          "datatype": "Feature Class"
        },
        {
          "name": "img_width(Optional)",
          "explanation": "The width, in pixels, of each image attachment.",
          "datatype": "Long"
        },
        {
          "name": "img_height(Optional)",
          "explanation": "The height, in pixels, of each image attachment.",
          "datatype": "Long"
        },
        {
          "name": "rotate_x_axis_labels(Optional)",
          "explanation": "Specifies whether the x-axis labels will be rotated.ROTATE—The x-axis labels will be rotated 20 degrees.NO_ROTATE—The x-axis labels will not be rotated. This is the default.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Prepares interactive pop-up charts for web display by saving them as image attachments to a feature class. Several tools in the Spatial Statistics and Space Time Pattern Mining toolboxes create output feature classes that include an HTML_CHART  field. If you click a feature that contains this field, an interactive chart will appear in the pop-up pane. However, if you share this feature class as a web layer to ArcGIS Online and click a feature in Map Viewer, the chart will not appear in the pop-ups. This tool creates a feature class that contains the pop-up charts as image attachments. If the feature class with image attachments is shared as a web service to ArcGIS Online, the charts will appear in the pop-ups of the web feature layer.",
      "extraction_date": "2025-10-01T15:20:45.349927"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Convert Spatial Weights Matrix To Table",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/convert-spatial-weights-matrix-to-table.htm",
      "parameters": [
        {
          "name": "Input_Spatial_Weights_Matrix_File",
          "explanation": "The full pathname for the spatial weights matrix file (.swm) you want to convert.",
          "datatype": "File"
        },
        {
          "name": "Output_Table",
          "explanation": "A full pathname to the table you want to create.",
          "datatype": "Table"
        }
      ],
      "summary": "Converts a binary spatial weights matrix file (.swm) to a table.",
      "extraction_date": "2025-10-01T15:20:47.721711"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Describe Spatial Statistics Model File",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/describe-spatial-statistics-model-file.htm",
      "parameters": [
        {
          "name": "input_model",
          "explanation": "The spatial statistics model file that will be described.",
          "datatype": "File"
        }
      ],
      "summary": "Describes the contents and diagnostics of a spatial statistics model file. Learn more about spatial statistics model files",
      "extraction_date": "2025-10-01T15:20:50.081031"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Dimension Reduction",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/dimensionreduction.htm",
      "parameters": [
        {
          "name": "in_table",
          "explanation": "The table or features containing the fields with the dimension that will be reduced.",
          "datatype": "Table View"
        },
        {
          "name": "output_data(Optional)",
          "explanation": "The output table or feature class containing the resulting components of the dimension reduction.",
          "datatype": "Table"
        },
        {
          "name": "fields[fields,...]",
          "explanation": "The fields representing the data with the dimension that will be reduced.",
          "datatype": "Field"
        },
        {
          "name": "method(Optional)",
          "explanation": "Specifies the method that will be used to reduce the dimensions of the analysis fields.PCA—The analysis fields will be partitioned into components that each maintain the maximum proportion of the total variance. This is the default.LDA—The analysis fields will be partitioned into components that each maintain the maximum  between-category separability of a categorical variable.",
          "datatype": "String"
        },
        {
          "name": "scale(Optional)",
          "explanation": "Specifies whether the values of each analysis will be scaled to have a variance equal to one. This scaling ensures that each analysis field is given equal priority in the components. Scaling also removes the effect of linear units; for example, the same data measured in meters and feet will result in equivalent components. The values of the analysis fields will be shifted to have mean zero for both options.SCALE_DATA—The values of each analysis field will be scaled to have a variance equal to one by dividing each value by the standard deviation of the analysis field.  This is the default.NO_SCALE_DATA—The variance of each analysis field  will not be scaled.",
          "datatype": "Boolean"
        },
        {
          "name": "categorical_field(Optional)",
          "explanation": "The field representing the categorical variable for LDA.  The components will maintain the maximum amount of information needed to classify each input record into these categories.",
          "datatype": "Field"
        },
        {
          "name": "min_variance(Optional)",
          "explanation": "The minimum percent of total variance  of the analysis fields that must be maintained in the components.\r\nThe total variance depends on whether the analysis fields were scaled using the scale parameter.",
          "datatype": "Long"
        },
        {
          "name": "min_components(Optional)",
          "explanation": "The minimum number of components.",
          "datatype": "Long"
        },
        {
          "name": "append_fields(Optional)",
          "explanation": "Specifies whether all fields from the input table or features will be copied and appended to the output table or feature class. The fields provided in the fields parameter will be copied to the output regardless of the value of this parameter.APPEND—All fields from the input table or features will be copied and appended to the output table or feature class.NO_APPEND—Only the analysis fields will be included in the output table or feature class.  This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "output_eigenvalues_table(Optional)",
          "explanation": "The output table containing the eigenvalues of each component.\r\nThe values of the eigenvectors are rescaled to have unit norm (the sum of squared values equals one).",
          "datatype": "Table"
        },
        {
          "name": "output_eigenvectors_table(Optional)",
          "explanation": "The output table containing the eigenvectors of each component.",
          "datatype": "Table"
        },
        {
          "name": "number_of_permutations(Optional)",
          "explanation": "The number of permutations that will be used when determining the optimal number of components.  The default value is 0, which indicates that no permutation test will be performed.\r\nThe provided value must be equal to 0, 99, 199, 499, or 999.  If any other value is provided, 0 will be used and no permutation test will be performed.",
          "datatype": "Long"
        },
        {
          "name": "append_to_input(Optional)",
          "explanation": "Specifies whether the component fields will be appended to the input dataset or saved to an output table or feature class. If you append the fields to the input, the output coordinate system environment will be ignored.APPEND_TO_INPUT—The fields containing the components will be appended to the input features. This option modifies the input data.NEW_OUTPUT—An output table or feature class  will be created containing the component fields. This is the default.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Reduces the number of dimensions of a set of continuous variables by aggregating the highest possible amount of variance into fewer components using Principal Component Analysis (PCA) or Reduced-Rank Linear Discriminant Analysis (LDA). The variables are specified as fields in an input table or feature layer, and new fields representing the new variables are saved  in the output table or feature class. The number of new fields will be fewer than the number of original variables while maintaining the highest possible amount of variance from all the original variables. Dimension reduction is commonly used to explore multivariate relationships between variables and to reduce the computational cost of machine learning algorithms in which the required memory and processing time depend on the number of dimensions of the data. Using the components in place of the original data in analysis or machine learning algorithms can often provide comparable (or better) results while consuming fewer computational resources. Learn more about how Dimension Reduction works",
      "extraction_date": "2025-10-01T15:20:52.673805"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Export Feature Attributes To ASCII",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/export-feature-attribute-to-ascii.htm",
      "parameters": [
        {
          "name": "Input_Feature_Class",
          "explanation": "The feature class from which the feature coordinates and attribute values will be exported.",
          "datatype": "Feature Layer"
        },
        {
          "name": "Value_Field[Value_Field,...]",
          "explanation": "The field or fields in the input feature class containing the values to export to an ASCII text file.",
          "datatype": "Field"
        },
        {
          "name": "Delimiter",
          "explanation": "Specifies how feature coordinates and attribute values will be separated in the output ASCII file.SPACE—Feature coordinates and attribute values will be separated by a space in the output. This is the default.COMMA—Feature coordinates and attribute values will be separated by a comma in the output. SEMI-COLON—Feature coordinates and attribute values will be separated by a semicolon in the output. TAB—Feature coordinates and attribute values will be separated by a tab in the output.",
          "datatype": "String"
        },
        {
          "name": "Output_ASCII_File",
          "explanation": "The ASCII text file that will contain the feature coordinates and attribute values.",
          "datatype": "File"
        }
      ],
      "summary": "Exports feature class coordinates and attribute values to a space-, comma-, tab-, or semicolon-delimited ASCII text file.",
      "extraction_date": "2025-10-01T15:20:55.055200"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Set Spatial Statistics Model File Properties",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/set-spatial-statistics-model-file-properties.htm",
      "parameters": [
        {
          "name": "input_model",
          "explanation": "The spatial statistics model file.",
          "datatype": "File"
        },
        {
          "name": "variable_predict[[var1, desc1, unit1], [var2, desc2, unit2],...](Optional)",
          "explanation": "The name, description, and unit of the variable that will be predicted at new locations.",
          "datatype": "Value Table"
        },
        {
          "name": "explanatory_variables[[var1, desc1, unit1], [var2, desc2, unit2],...](Optional)",
          "explanation": "The name, description, and unit\r\nof the explanatory variables that will be used to train the input model.",
          "datatype": "Value Table"
        },
        {
          "name": "distance_features[[var1, desc1, unit1], [var2, desc2, unit2],...](Optional)",
          "explanation": "The name, description, and unit\r\nof the explanatory training distance features that will be used to train the input model.",
          "datatype": "Value Table"
        },
        {
          "name": "explanatory_rasters[[var1, desc1, unit1], [var2, desc2, unit2],...](Optional)",
          "explanation": "The name, description, and unit\r\nof the explanatory training rasters that will be used to train the input model.",
          "datatype": "Value Table"
        }
      ],
      "summary": "Adds descriptions and units to the variables stored in a spatial statistics model file. Learn more about spatial statistics model files",
      "extraction_date": "2025-10-01T15:20:57.517819"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Time Series Smoothing",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/spatial-statistics/time-series-smoothing.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The features or table containing the time series data and the field to smooth.",
          "datatype": "Table View"
        },
        {
          "name": "time_field",
          "explanation": "The field containing the time of each record.",
          "datatype": "Field"
        },
        {
          "name": "analysis_field",
          "explanation": "The field containing the values that will be smoothed.",
          "datatype": "Field"
        },
        {
          "name": "group_method(Optional)",
          "explanation": "Specifies the method that will be used to group records into different time series. \r\nSmoothing is performed independently for each time series.LOCATION—Features at the same location will be grouped in the same time series. This is the default.ID_FIELD—Records with the same value of the ID field will be grouped in the same time series.NONE—All records will be in the same time series.",
          "datatype": "String"
        },
        {
          "name": "method(Optional)",
          "explanation": "Specifies the smoothing method that will be used.\r\nBACKWARD—The smoothed value is the average of the record and the values within the time window before it. This is the default.CENTERED—The smoothed value is the average of the record and the values before and after it. Half of the time window is used before the time of the record, and half is used after.FORWARD—The smoothed value is the average of the record and the values within the time window after it.ADAPTIVE—The smoothed value is the result of a local linear regression centered at the record. The size of the time window is optimized for each record.",
          "datatype": "String"
        },
        {
          "name": "time_window(Optional)",
          "explanation": "The length of the time window. The value can be provided in seconds, minutes, hours, days, weeks, months, or years. For backward, forward, and centered moving averages, the value and unit must be provided. For adaptive bandwidth local linear regression, the value can be left empty and a time window will be estimated independently for each value. Values that fall on the border of the time window will be included within the window. For example, if you have daily data and you use a backward moving average with a time window of four days, five values will be included in the window when smoothing a record: the value of the record and the values of the four previous days.",
          "datatype": "Time Unit"
        },
        {
          "name": "append_to_input(Optional)",
          "explanation": "Specifies whether the output fields will be appended to the input dataset or saved as a new output table or feature class. If you append the fields to the input, the output coordinate system environment will be ignored.APPEND_TO_INPUT—The output fields will be appended to the input features. This option modifies the input data.NEW_OUTPUT—The output fields will not be appended to the input. An output table or a feature class will be created containing the output fields. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "output_features(Optional)",
          "explanation": "The output features containing the smoothed values as well as fields for the time window and number of neighbors.",
          "datatype": "Feature Class; Table"
        },
        {
          "name": "id_field(Optional)",
          "explanation": "The integer or text field containing a unique ID for each time series. All records with the same value of this field are part of the same time series.",
          "datatype": "Field"
        },
        {
          "name": "apply_shorter_window(Optional)",
          "explanation": "Specifies whether the time window will be shortened at the beginning and end of each time series.APPLY_SHORTER_WINDOW—The time window will be shortened at the start and end of the time series so that the time window does not extend before the start or after the end of the time series.NOT_APPLY_SHORTER_WINDOW—The time window will not be shortened. If the time window extends before the start or after the end of the time series, the smoothed value will be null. This is the default.",
          "datatype": "Boolean"
        },
        {
          "name": "enable_time_series_popups(Optional)",
          "explanation": "Specifies whether the output features or table will include pop-up charts showing the original and smoothed values of the time series.CREATE_POPUP—The output will include pop-up charts. This is the default.NO_POPUP—The output will not include pop-up charts.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Smooths a numeric variable of one or more time series using centered, forward, and backward moving averages, as well as an adaptive method based on local linear regression. After smoothing short-term fluctuations, longer-term trends or cycles often become apparent. Learn more about how Time Series Smoothing works",
      "extraction_date": "2025-10-01T15:21:00.264153"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Calculate Field",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/data-management/calculate-field.htm",
      "parameters": [
        {
          "name": "in_table",
          "explanation": "The table containing the field that will be updated with the new calculation.",
          "datatype": "Mosaic Layer; Raster Layer; Table View"
        },
        {
          "name": "field",
          "explanation": "The field that will be updated with the new calculation.If a field with the specified name does not exist in the input table, it will be added.",
          "datatype": "Field"
        },
        {
          "name": "expression",
          "explanation": "The simple calculation expression used to create a value that will populate the selected rows.",
          "datatype": "SQL Expression"
        },
        {
          "name": "expression_type(Optional)",
          "explanation": "Specifies the type of expression that will be used.PYTHON3—The Python expression type will be used.ARCADE—The Arcade expression type will be used.SQL—The SQL expression type will be used.VB—The VBScript expression type will be used.If the input is a feature service, the default expression type is SQL. For any other type of input, the default expression type is PYTHON3.To learn more about Python expressions, see Calculate Field Python examples.To learn more about Arcade expressions, see ArcGIS Arcade in the Developer help.To learn more about SQL expressions, see SQL expression syntax and Calculate field values.SQL expressions support faster calculations for feature services and enterprise geodatabases. Instead of performing calculations one feature or row at a time, a single request is sent to the server or database, resulting in significantly faster calculations.Only feature services,  enterprise geodatabases, mobile geodatabases, file geodatabases, databases, SQLite, and GeoPackage support SQL expressions. For other formats, use Python or Arcade expressions.To learn more about VBScript expressions, see Calculate Field VBScript examples.",
          "datatype": "String"
        },
        {
          "name": "code_block(Optional)",
          "explanation": "A block of code that will be used for complex Python or VBScript expressions.",
          "datatype": "String"
        },
        {
          "name": "field_type(Optional)",
          "explanation": "Specifies the field type of the new field. This parameter is only used when the field name does not exist in the input table.If\r\nthe field is of type text, the field will have a length of 512,\r\nunless the input is a shapefile or dBASE file, in which case the\r\nlength will be 254.  To adjust the length, use the Alter Field tool.\t\t\t\t\t\tSHORT—The field type will be short. Short fields support whole numbers between -32,768 and 32,767.LONG—The field type will be long. Long fields support whole numbers between -2,147,483,648 and 2,147,483,647.BIGINTEGER—The field type will be big integer. Big integer fields support whole numbers between -(253) and 253.FLOAT—The field type will be float. Float fields support fractional numbers between -3.4E38 and 1.2E38.DOUBLE—The field type will be double. Double fields support fractional numbers between -2.2E308 and 1.8E308.TEXT—The field type will be text. Text fields support a string of characters.DATE—The field type will be date. Date fields support date and  time values. DATEHIGHPRECISION—The field type will be high precision date. High precision date fields support date and time values with millisecond time.DATEONLY—The field type will be date only. Date only fields support date values with no time values.TIMEONLY—The field type will be time only. Time only fields support time values with no date values.TIMESTAMPOFFSET—The field type will be timestamp offset. Timestamp offset fields support a date, time, and offset from a UTC value.BLOB—The field type will be BLOB. BLOB fields support data stored as a long sequence of binary numbers. You need  a custom loader or viewer or a third-party\r\napplication to load items into a BLOB field or view the contents of\r\na BLOB field.\r\nGUID—The field type will be GUID. GUID fields store registry-style strings consisting of 36 characters enclosed in curly brackets.RASTER— The field type will be raster. Raster fields can store raster data in or alongside the geodatabase. All ArcGIS software-supported raster dataset formats can be stored, but it is recommended that only small images be used.",
          "datatype": "String"
        },
        {
          "name": "enforce_domains(Optional)",
          "explanation": "Specifies whether field domain rules will be enforced.ENFORCE_DOMAINS—Field domain rules will be enforced.NO_ENFORCE_DOMAINS—Field domain rules will not be enforced. This is the default.",
          "datatype": "Boolean"
        }
      ],
      "summary": "Calculates the values of a field for a feature class, feature layer, or raster.",
      "extraction_date": "2025-10-01T15:21:03.014921"
    },
    {
      "toolset": "spatial-statistics",
      "tool_name": "Calculate Geometry Attributes",
      "help_url": "https://pro.arcgis.com/en/pro-app/3.5/tool-reference/data-management/calculate-geometry-attributes.htm",
      "parameters": [
        {
          "name": "in_features",
          "explanation": "The features with a field that will be updated with geometry calculations.",
          "datatype": "Feature Layer"
        },
        {
          "name": "geometry_property[[Field, Property],...]",
          "explanation": "The fields in which the specified geometry properties will be calculated. You can select an existing field or provide a new field name. If a new field name is provided, the field type is determined by the type of values that are written to the field.  Count attributes are written to long integer fields;  area, length, and x-, y-, z-coordinate, and m-value attributes are written to double fields; and coordinate notations such as Degrees Minutes Seconds or MGRS are written to text fields.Unless otherwise noted, area and length properties are planar measurements using 2D Cartesian mathematics.AREA—An attribute will be added to store the area of each polygon feature.AREA_GEODESIC—An attribute will be added to store the shape-preserving geodesic area of each polygon feature.CENTROID_X—An attribute will be added to store the centroid x-coordinate of each feature.CENTROID_Y—An attribute will be added to store the centroid y-coordinate of each feature.CENTROID_Z—An attribute will be added to store the centroid z-coordinate of each feature.CENTROID_M—An attribute will be added to store the centroid m-value of each feature.INSIDE_X—An attribute will be added to store the x-coordinate of a central point inside or on each feature. This point is the same as the centroid if the centroid is inside the feature; otherwise, it is an inner label point.INSIDE_Y—An attribute will be added to store the y-coordinate of a central point inside or on each feature. This point is the same as the centroid if the centroid is inside the feature; otherwise, it is an inner label point.INSIDE_Z—An attribute will be added to store the z-coordinate of a central point inside or on each feature. This point is the same as the centroid if the centroid is inside the feature; otherwise, it is an inner label point.INSIDE_M—An attribute will be added to store the m-value of a central point inside or on each feature. This point is the same as the centroid if the centroid is inside the feature; otherwise, it is an inner label point.CURVE_COUNT—An attribute will be added to store the number of curves in each feature. Curves include elliptical arcs, circular arcs, and Bezier curves.HOLE_COUNT—An attribute will be added to store the number of interior holes within each polygon feature.EXTENT_MIN_X—An attribute will be added to store the minimum x-coordinate of each feature's extent.EXTENT_MIN_Y—An attribute will be added to store the minimum y-coordinate of each feature's extent.EXTENT_MIN_Z—An attribute will be added to store the minimum z-coordinate of each feature's extent.EXTENT_MAX_X—An attribute will be added to store the maximum x-coordinate of each feature's extent.EXTENT_MAX_Y—An attribute will be added to store the maximum y-coordinate of each feature's extent.EXTENT_MAX_Z—An attribute will be added to store the maximum z-coordinate of each feature's extent.LENGTH—An attribute will be added to store the length of each line feature.LENGTH_GEODESIC—An attribute will be added to store the shape-preserving geodesic length of each line feature.LENGTH_3D—An attribute will be added to store the 3D length of each line feature.LINE_BEARING—An attribute will be added to store the start-to-end bearing of each line feature. Values range from 0 to 360, with 0 meaning north, 90 east, 180 south, 270 west, and so on.LINE_START_X—An attribute will be added to store the x-coordinate of the start point of each line feature.LINE_START_Y—An attribute will be added to store the y-coordinate of the start point of each line feature.LINE_START_Z—An attribute will be added to store the z-coordinate of the start point of each line feature.LINE_START_M—An attribute will be added to store the m-value of the start point of each line feature.LINE_END_X—An attribute will be added to store the x-coordinate of the end point of each line feature.LINE_END_Y—An attribute will be added to store the y-coordinate of the end point of each line feature.LINE_END_Z—An attribute will be added to store the z-coordinate of the end point of each line feature.LINE_END_M—An attribute will be added to store the m-value of the end point of each line feature.PART_COUNT—An attribute will be added to store the number of parts composing each feature.POINT_COUNT—An attribute will be added to store the number of points or vertices composing each feature.PERIMETER_LENGTH—An attribute will be added to store the length of the perimeter or border of each polygon feature.PERIMETER_LENGTH_GEODESIC—An attribute will be added to store the shape-preserving geodesic length of the perimeter or border of each polygon feature.POINT_X—An attribute will be added to store the x-coordinate of each point feature.POINT_Y—An attribute will be added to store the y-coordinate of each point feature.POINT_Z—An attribute will be added to store the z-coordinate of each point feature.POINT_M—An attribute will be added to store the m-value of each point feature.POINT_COORD_NOTATION—An attribute will be added to store the x- and y-coordinate of each point feature formatted as a specified coordinate notation.",
          "datatype": "Value Table"
        },
        {
          "name": "length_unit(Optional)",
          "explanation": "Specifies the unit that will be used to calculate length.\r\nKILOMETERS—The length unit will be kilometers.METERS—The length unit will be meters.MILES_INT—The length unit will be statute miles.NAUTICAL_MILES_INT—The length unit will be international nautical miles.YARDS_INT—The length unit will be international yards.FEET_INT—The length unit will be international feet.MILES_US—The length unit will be US survey miles.NAUTICAL_MILES—The length unit will be US survey nautical miles.YARDS—The length unit will be US survey yards.FEET_US—The length unit will be US survey feet.",
          "datatype": "String"
        },
        {
          "name": "area_unit(Optional)",
          "explanation": "Specifies the unit that will be used to calculate area.\r\nSQUARE_KILOMETERS—The area unit will be square kilometers.HECTARES—The area unit will be hectares.SQUARE_METERS—The area unit will be square meters.SQUARE_MILES_INT—The area unit will be square statute miles.SQUARE_NAUTICAL_MILES—The area unit will be square international nautical miles.ACRES—The area unit will be international acres.SQUARE_YARDS—The area unit will be square international yards.SQUARE_FEET_INT—The area unit will be square international feet.SQUARE_MILES_US—The area unit will be square US survey miles.SQUARE_NAUTICAL_MILES_US—The area unit will be square US survey nautical miles.ACRES_US—The area unit will be US survey acres.SQUARE_YARDS_US—The area unit will be square US survey yards.SQUARE_FEET_US—The area unit will be square US survey feet.",
          "datatype": "String"
        },
        {
          "name": "coordinate_system(Optional)",
          "explanation": "The coordinate system in which the coordinates, length, and area will be calculated. The coordinate system of the input features is used by default.",
          "datatype": "Coordinate System"
        },
        {
          "name": "coordinate_format(Optional)",
          "explanation": "Specifies the coordinate format in which the x- and y-coordinates will be calculated. The coordinate format matching the input features' spatial reference units is used by default. \r\nSeveral coordinate formats, including Degrees Minutes Seconds, Degrees Decimal Minutes, and others, require the calculation to be performed in a text field.SAME_AS_INPUT—The input features' spatial reference units will be used for coordinate formatting. This is the default.DD—The coordinate format will be Decimal Degrees.DMS_DIR_LAST—The coordinate format will be Degrees Minutes Seconds with cardinal direction component at the end (DDD° MM' SSS.ss\" &lt;N|S|E|W&gt;).DMS_DIR_FIRST—The coordinate format will be Degrees Minutes Seconds with cardinal direction component at the beginning (&lt;N|S|E|W&gt; DDD° MM' SSS.ss\").DMS_POS_NEG—The coordinate format will be Degrees Minutes Seconds with positive or negative direction component at the beginning (&lt;+|-&gt; DDD° MM' SSS.ss\").DMS_PACKED—The coordinate format will be Degrees Minutes Seconds packed into a single value with positive or negative direction component at the beginning (&lt;+|-&gt; DDD.MMSSSss).DDM_DIR_LAST—The coordinate format will be Degrees Decimal Minutes with cardinal direction component at the end (DDD° MM.mmm' &lt;N|S|E|W&gt;).DDM_DIR_FIRST—The coordinate format will be Degrees Decimal Minutes with cardinal direction component at the beginning (&lt;N|S|E|W&gt; DDD° MM.mmm').DDM_POS_NEG—The coordinate format will be Degrees Decimal Minutes with positive or negative direction component at the beginning (&lt;+|-&gt; DDD° MM.mmm').GARS—The coordinate format will be Global Area Reference System. The Global Area Reference System is based on latitude and longitude, dividing and subdividing the world into cells.GEOREF—The coordinate format will be World Geographic Reference System. The World Geographic Reference System is based on the geographic system of latitude and longitude, but using a simpler and more flexible notation.MGRS—The coordinate format will be Military Grid Reference System.USNG—The coordinate format will be United States National Grid.UTM—The coordinate format will be Universal Transverse Mercator.UTMNS—The coordinate format will be Universal Transverse Mercator with no spaces.",
          "datatype": "String"
        }
      ],
      "summary": "Adds information to a feature's attribute fields representing the spatial or geometric characteristics and location of each feature, such as length or area and x-, y-, z-coordinates, and m-values.",
      "extraction_date": "2025-10-01T15:21:05.630553"
    }
  ]
}